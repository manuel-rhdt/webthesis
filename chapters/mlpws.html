<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <link rel="sitemap" type="application/xml" href="/sitemap.xml">
  <title>ML-PWS</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../css/thesis-style.css" />
  <a href="../index.html" class="back-link">‚Üê Back to Contents</a>
  <script src="../js/equation-tooltips.js"></script>
</head>
<body>
<header id="title-block-header">
<h1 class="title">ML-PWS</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#abstract" id="toc-abstract">Abstract</a></li>
<li><a href="#ch:ml-pws" id="toc-ch:ml-pws">ML-PWS: Quantifying
Information Transmission Using Neural Networks</a>
<ul>
<li><a href="#methods" id="toc-methods">Methods</a>
<ul>
<li><a href="#the-mutual-information-rate-for-discrete-time-processes"
id="toc-the-mutual-information-rate-for-discrete-time-processes">The
Mutual Information Rate for Discrete-time Processes</a></li>
<li><a href="#path-weight-sampling" id="toc-path-weight-sampling">Path
Weight Sampling</a></li>
<li><a
href="#autoregressive-neural-networks-for-stochastic-sequence-modeling"
id="toc-autoregressive-neural-networks-for-stochastic-sequence-modeling">Autoregressive
neural networks for stochastic sequence modeling</a></li>
<li><a href="#sec:ml_variational" id="toc-sec:ml_variational">Efficient
Marginalization Using Variational Inference</a></li>
</ul></li>
<li><a href="#sec:ml_application"
id="toc-sec:ml_application">Application to a Minimal Nonlinear Model</a>
<ul>
<li><a href="#nonlinear-model" id="toc-nonlinear-model">Nonlinear
Model</a></li>
<li><a href="#training-the-neural-networks"
id="toc-training-the-neural-networks">Training the Neural
Networks</a></li>
<li><a href="#comparison-against-the-true-mutual-information"
id="toc-comparison-against-the-true-mutual-information">Comparison
Against the True Mutual Information</a></li>
<li><a href="#comparison-against-the-gaussian-approximation"
id="toc-comparison-against-the-gaussian-approximation">Comparison
Against the Gaussian Approximation</a></li>
</ul></li>
<li><a href="#sec:ml_discussion"
id="toc-sec:ml_discussion">Discussion</a></li>
</ul></li>
<li><a href="#bibliography" id="toc-bibliography">References</a></li>
</ul>
</nav>
<h1 id="abstract">Abstract</h1>
<blockquote>
<p>Understanding the flow of information in natural and engineered
systems is crucial for their design and analysis. The mutual information
rate is the fundamental measure to describe the transmission of
information for systems with time-varying signals. Yet, computing it
accurately is extremely challenging due to the high-dimensional nature
of trajectories. Previous methods include the Gaussian approximation
which is limited to linear systems with Gaussian noise. A recent
technique, Path Weight Sampling (PWS), in principle addresses these
limitations, but it requires a stochastic model, which is often not
available for the systems of interest. We propose leveraging recent
advances in machine learning to obtain such a stochastic model directly
from data, and provide a general-purpose tool for estimating the mutual
information rate. Specifically, using unsupervised learning, we estimate
the probability distribution of trajectories by training a neural
stochastic model on time-series data. We demonstrate that by combining
machine learning with PWS (ML-PWS) we can accurately compute the
information transmission rate of nonlinear systems, even in the absence
of a known mechanistic or phenomenological model. This approach
represents a significant advance for data-driven quantification of
information transmission in general nonlinear and non-Gaussian
systems.</p>
</blockquote>
<h1 id="ch:ml-pws">ML-PWS: Quantifying Information Transmission Using
Neural Networks</h1>
<p></p>
<p>Information theory is the most general framework for studying signal
processing systems and quantifying their performance. Shannon <span
class="citation" data-cites="1948.Shannon">¬†[<a href="#ref-1948.Shannon"
role="doc-biblioref">1</a>]</span> introduced the mutual information as
a measure to quantify how much information is communicated between two
random variables, such as the input and output of a system at a given
time. However, for most systems the mapping from input to the output
cannot be directly described as a sequence of independent transmissions,
rather information can generally be contained in temporal correlations
within the input or output signals. Therefore, the mutual information
between signal values at a given instant is in general ill-suited for
measuring the amount of information transmission. To correctly quantify
the information transmitted via time-varying signals requires computing
the mutual information between the entire input and output trajectories
of the system <span class="citation" data-cites="2009.Tostevin">¬†[<a
href="#ref-2009.Tostevin" role="doc-biblioref">2</a>]</span>. The rate
at which this trajectory mutual information increases with the
trajectory duration in the long-time limit defines the mutual
information rate <span class="citation" data-cites="1948.Shannon">¬†[<a
href="#ref-1948.Shannon" role="doc-biblioref">1</a>]</span>. This rate
represents the speed at which distinct messages are transmitted through
the system, and it depends not only on the accuracy of the input-output
mapping but also on the correlations within the input and output
signals. In the absence of feedback this rate also equals the multi-step
transfer entropy <span class="citation"
data-cites="1990.Massey 2000.Schreiber">¬†[<a href="#ref-1990.Massey"
role="doc-biblioref">3</a>,<a href="#ref-2000.Schreiber"
role="doc-biblioref">4</a>]</span>.</p>
<p>The mutual information rate is the key measure to quantify
information flow in dynamical systems. It is used to quantify
biochemical signaling performance <span class="citation"
data-cites="2021.Mattingly 2023.Hahn 2023.Moor">¬†[<a
href="#ref-2021.Mattingly" role="doc-biblioref">5</a>‚Äì<a
href="#ref-2023.Moor" role="doc-biblioref">7</a>]</span>, to perform
model reduction <span class="citation" data-cites="2023.Schmitt">¬†[<a
href="#ref-2023.Schmitt" role="doc-biblioref">8</a>]</span>, to detect
the causality of interactions <span class="citation"
data-cites="2007.Frenzel 2007.Hlav√°ƒçkov√°-Schindler">¬†[<a
href="#ref-2007.Frenzel" role="doc-biblioref">9</a>,<a
href="#ref-2007.Hlav√°ƒçkov√°-Schindler"
role="doc-biblioref">10</a>]</span> or to test for nonlinearities in
time series <span class="citation" data-cites="1995.Palu≈°">¬†[<a
href="#ref-1995.Palu≈°" role="doc-biblioref">11</a>]</span>. This
includes applications such as financial markets, to assess dependencies
between stock prices or market indices over time <span class="citation"
data-cites="2002.Marschinski 2013.Dimpfl 2016.Dimpfl">¬†[<a
href="#ref-2002.Marschinski" role="doc-biblioref">12</a>‚Äì<a
href="#ref-2016.Dimpfl" role="doc-biblioref">14</a>]</span>, or
neuroscience, where it is used to measure the amount of information
exchanged between different regions of the brain <span class="citation"
data-cites="2011.Rad 2012.So">¬†[<a href="#ref-2011.Rad"
role="doc-biblioref">15</a>,<a href="#ref-2012.So"
role="doc-biblioref">16</a>]</span>. Being one of the key performance
measures in information theory, the mutual information rate is thus of
paramount practical relevance.</p>
<p>Yet, computing the mutual information rate poses a significant
challenge because trajectories are high-dimensional objects, making its
accurate estimation difficult. Traditional techniques first estimate the
joint probability distribution of input and output, e.g. via histograms
or kernel density estimates, and then compute the mutual information
from the distribution estimate <span class="citation"
data-cites="1986.Fraser 1995.Moon">¬†[<a href="#ref-1986.Fraser"
role="doc-biblioref">17</a>,<a href="#ref-1995.Moon"
role="doc-biblioref">18</a>]</span>. However, these distribution
estimates are typically infeasible in high-dimensional spaces <span
class="citation" data-cites="2003.Paninski 2019.Cepeda-Humerez">¬†[<a
href="#ref-2003.Paninski" role="doc-biblioref">19</a>,<a
href="#ref-2019.Cepeda-Humerez" role="doc-biblioref">20</a>]</span>, and
have only been successfully used for computing the mutual information
between trajectories in very simple systems <span class="citation"
data-cites="2021.Meijers">¬†[<a href="#ref-2021.Meijers"
role="doc-biblioref">21</a>]</span>. Non-parametric estimators, such as
the k-nearest-neighbor estimator <span class="citation"
data-cites="2004.Kraskov">¬†[<a href="#ref-2004.Kraskov"
role="doc-biblioref">22</a>]</span> attempt to circumvent some of these
issues but require selecting an appropriate metric in trajectory space
and still suffer from uncontrolled biases for high-dimensional data
<span class="citation" data-cites="2014.Gao 2019.Cepeda-Humerez">¬†[<a
href="#ref-2019.Cepeda-Humerez" role="doc-biblioref">20</a>,<a
href="#ref-2014.Gao" role="doc-biblioref">23</a>]</span>. For systems
that exhibit approximately Gaussian dynamics, the mutual information can
be estimated directly from correlation functions <span class="citation"
data-cites="2009.Tostevin 2010.Tostevin">¬†[<a href="#ref-2009.Tostevin"
role="doc-biblioref">2</a>,<a href="#ref-2010.Tostevin"
role="doc-biblioref">24</a>]</span>, though this method is limited to
linear systems.<a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a> Finally, analytical and numerical
approaches have been developed to accurately compute or approximate the
trajectory mutual information from a dynamical model of the system <span
class="citation"
data-cites="2009.Tostevin 2019.Duso 2023.Reinhardt 2023.Moor 2023.Sinzger">¬†[<a
href="#ref-2009.Tostevin" role="doc-biblioref">2</a>,<a
href="#ref-2023.Moor" role="doc-biblioref">7</a>,<a
href="#ref-2019.Duso" role="doc-biblioref">25</a>‚Äì<a
href="#ref-2023.Sinzger" role="doc-biblioref">27</a>]</span>. In
particular, we recently introduced Path Weight Sampling (PWS), a
model-based Monte Carlo technique to exactly compute the mutual
information rate <span class="citation" data-cites="2023.Reinhardt">¬†[<a
href="#ref-2023.Reinhardt" role="doc-biblioref">26</a>]</span>. But,
since all these techniques require an accurate stochastic model
describing the system, they cannot be directly applied to data.</p>
<p>Neural network-based methods offer a promising alternative. By
leveraging gradient descent for learning complex high-dimensional
distributions, we can potentially estimate the mutual information more
accurately. So far, most of these approaches have primarily focused on
training neural networks to optimize variational bounds of the mutual
information <span class="citation"
data-cites="2004.Barber 2010.Nguyen 2016.Alemi 2018.Belghazi 2018.Oord 2019.Poole">¬†[<a
href="#ref-2004.Barber" role="doc-biblioref">28</a>‚Äì<a
href="#ref-2019.Poole" role="doc-biblioref">33</a>]</span>, often with
the goal of learning effective latent state representations. However,
these variational bounds are frequently not tight due to limited amounts
of training data and the difficulty of optimizing over high-dimensional
spaces <span class="citation"
data-cites="2018.McAllester 2019.Poole 2019.Kolchinsky 2019.Cepeda-Humerez 2019.Hledik">¬†[<a
href="#ref-2019.Cepeda-Humerez" role="doc-biblioref">20</a>,<a
href="#ref-2019.Poole" role="doc-biblioref">33</a>‚Äì<a
href="#ref-2019.Hledik" role="doc-biblioref">36</a>]</span>, leading to
significant underestimation of the mutual information. The
Difference-of-Entropies (DoE) estimator by McAllester and Stratos <span
class="citation" data-cites="2018.McAllester">¬†[<a
href="#ref-2018.McAllester" role="doc-biblioref">34</a>]</span> neither
provides an upper nor a lower bound on the mutual information, but often
results in more accurate mutual information estimates. As discussed in
<a href="#sec:ml_discussion">Sec. ml_discussion</a>, this estimator
shares some similarities with PWS. Given the effectiveness of neural
networks for modeling sequential data, we thus asked whether machine
learning could be combined with PWS to create a robust, data-driven
estimator for the mutual information rate.</p>
<p>In this chapter, we present ML-PWS, an extension of PWS for computing
the mutual information rate directly from experimental time-series data.
By leveraging current machine learning methods, and combining them with
PWS, we obtain a flexible architecture for computing the mutual
information rate. We demonstrate that neural autoregressive sequence
prediction models, which have been used in speech synthesis <span
class="citation" data-cites="2016.Oord">¬†[<a href="#ref-2016.Oord"
role="doc-biblioref">37</a>]</span> or text generation <span
class="citation" data-cites="2011.Sutskever">¬†[<a
href="#ref-2011.Sutskever" role="doc-biblioref">38</a>]</span>, can be
trained to learn a nonlinear stochastic model directly from data
consisting of many input-output pairs of time-series. The model is
trained by minimizing the Kullback-Leibler divergence between the model
predictions and the observed trajectories. With this approach, the model
learns the stochastic properties of the trajectories, enabling the
computation of the mutual information rate using PWS. Here, the neural
network is both used to generate stochastic trajectories, as well as to
compute the path weights required for the PWS Monte Carlo estimate.
Moreover, we show that by leveraging variational techniques we can
significantly improve the PWS estimator itself, employing neural
importance sampling <span class="citation" data-cites="2019.Muller">¬†[<a
href="#ref-2019.Muller" role="doc-biblioref">39</a>]</span> to
efficiently marginalize the joint distribution of input and output‚Äîa key
step in the algorithm. We posit that these advances lead to a generic,
flexible, and efficient framework for computing the mutual information
rate directly from experimental data.</p>
<p>We test our approach by computing the mutual information rate for a
minimal nonlinear model and comparing our results against the true
mutual information as well as against the Gaussian approximation. We
find that the autoregressive sequence model effectively learns the
stochastic dynamics of the nonlinear system, and that PWS yields
accurate mutual information estimates, including in regimes where the
widely-used Gaussian approximation fails. Notably, we find that even for
approximately linear systems, our model combined with PWS provides more
accurate mutual information estimates than the Gaussian approximation
because it suffers less from bias caused by using a finite-size
dataset.</p>
<h2 id="methods">Methods</h2>
<h3 id="the-mutual-information-rate-for-discrete-time-processes">The
Mutual Information Rate for Discrete-time Processes</h3>
<p>The mutual information between two random variables
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
is defined as </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo stretchy="false" form="prefix">(</mo><mi>S</mi><mo>,</mo><mi>X</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mo>‚à¨</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mfrac><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>s</mi><mo stretchy="false" form="postfix">)</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow></mfrac><mspace width="0.222em"></mspace><mi>d</mi><mi>s</mi><mspace width="0.167em"></mspace><mi>d</mi><mi>x</mi><mspace width="0.167em"></mspace><mo>,</mo></mrow><annotation encoding="application/x-tex">I(S, X) = \iint \mathrm{P}(s, x) \ln \frac{\mathrm{P}(s, x)}{\mathrm{P}(s)\mathrm{P}(x)}\ ds\,dx \,,</annotation></semantics></math>
<p> or, equivalently, using Shannon entropies </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"><mi>I</mi><mo stretchy="false" form="prefix">(</mo><mi>S</mi><mo>,</mo><mi>X</mi><mo stretchy="false" form="postfix">)</mo></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>S</mi><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo stretchy="false" form="postfix">)</mo><mo>‚àí</mo><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>S</mi><mo>,</mo><mi>X</mi><mo stretchy="false" form="postfix">)</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>S</mi><mo stretchy="false" form="postfix">)</mo><mo>‚àí</mo><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>S</mi><mo stretchy="false" form="prefix">|</mo><mi>X</mi><mo stretchy="false" form="postfix">)</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo stretchy="false" form="postfix">)</mo><mo>‚àí</mo><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo stretchy="false" form="prefix">|</mo><mi>S</mi><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
I(S, X) 
&amp;= H(S) + H(X) - H(S, X) \\
&amp;= H(S) - H(S|X) \\
&amp;= H(X) - H(X|S)\,.
\end{aligned}</annotation></semantics></math>
<p> In the context of a noisy communication channel,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
represent the messages at the sending and receiving end, respectively.
Then,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo stretchy="false" form="prefix">(</mo><mi>S</mi><mo>,</mo><mi>X</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">I(S, X)</annotation></semantics></math>
is the amount of information about
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
that is communicated when only
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
is received. If
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
can be perfectly reconstructed from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>,
then
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo stretchy="false" form="prefix">(</mo><mi>S</mi><mo>,</mo><mi>X</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>S</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">I(S,X)=H(S)</annotation></semantics></math>.
On the contrary, if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
are independent,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo stretchy="false" form="prefix">(</mo><mi>S</mi><mo>,</mo><mi>X</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">I(S, X)=0</annotation></semantics></math>.
The mutual information thus is always non-negative and quantifies the
degree of statistical dependence between two random variables.</p>
<p>For systems that repeatedly transmit information, this concept must
be extended to sequences of messages
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>=</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>S</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>S</mi><mi>n</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">S_{1:n}=(S_1,\ldots,S_n)</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>=</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>X</mi><mi>n</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">X_{1:n}=(X_1,\ldots,X_n)</annotation></semantics></math>.
The mutual information between random sequences is defined analogously
as </p>
<div id="eq:trajectory_mi_sequence">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>S</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>X</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><msub><mrow><mo stretchy="true" form="prefix">‚ü®</mo><mi>ln</mi><mfrac><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow></mfrac><mo stretchy="true" form="postfix">‚ü©</mo></mrow><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow></msub></mrow><annotation encoding="application/x-tex">I(S_{1:n},X_{1:n}) = \left\langle \ln\frac{\mathrm{P}(s_{1:n}, x_{1:n})}{\mathrm{P}(s_{1:n}) \mathrm{P}(x_{1:n})} \right\rangle_{\mathrm{P}(s_{1:n}, x_{1:n})}
\label{eq:trajectory_mi_sequence}</annotation></semantics></math>
</div>
<p> where the expected value is taken with respect to the full joint
probability of both sequences. This quantity can be interpreted as the
total information that is communicated via
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
transmissions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>i</mi></msub><mo>‚Ü¶</mo><msub><mi>X</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">S_i\mapsto X_i</annotation></semantics></math>.</p>
<p>Note that, unless the individual messages are independent, the total
amount of information communicated is not equal to the sum of the mutual
information between individual messages. Thus, in general </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>S</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>X</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>‚â†</mo><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>I</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>S</mi><mi>i</mi></msub><mo>,</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">I(S_{1:n},X_{1:n}) \neq \sum^n_{i=1} I(S_i, X_i) \,.</annotation></semantics></math>
<p> Intuitively, this makes sense. On one hand, auto-correlations within
the input or output sequences reduce the amount of information
transmitted per message such that the left term of the inequality may
become smaller than the right term. On the other hand, information can
be encoded in temporal features of the sequences, such that the left
term could become larger than the right term. These observations show
that generally the instantaneous mutual information
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>S</mi><mi>t</mi></msub><mo>,</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">I(S_t, X_t)</annotation></semantics></math>
at any given time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>
does not provide a meaningful measure of information flow, as has been
pointed out before <span class="citation"
data-cites="2021.Meijers 2024.Fan">¬†[<a href="#ref-2021.Meijers"
role="doc-biblioref">21</a>,<a href="#ref-2024.Fan"
role="doc-biblioref">40</a>]</span>. To correctly quantify the amount of
information transmitted per unit time we must take the whole sequence of
messages over time into account.</p>
<p>For that reason, the relevant performance measure for an information
processing system is the mutual information rate. Let the input and
output of an information processing system be given by two discrete-time
stochastic processes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùíÆ</mi><mo>=</mo><mo stretchy="false" form="prefix">{</mo><msub><mi>S</mi><mi>t</mi></msub><mo>‚à£</mo><mi>t</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi>‚Ä¶</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\mathcal{S}=\{S_t\mid t=1,2,\ldots\}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùí≥</mi><mo>=</mo><mo stretchy="false" form="prefix">{</mo><msub><mi>X</mi><mi>t</mi></msub><mo>‚à£</mo><mi>t</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi>‚Ä¶</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\mathcal{X}=\{X_t\mid t=1,2,\ldots\}</annotation></semantics></math>.
Then, the mutual information rate between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùíÆ</mi><annotation encoding="application/x-tex">\mathcal{S}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùí≥</mi><annotation encoding="application/x-tex">\mathcal{X}</annotation></semantics></math>
is </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo stretchy="false" form="prefix">(</mo><mi>ùíÆ</mi><mo>,</mo><mi>ùí≥</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><munder><mi>lim</mi><mrow><mi>t</mi><mo>‚Üí</mo><mi>‚àû</mi></mrow></munder><mfrac><mn>1</mn><mi>t</mi></mfrac><mi>I</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>S</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub><mo>,</mo><msub><mi>X</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">R(\mathcal{S}, \mathcal{X}) = \lim_{t\to\infty} \frac{1}{t} I(S_{1:t}, X_{1:t})\,.</annotation></semantics></math>
<p> The mutual information rate quantifies the amount of information
that can reliably be transmitted per unit time.</p>
<p>The definitions above however do not provide an obvious way of how to
compute the mutual information rate in practice. Path Weight Sampling is
a Monte Carlo estimator introduced recently for exactly computing the
mutual information between trajectories <span class="citation"
data-cites="2023.Reinhardt">¬†[<a href="#ref-2023.Reinhardt"
role="doc-biblioref">26</a>]</span>.</p>
<h3 id="path-weight-sampling">Path Weight Sampling</h3>
<p>In the previous chapters, we developed Path Weight Sampling, which
addresses many of the shortcomings of previous techniques for computing
the mutual information. PWS is an exact technique that supports
nonlinear systems and, in contrast to the Gaussian approximation,
correctly takes into account higher-order correlations that may be
present. Given a mechanistic model that describes the stochastic
dynamics of a system, PWS makes it possible to directly compute the
mutual information rate for this model.</p>
<p>PWS is based on the exact evaluation of conditional path
probabilities and requires that we have a model of the system as well as
its input statistics. Specifically, it has three requirements. To
compute the Monte Carlo estimate of the mutual information one needs
to</p>
<ol>
<li><p>sample from the input distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(s_{1:n})</annotation></semantics></math>,</p></li>
<li><p>sample from the conditional output distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n}|s_{1:n})</annotation></semantics></math>,
and</p></li>
<li><p>evaluate the conditional probability density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n}|s_{1:n})</annotation></semantics></math>,
i.e., the path weight.</p></li>
</ol>
<p>We thus require a model of the system, that describes how the output
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>
evolves stochastically for a given input sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">s_{1:n}</annotation></semantics></math>,
as well as a model that describes the stochastic input
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>‚àº</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">s_{1:n} \sim \mathrm{P}(s_{1:n})</annotation></semantics></math>
to the system. Note, that we only need an estimate of the probability
density for the output
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n}|s_{1:n})</annotation></semantics></math>,
but not for the input.</p>
<p>Given these models for input and output, the mutual information is
computed using a Monte Carlo estimate of <a
href="#eq:trajectory_mi_sequence">eq:trajectory_mi_sequence</a> </p>
<div id="eq:monte_carlo_information">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>I</mi><mrow><mi>M</mi><mi>C</mi></mrow></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>S</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>X</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mfrac><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msubsup><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mi>i</mi></msubsup><mo stretchy="false" form="prefix">|</mo><msubsup><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mi>i</mi></msubsup><mo stretchy="false" form="postfix">)</mo></mrow><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msubsup><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mi>i</mi></msubsup><mo stretchy="false" form="postfix">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">I_{MC}(S_{1:n}, X_{1:n}) = \frac{1}{N} \sum^N_{i=1} \ln \frac{\mathrm{P}(x^i_{1:n} | s^i_{1:n})}{\mathrm{P}(x^i_{1:n})}
\label{eq:monte_carlo_information}</annotation></semantics></math>
</div>
<p> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msubsup><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mn>1</mn></msubsup><mo>,</mo><msubsup><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mn>1</mn></msubsup><mo stretchy="false" form="postfix">)</mo><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mo stretchy="false" form="prefix">(</mo><msubsup><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mi>N</mi></msubsup><mo>,</mo><msubsup><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mi>N</mi></msubsup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(s^1_{1:n}, x^1_{1:n}), \ldots, (s^N_{1:n}, x^N_{1:n})</annotation></semantics></math>
are pairs of input-output trajectories that need to be drawn
independently from the full joint distribution of trajectories, given by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(s_{1:n}, x_{1:n})=\mathrm{P}(s_{1:n})\mathrm{P}(x_{1:n}|s_{1:n})</annotation></semantics></math>.
Such draws can be realized by first generating an input sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>‚àº</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">s_{1:n} \sim \mathrm{P}(s_{1:n})</annotation></semantics></math>,
and subsequently generating an output from the conditional model
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>‚àº</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">x_{1:n}\sim \mathrm{P}(x_{1:n}|s_{1:n})</annotation></semantics></math>.
As
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>‚Üí</mo><mi>‚àû</mi></mrow><annotation encoding="application/x-tex">N\to\infty</annotation></semantics></math>
this estimate converges to the true mutual information
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>S</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>X</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">I(S_{1:n}, X_{1:n})</annotation></semantics></math>,
making PWS an exact Monte Carlo scheme. <a
href="#eq:monte_carlo_information">Equation monte_carlo_information</a>
requires evaluating the conditional probability density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n} | s_{1:n})</annotation></semantics></math>,
as well as the marginal probability density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n})</annotation></semantics></math>
for a potentially large set of Monte Carlo samples. How to evaluate
these densities efficiently is the crux of PWS.</p>
<p>The first important observation is that we can typically directly
evaluate the conditional probability density of output sequences
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n} | s_{1:n})</annotation></semantics></math>
from the stochastic model of our system. For instance, suppose the
output model is given by a Langevin equation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>x</mi><mo accent="true">Ãá</mo></mover><mo>=</mo><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>s</mi><mo>,</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mi>œÉ</mi><mi>Œæ</mi><mo stretchy="false" form="prefix">(</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\dot x = f(x, s, t) + \sigma\xi(t)</annotation></semantics></math>
with delta-correlated unit white noise
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œæ</mi><mo stretchy="false" form="prefix">(</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\xi(t)</annotation></semantics></math>.
A discretized path
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>
sampled from the model, can be represented by the initial state
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mn>1</mn></msub><annotation encoding="application/x-tex">x_1</annotation></semantics></math>
and the sequence of random numbers
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>œµ</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>œµ</mi><mrow><mi>n</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>‚àº</mo><mi>ùí©</mi><mo stretchy="false" form="prefix">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\epsilon_1,\ldots,\epsilon_{n-1}\sim\mathcal{N}(0, 1)</annotation></semantics></math>
that were used to generate the path with a stochastic integration
scheme. The conditional probability density of the path can then be
written as </p>
<div id="eq:tractable_conditional">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mn>1</mn></msub><mo stretchy="false" form="postfix">)</mo><munderover><mo>‚àè</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><mo>‚àí</mo><mn>1</mn></mrow></munderover><mfrac><mn>1</mn><mrow><msqrt><mrow><mn>2</mn><mi>œÄ</mi></mrow></msqrt><mi>œÉ</mi></mrow></mfrac><mrow><mi>exp</mi><mo>&#8289;</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>‚àí</mi><msubsup><mi>œµ</mi><mi>i</mi><mn>2</mn></msubsup><mi>/</mi><mn>2</mn><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n}|s_{1:n}) = \mathrm{P}(x_1|s_1) \prod^{n-1}_{i=1} \frac{1}{\sqrt{2\pi}\sigma} \exp\left(- \epsilon_{i}^2 / 2 \right) \,.
    \label{eq:tractable_conditional}</annotation></semantics></math>
</div>
<p> A similar formula exists if the model is given by a master equation
<span class="citation"
data-cites="2019.Cepeda-Humerez 2023.Reinhardt">¬†[<a
href="#ref-2019.Cepeda-Humerez" role="doc-biblioref">20</a>,<a
href="#ref-2023.Reinhardt" role="doc-biblioref">26</a>]</span>, which is
based on the random numbers drawn in the Gillespie algorithm. There is
also a class of deep generative models with tractable probability
distributions. More generally, it is known that efficiently evaluating
the conditional probability density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n} | s_{1:n})</annotation></semantics></math>
of sequences is tractable for any autoregressive sequence model without
latent (unobserved) variables <span class="citation"
data-cites="1998.Frey">¬†[<a href="#ref-1998.Frey"
role="doc-biblioref">41</a>]</span>. In this chapter we will exclusively
deal with tractable conditional distributions, allowing us to evaluate
the numerator in <a
href="#eq:monte_carlo_information">eq:monte_carlo_information</a>.</p>
<p>Unfortunately, the for denominator of <a
href="#eq:monte_carlo_information">eq:monte_carlo_information</a>, i.e.,
the marginal probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n})</annotation></semantics></math>,
no simple formulae like <a
href="#eq:tractable_conditional">eq:tractable_conditional</a> typically
exist. Yet,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n})</annotation></semantics></math>
is required for the Monte Carlo estimate of the mutual information. The
only way of computing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n})</annotation></semantics></math>
exactly from the conditional probability density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n} | s_{1:n})</annotation></semantics></math>
is via marginalization over the input paths: </p>
<div id="eq:marginalization">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mo>‚à´</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mi>d</mi><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n}) = \int \mathrm{P}(x_{1:n} | s_{1:n}) \mathrm{P}(s_{1:n}) ds_{1:n} \,.
    \label{eq:marginalization}</annotation></semantics></math>
</div>
<p> In practice, directly evaluating this integral is typically
infeasible. A simple ‚Äúbrute force‚Äù Monte Carlo estimate of <a
href="#eq:marginalization">eq:marginalization</a> can be obtained by
sampling
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mn>1</mn></msubsup><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msubsup><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mi>M</mi></msubsup></mrow><annotation encoding="application/x-tex">s^1_{1:n}, \ldots, s^M_{1:n}</annotation></semantics></math>
from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(s_{1:n})</annotation></semantics></math>
and computing </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>‚âà</mo><mfrac><mn>1</mn><mi>M</mi></mfrac><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msubsup><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mi>i</mi></msubsup><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n}) \approx \frac{1}{M} \sum^M_{i=1} \mathrm{P}(x_{1:n} | s^i_{1:n}) \,.</annotation></semantics></math>
<p> For
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>‚Üí</mo><mi>‚àû</mi></mrow><annotation encoding="application/x-tex">M\to\infty</annotation></semantics></math>
this estimate converges to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n})</annotation></semantics></math>.
This direct Monte Carlo estimate forms the basis of <em>Direct PWS</em>,
the simplest variant of PWS, and can be sufficiently accurate for short
trajectories. However, due to the combinatorial explosion, the required
amount of samples
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>
to achieve an accurate result grows exponentially with trajectory
length, and thus for long trajectories the brute force estimate becomes
intractable. The problem is that for a given
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>
most of the density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n} | s_{1:n})</annotation></semantics></math>
will typically be concentrated in a very small region of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">s_{1:n}</annotation></semantics></math>-space.
Therefore, for longer trajectories more sophisticated Monte Carlo
samplers must be used to achieve good results. Two more powerful
variants of PWS were introduced in <a href="#ch:variants">Ch.
variants</a>.</p>
<p>While PWS is a powerful exact method to compute the mutual
information between trajectories, it cannot be applied directly to
experimental data. The need for a stochastic model that provides an
expression for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n} | s_{1:n})</annotation></semantics></math>
represents the most significant challenge for the use of PWS in
practice. In many cases, a detailed mechanistic or phenomenological
model of the experimental system is not available. To overcome this
problem, we learn a stochastic model from data which can then be used in
combination with PWS to compute the mutual information rate directly
from experimental time series data.</p>
<h3
id="autoregressive-neural-networks-for-stochastic-sequence-modeling">Autoregressive
neural networks for stochastic sequence modeling</h3>
<p>For computing the mutual information between trajectories using PWS,
we require a generative sequence model that specifies the stochastic
dynamics of the input-output mapping. We assume that the input
distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(s_{1:n})</annotation></semantics></math>
is known and can be sampled from. In experimental practice, we often
have control over the input that is delivered to the system. The
challenge is thus in accurately modeling the unknown stochastic dynamics
of the system.</p>
<p>Hence, we require a model which, given an input sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>=</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>s</mi><mi>n</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">s_{1:n}=(s_1,\ldots,s_n)</annotation></semantics></math>,
models the statistics of the stochastic output sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>=</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">x_{1:n}=(x_1,\ldots,x_n)</annotation></semantics></math>,
i.e., we want a generative model for the distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo>‚à£</mo><msub><mi>s</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>s</mi><mi>n</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>‚à£</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_1,\ldots,x_n \mid s_1,\ldots,s_n) = \mathrm{P}(x_{1:n} \mid s_{1:n})</annotation></semantics></math>.
However, for large
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
the space of multivariate distributions in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>
is vast, and we need to make simplifying assumptions to be able to fit a
stochastic model to observed data. We develop a trainable machine
learning model to obtain a generative sequence model from experimental
data that meets the requirements for using PWS.</p>
<p>We can factorize the joint probability of a sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>
as </p>
<div id="eq:sequence_factorization">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>‚à£</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><munderover><mo>‚àè</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>‚à£</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mo>,</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n} \mid s_{1:n}) = \prod_{i=1}^n \mathrm{P}(x_i \mid x_{1:i-1}, s_{1:n}) \,,
    \label{eq:sequence_factorization}</annotation></semantics></math>
</div>
<p> i.e., the stochastic dynamics are fully specified by the conditional
stepping probabilities. Note that in a physical system obeying
causality, the output
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>
cannot depend on future inputs. Thus, we can simplify <a
href="#eq:sequence_factorization">eq:sequence_factorization</a> to </p>
<div id="eq:causal_sequence_factorization">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>‚à£</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><munderover><mo>‚àè</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>‚à£</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n} \mid s_{1:n}) = \prod_{i=1}^n \mathrm{P}(x_i \mid x_{1:i-1}, s_{1:i}) \,.
    \label{eq:causal_sequence_factorization}</annotation></semantics></math>
</div>
<p>A common approach for modeling stochastic sequences is to assume
Markov statistics, meaning each element depends only on its immediate
predecessor, simplifying the conditional to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>‚à£</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>‚à£</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{i} \mid x_{1:i-1}, s_{1:i}) = \mathrm{P}(x_{i} \mid x_{i-1}, s_i)</annotation></semantics></math>.
In the case of a stationary system, the transition probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>‚à£</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{i} \mid x_{i-1}, s_i)</annotation></semantics></math>
is the same for all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>,
such that only one scalar distribution needs to be specified to define
the Markovian process. While this assumption significantly reduces the
complexity of the distribution space, Markov models are severely limited
in that they cannot accurately model sequences with long-range
dependencies or feedback. Yet, these non-Markovian features are often
crucial to describe physical or biological processes.</p>
<p>Hence, we use a more general approach to directly learn <a
href="#eq:causal_sequence_factorization">eq:causal_sequence_factorization</a>
and parameterize the probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>‚à£</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_i \mid x_{1:i-1}, s_{1:i})</annotation></semantics></math>
at each time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
using neural networks. These models are called <em>autoregressive
models</em> and have been used for modeling the probability distribution
of sequential data in a large variety of contexts <span class="citation"
data-cites="2011.Sutskever 2013.Graves 2014.Bayer 2016.Oord">¬†[<a
href="#ref-2016.Oord" role="doc-biblioref">37</a>,<a
href="#ref-2011.Sutskever" role="doc-biblioref">38</a>,<a
href="#ref-2013.Graves" role="doc-biblioref">42</a>,<a
href="#ref-2014.Bayer" role="doc-biblioref">43</a>]</span>. To
efficiently model a sequence, we need to make two main choices:
(a)¬†which parametric family of distributions to use for modeling each
conditional probability, and (b)¬†which neural network architecture to
use for obtaining the parameters for the chosen family of distributions,
at each time.</p>
<h4 id="gaussian-autoregressive-model">Gaussian autoregressive
model</h4>
<p>The choice of the parametric family of distributions depends on the
nature of the data. For example, for scalar continuous data, a Gaussian
distribution might be appropriate, whereas for discrete data, a
categorical distribution is more suitable. More complex data might
require richer distributional families, such as autoregressive flows or
variational approaches, which allow for more flexible modeling of
dependencies between sequence elements. For this chapter, we assume that
the experimental data is scalar and continuous and can be sufficiently
well modeled by Gaussian conditional distributions.</p>
<p>Hence, we consider an autoregressive model where each conditional
distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>‚à£</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_i \mid x_{1:i-1}, s_{1:i})</annotation></semantics></math>
is Gaussian. For
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">i=1,\ldots,n</annotation></semantics></math>,
the model uses a neural network to predict the mean
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œº</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mu_i(x_{1:i-1}, s_{1:i})</annotation></semantics></math>
and standard deviation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>œÉ</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\sigma_i(x_{1:i-1}, s_{1:i})</annotation></semantics></math>
of the current sequence element
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>,
given the previous elements. Thus, conditional on the input and its
predecessors, the variable
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>
is normal distributed, with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi>ùí©</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>Œº</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>,</mo><msub><mi>œÉ</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_i | x_{1:i-1}, s_{1:i}) = \mathcal{N}(\mu_i(x_{1:i-1}, s_{1:i}), \sigma_i(x_{1:i-1}, s_{1:i}))</annotation></semantics></math>.
The functions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œº</mi><mi>i</mi></msub><mo>:</mo><msup><mi>‚Ñù</mi><mrow><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msup><mo>‚Üí</mo><mi>‚Ñù</mi></mrow><annotation encoding="application/x-tex">\mu_i: \mathbb{R}^{i-1}\to \mathbb{R}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>œÉ</mi><mi>i</mi></msub><mo>:</mo><msup><mi>‚Ñù</mi><mrow><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msup><mo>‚Üí</mo><msup><mi>‚Ñù</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">\sigma_i: \mathbb{R}^{i-1}\to \mathbb{R}^+</annotation></semantics></math>
are implemented as neural networks and trained from experimental
data.</p>
<p>Importantly, while each conditional distribution is Gaussian, the
whole sequence is not Gaussian due to the nonlinear nature of the neural
network. This means that Gaussian autoregressive models are a
generalization of regular multivariate Gaussian models. In fact, a
Gaussian autoregressive model can learn arbitrarily complex nonlinear
relationships between the individual elements of a sequence, where the
complexity is only limited by the neural network architecture. In
contrast, a Gaussian model can only describe linear correlations between
different sequence elements. Various neural network architectures can be
used to implement the nonlinear functions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œº</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\mu_i</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>œÉ</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\sigma_i</annotation></semantics></math>,
and the choice must be made depending on the amount of training data,
the complexity of the input-output mapping, as well as computational
constraints.</p>
<h4 id="network-architecture">Network architecture</h4>
<p>The network architecture is crucial because it directly determines
the number of neural network parameters (or weights) that need to be
learned. This, in turn, affects both the flexibility of the model and
the computational efficiency of training and inference. A more flexible
architecture, with a larger number of weights, can potentially capture
more complex relationships in the data but comes with the tradeoff of
increased computational cost and the risk of overfitting.</p>
<p>In principle, for modeling a sequence of length
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>,
learning an autoregressive sequence model would require training
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
separate neural networks, one for each conditional distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>‚à£</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_i \mid x_{1:i-1}, s_{1:n})</annotation></semantics></math>,
with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">i=1,\ldots,n</annotation></semantics></math>.
In practice, shared weights can drastically reduce the number of
parameters to be learned. If the sequence is stationary or has other
types of periodic features, the neural networks corresponding to
different time steps can often share a majority, if not all, of their
weights. This drastically simplifies training and evaluation of the
autoregressive model.</p>
<figure id="fig:ML_autoregressive_model">
<img src="../images/ML_autoregressive_model.svg"  />
<figcaption>Two possible network architectures for autoregressive
sequence models. In both cases, the next output
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>
is sampled from a Gaussian distribution with parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msub><mi>Œº</mi><mi>i</mi></msub><mo>,</mo><msub><mi>œÉ</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(\mu_i, \sigma_i)</annotation></semantics></math>
which the neural network computes from the history
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mn>0</mn><mo>:</mo><mi>i</mi></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mn>0</mn><mo>:</mo><mrow><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></mrow></msub></mrow><annotation encoding="application/x-tex">s_{0:i}, x_{0:{i-1}}</annotation></semantics></math>.</figcaption>
</figure>
<p>We discuss two neural network architectures (schematically in <a
href="#fig:ML_autoregressive_model">Fig. ML_autoregressive_model</a>)
that are widely used for stochastic sequence prediction and make use of
weight-sharing to reduce computational costs: recurrent neural networks
(RNNs) and autoregressive convolutional neural networks (CNNs). Other
sequence models like transformer models <span class="citation"
data-cites="2017.Vaswani 2018.Devlin">¬†[<a href="#ref-2017.Vaswani"
role="doc-biblioref">44</a>,<a href="#ref-2018.Devlin"
role="doc-biblioref">45</a>]</span> could similarly be used but are not
presented here.</p>
<h5 id="recurrent-neural-networks">Recurrent neural networks</h5>
<p>Recurrent Neural Networks (RNNs) process sequential data while
maintaining a hidden state that evolves over time. At each time step, an
RNN takes the current input and the previous hidden state to produce an
output and update the hidden state. This mechanism allows the network to
store relevant information about past inputs in the hidden state,
effectively creating a form of memory. This makes the use of RNNs
attractive for generic autoregressive sequence prediction models.</p>
<p>Given the sequences
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">s_{1:n}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>
the RNN takes an initial state
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>0</mn></msub><mo>‚àà</mo><msup><mi>‚Ñù</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">h_0\in\mathbb{R}^d</annotation></semantics></math>
and generates a sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>=</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>h</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>h</mi><mi>n</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">h_{1:n}=(h_1,\ldots,h_n)</annotation></semantics></math>
from a recursive relation </p>
<div id="eq:recursion">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub><mo>=</mo><msub><mi>f</mi><mi>Œ∏</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>h</mi><mrow><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">h_i = f_\theta(s_i, x_{i-1}, h_{i-1})
    \label{eq:recursion}</annotation></semantics></math>
</div>
<p> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub><mo>‚àà</mo><msup><mi>‚Ñù</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">h_i\in\mathbb{R}^d</annotation></semantics></math>
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>‚àà</mo><mo stretchy="false" form="prefix">{</mo><mn>1</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>n</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">i\in\{1,\ldots,n\}</annotation></semantics></math>
and an activation function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mi>Œ∏</mi></msub><annotation encoding="application/x-tex">f_\theta</annotation></semantics></math>.
The activation function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mi>Œ∏</mi></msub><annotation encoding="application/x-tex">f_\theta</annotation></semantics></math>
could for instance be parameterized by a simple neural network layer
</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>Œ∏</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>x</mi><mo>,</mo><mi>h</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mrow><mi>tanh</mi><mo>&#8289;</mo></mrow><mo stretchy="false" form="prefix">(</mo><mi>U</mi><mi>s</mi><mo>+</mo><mi>V</mi><mi>x</mi><mo>+</mo><mi>W</mi><mi>h</mi><mo>+</mo><mi>b</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">f_\theta(s, x, h) = \tanh(U s + V x + W h + b)</annotation></semantics></math>
<p> with parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ∏</mi><mo>=</mo><mo stretchy="false" form="prefix">(</mo><mi>U</mi><mo>‚àà</mo><msup><mi>‚Ñù</mi><mrow><mi>d</mi><mo>√ó</mo><mn>1</mn></mrow></msup><mo>,</mo><mi>V</mi><mo>‚àà</mo><msup><mi>‚Ñù</mi><mrow><mi>d</mi><mo>√ó</mo><mn>1</mn></mrow></msup><mo>,</mo><mi>W</mi><mo>‚àà</mo><msup><mi>‚Ñù</mi><mrow><mi>d</mi><mo>√ó</mo><mi>d</mi></mrow></msup><mo>,</mo><mi>b</mi><mo>‚àà</mo><msup><mi>‚Ñù</mi><mi>d</mi></msup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\theta = (U\in\mathbb{R}^{d\times 1}, V\in\mathbb{R}^{d\times 1}, W\in\mathbb{R}^{d\times d}, b\in\mathbb{R}^{d})</annotation></semantics></math>
and applying
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>tanh</mi><annotation encoding="application/x-tex">\tanh</annotation></semantics></math>
elementwise. Other possible choices for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mi>Œ∏</mi></msub><annotation encoding="application/x-tex">f_\theta</annotation></semantics></math>
include LSTM units <span class="citation"
data-cites="1997.Hochreiter">¬†[<a href="#ref-1997.Hochreiter"
role="doc-biblioref">46</a>]</span> or GRU units <span class="citation"
data-cites="2014.Cho">¬†[<a href="#ref-2014.Cho"
role="doc-biblioref">47</a>]</span> which often allow the model to
better learn long-term dependencies.</p>
<p>From the RNN we can obtain a stochastic representation of the output
sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>.
We extend the recursive relation above by adding a sampling step to
obtain
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>
from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>h</mi><mi>i</mi></msub><annotation encoding="application/x-tex">h_i</annotation></semantics></math>
</p>
<div id="eq:recursion-2">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"><msub><mi>x</mi><mi>i</mi></msub><mo>‚à£</mo><msub><mi>h</mi><mi>i</mi></msub></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>‚àº</mo><mi>ùí©</mi><mo stretchy="false" form="prefix">(</mo><mi>Œº</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>h</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>,</mo><mi>œÉ</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>h</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="postfix">)</mo></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
        % h_i &amp;= f_\theta(s_i, x_{i-1}, h_{i-1}) \\
        x_i \mid h_i &amp;\sim \mathcal{N}(\mu(h_i), \sigma(h_i))
\end{aligned}
\label{eq:recursion-2}</annotation></semantics></math>
</div>
<p> such that each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>
is a normal-distributed random variable whose mean
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œº</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>h</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mu(h_i)</annotation></semantics></math>
and standard deviation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œÉ</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>h</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\sigma(h_i)</annotation></semantics></math>
are computed from the current hidden state
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>h</mi><mi>i</mi></msub><annotation encoding="application/x-tex">h_i</annotation></semantics></math>.
In practice we use the following form for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œº</mi><annotation encoding="application/x-tex">\mu</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œÉ</mi><annotation encoding="application/x-tex">\sigma</annotation></semantics></math>
</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"><mi>Œº</mi><mo stretchy="false" form="prefix">(</mo><mi>h</mi><mo stretchy="false" form="postfix">)</mo></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><msub><mi>W</mi><mi>Œº</mi></msub><mi>h</mi><mo>+</mo><msub><mi>b</mi><mi>Œº</mi></msub></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"><mi>œÉ</mi><mo stretchy="false" form="prefix">(</mo><mi>h</mi><mo stretchy="false" form="postfix">)</mo></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><mrow><mi>exp</mi><mo>&#8289;</mo></mrow><mo stretchy="false" form="prefix">(</mo><msub><mi>W</mi><mi>œÉ</mi></msub><mi>h</mi><mo>+</mo><msub><mi>b</mi><mi>œÉ</mi></msub><mo stretchy="false" form="postfix">)</mo></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
    \mu(h) &amp;= W_\mu h + b_\mu \\
    \sigma(h) &amp;= \exp (W_\sigma h + b_\sigma)
\end{aligned}</annotation></semantics></math>
<p> where the weights
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mi>Œº</mi></msub><annotation encoding="application/x-tex">W_\mu</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mi>œÉ</mi></msub><annotation encoding="application/x-tex">W_\sigma</annotation></semantics></math>
are
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>d</mi><annotation encoding="application/x-tex">d</annotation></semantics></math>-dimensional
row vectors and the exponential function ensures that the standard
deviation is always positive. We denote the combination of all neural
network parameters by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùúΩ</mi><mo>=</mo><mo stretchy="false" form="prefix">(</mo><mi>Œ∏</mi><mo>,</mo><msub><mi>W</mi><mi>Œº</mi></msub><mo>,</mo><msub><mi>b</mi><mi>m</mi></msub><mi>u</mi><mo>,</mo><msub><mi>W</mi><mi>œÉ</mi></msub><mo>,</mo><msub><mi>b</mi><mi>œÉ</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathbfit{\theta} = (\theta, W_\mu, b_mu, W_\sigma, b_\sigma)</annotation></semantics></math>.</p>
<p>The recursive relations¬† fully define the conditional probability
distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><mi>ùúΩ</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">P(x_{1:n}|s_{1:n},\mathbfit{\theta})</annotation></semantics></math>
of the output sequence given the input sequence. Since
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>h</mi><mi>i</mi></msub><annotation encoding="application/x-tex">h_i</annotation></semantics></math>
depends on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>s</mi><mi>i</mi></msub><annotation encoding="application/x-tex">s_i</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">x_{i-1}</annotation></semantics></math>,
as well as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>h</mi><mrow><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">h_{i-1}</annotation></semantics></math>,
it encodes information about the entire past
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><annotation encoding="application/x-tex">s_{1:i}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">x_{1:i-1}</annotation></semantics></math>.
Therefore, the model can incorporate long-range information for
predicting the next output.</p>
<h5 id="convolutional-neural-networks">Convolutional neural
networks</h5>
<p>Autoregressive convolutional networks model sequential data using
masked 1D-convolutions. The masking ensures that the prediction at each
time step only depends on the current and preceding elements of the
sequence, maintaining causality. Unlike RNNs, which process sequences
one time step at a time, CNNs can efficiently compute representations of
the entire sequence in parallel, leading to substantial improvements in
computational speed. This parallelism is particularly advantageous when
working with long sequences. The architecture we describe here is
inspired by MADE <span class="citation"
data-cites="2017.Papamakarios">¬†[<a href="#ref-2017.Papamakarios"
role="doc-biblioref">48</a>]</span>, as well as PixelCNN <span
class="citation" data-cites="2016.Oord">¬†[<a href="#ref-2016.Oord"
role="doc-biblioref">37</a>]</span>.</p>
<p>The autoregressive CNN processes the data by applying a series of
masked convolutional layers. At time step
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>,
the CNN predicts the Gaussian parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œº</mi><mi>i</mi></msub><mo>,</mo><msub><mi>œÉ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mu_i, \sigma_i</annotation></semantics></math>
which describe the conditional
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>‚à£</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_i\mid s_{1:i}, x_{1:i-1})</annotation></semantics></math>.
The mask is applied to each convolutional layer and restricts
connections to only inputs in the past, or previously predicted outputs,
i.e., non-causal connections are masked out by setting their weights to
zero. The output of the first convolutional layer at time step
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
depends on the local receptive field
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mi>i</mi><mo>‚àí</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>‚àí</mo><mi>k</mi><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(s_{i-k+1:i}, x_{i-k:i-1})</annotation></semantics></math>
of the input and output sequences, where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
is the kernel size, i.e., </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub><mo>=</mo><msub><mi>f</mi><mi>Œ∏</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mi>i</mi><mo>‚àí</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>‚àí</mo><mi>k</mi><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">h_i = f_\theta(s_{i-k+1:i}, x_{i-k:i-1})</annotation></semantics></math>
<p> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mi>Œ∏</mi></msub><annotation encoding="application/x-tex">f_\theta</annotation></semantics></math>
represents the 1D convolutional operation with learnable parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>.
The operation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mi>Œ∏</mi></msub><annotation encoding="application/x-tex">f_\theta</annotation></semantics></math>
is composed of a set of learned convolutional filters and a non-linear
activation function such as ReLU. Unlike for a RNN
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>h</mi><mi>i</mi></msub><annotation encoding="application/x-tex">h_i</annotation></semantics></math>
is not computed via a recursive relation since
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>h</mi><mi>i</mi></msub><annotation encoding="application/x-tex">h_i</annotation></semantics></math>
does not depend on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>h</mi><mrow><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">h_{i-1}</annotation></semantics></math>.
Thus, we need a different mechanism to capture long-range
dependencies.</p>
<p>Typically we apply multiple convolutional layers in series. This
enables the model to capture long-range dependencies beyond the kernel
size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
in the input sequence, as the depth of the network increases the
temporal span of the receptive field. Moreover, stacking convolutional
layers with non-linear activation functions allows the model to learn
more complex representations of the data, potentially improving the
accuracy of the model.</p>
<p>To generate the output sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>,
we add a sampling step similar to the RNN case. Specifically, the output
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>
at each time step is sampled from a distribution parameterized by the
corresponding output from the CNN
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>h</mi><mi>i</mi></msub><annotation encoding="application/x-tex">h_i</annotation></semantics></math>:
</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>‚à£</mo><msub><mi>h</mi><mi>i</mi></msub><mo>‚àº</mo><mi>ùí©</mi><mo stretchy="false" form="prefix">(</mo><mi>Œº</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>h</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>,</mo><mi>œÉ</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>h</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">x_i \mid h_i \sim \mathcal{N}(\mu(h_i), \sigma(h_i))</annotation></semantics></math>
<p> The resulting conditional probability distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>œÅ</mi><mi>ùõâ</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\rho_{\symbf\theta}(x_{1:n}|s_{1:n})</annotation></semantics></math>
is fully defined by the convolution weights
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùõâ</mi><annotation encoding="application/x-tex">\symbf\theta</annotation></semantics></math>
and the sampling step.</p>
<h4 id="evaluating-and-training-the-network">Evaluating and training the
network</h4>
<p>The autoregressive neural network described above can be viewed as
generative models that approximate the conditional distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n}|s_{1:n})</annotation></semantics></math>,
i.e., we can use them to draw independent samples from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>œÅ</mi><mi>ùõâ</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>‚âà</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\rho_{\symbf\theta}(x_{1:n}|s_{1:n}) \approx\mathrm{P}(x_{1:n}|s_{1:n})</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùúΩ</mi><annotation encoding="application/x-tex">\mathbfit{\theta}</annotation></semantics></math>
represents the network weights. Generating
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>
given
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">s_{1:n}</annotation></semantics></math>
is done sequentially. For
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">i=1,\ldots,n</annotation></semantics></math>,
the sampling procedure alternates between computing the parameters of
the conditional distribution,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>Œº</mi><mo accent="true">ÃÇ</mo></mover><mi>i</mi></msub><mo>=</mo><msub><mi>Œº</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\hat{\mu}_i = \mu_i(x_{1:i-1}, s_{1:i})</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>œÉ</mi><mo accent="true">ÃÇ</mo></mover><mi>i</mi></msub><mo>=</mo><msub><mi>œÉ</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\hat{\sigma}_i = \sigma_i(x_{1:i-1}, s_{1:i})</annotation></semantics></math>,
and sampling the next
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>‚àº</mo><mi>ùí©</mi><mo stretchy="false" form="prefix">(</mo><msub><mover><mi>Œº</mi><mo accent="true">ÃÇ</mo></mover><mi>i</mi></msub><mo>,</mo><msub><mover><mi>œÉ</mi><mo accent="true">ÃÇ</mo></mover><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">x_i \sim \mathcal{N}(\hat{\mu}_i, \hat{\sigma}_i)</annotation></semantics></math>.</p>
<p>The conditional probability of the resulting output sequence is given
by </p>
<div id="eq:autoregressive_conditional_density">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"><msub><mi>œÅ</mi><mi>ùõâ</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><munderover><mo>‚àè</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub><mo>,</mo><mi>ùúΩ</mi><mo stretchy="false" form="postfix">)</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><munderover><mo>‚àè</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mfrac><mn>1</mn><mrow><msqrt><mrow><mn>2</mn><mi>œÄ</mi></mrow></msqrt><msub><mover><mi>œÉ</mi><mo accent="true">ÃÇ</mo></mover><mi>i</mi></msub></mrow></mfrac><mrow><mi>exp</mi><mo>&#8289;</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>‚àí</mi><mfrac><mrow><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>‚àí</mo><msub><mover><mi>Œº</mi><mo accent="true">ÃÇ</mo></mover><mi>i</mi></msub><msup><mo stretchy="false" form="postfix">)</mo><mn>2</mn></msup></mrow><mrow><mn>2</mn><msubsup><mover><mi>œÉ</mi><mo accent="true">ÃÇ</mo></mover><mi>i</mi><mn>2</mn></msubsup></mrow></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
    \rho_{\symbf\theta}(x_{1:n}|s_{1:n}) &amp;= \prod^n_{i=1} \mathrm{P}(x_i|x_{1:t-1}, s_{1:t}, \mathbfit{\theta})\\
    &amp;= \prod^n_{i=1} \frac{1}{\sqrt{2\pi}\hat{\sigma}_i} \exp\left(-\frac{(x_i-\hat{\mu}_i)^2}{2\hat{\sigma}^2_i}\right)\,.
\end{aligned}
\label{eq:autoregressive_conditional_density}</annotation></semantics></math>
</div>
<p> This probability can be evaluated on the fly while generating the
sequence. Moreover, for a given pair of input and output sequences, we
can also use the model to directly evaluate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>œÅ</mi><mi>ùõâ</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\rho_{\symbf\theta}(x_{1:n}|s_{1:n})</annotation></semantics></math>
which is required for PWS. Note that in practice, to numerically
accurately compute a product with many terms it is typically necessary
to perform the computation in log space.</p>
<p>Note that while generating a sequence is inherently a sequential
process, the path likelihood
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>œÅ</mi><mi>ùõâ</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\rho_{\symbf\theta}(x_{1:n}|s_{1:n})</annotation></semantics></math>
can be evaluated in parallel in some neural architectures like the CNN.
Specifically, for a given pair of sequences
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(s_{1:n}, x_{1:n})</annotation></semantics></math>,
the conditional probability in <a
href="#eq:autoregressive_conditional_density">eq:autoregressive_conditional_density</a>
is parallelizable, since the computations for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>Œº</mi><mo accent="true">ÃÇ</mo></mover><mi>i</mi></msub><annotation encoding="application/x-tex">\hat\mu_i</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>œÉ</mi><mo accent="true">ÃÇ</mo></mover><mi>i</mi></msub><annotation encoding="application/x-tex">\hat\sigma_i</annotation></semantics></math>
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">i=1,\ldots,n</annotation></semantics></math>
are independent of each other. This allows for efficient training on
parallel computing hardware.</p>
<p>To train the model, we minimize the negative log likelihood of its
predictions when evaluated on the training data. Specifically, we assume
that the training data consists of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
pairs of sequences
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msubsup><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mi>k</mi></msubsup><mo>,</mo><msubsup><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mi>k</mi></msubsup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(s^k_{1:n}, x^k_{1:n})</annotation></semantics></math>
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">k=1,\ldots,N</annotation></semantics></math>.
The loss function to be minimized is then given by the sum of the
individual negative log likelihoods for the trajectory pairs: </p>
<div id="eq:loss_function">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>‚Ñí</mi><mo stretchy="false" form="prefix">(</mo><mi>ùúΩ</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi>‚àí</mi><munderover><mo>‚àë</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><msub><mi>œÅ</mi><mi>ùõâ</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">\mathcal{L}(\mathbfit{\theta}) = -\sum^N_{k=1} \ln \rho_{\symbf\theta}(x_{1:n}|s_{1:n}) \,.
    \label{eq:loss_function}</annotation></semantics></math>
</div>
<p> This training objective is equivalent to minimizing an empirical
estimate of the Kullback-Leibler (KL) divergence between the
distribution of the training data and the distribution defined by the
model, thus training the model to fit the underlying data distribution
<span class="citation" data-cites="2006.Bishop">¬†[<a
href="#ref-2006.Bishop" role="doc-biblioref">49</a>]</span>.</p>
<p>There are a few practical considerations for efficiently training the
model. Training is performed in iterations and it is often beneficial to
introduce stochasticity between iterations to speed up gradient descent
and regularize the loss function to prevent overfitting <span
class="citation" data-cites="2010.Bottou 2021.Feng">¬†[<a
href="#ref-2010.Bottou" role="doc-biblioref">50</a>,<a
href="#ref-2021.Feng" role="doc-biblioref">51</a>]</span>. For this
reason, as typically done for training neural networks, the loss
function in <a href="#eq:loss_function">eq:loss_function</a> is only
computed for a subset of the training data, in mini-batches of size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>,
instead of the whole training set of size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>.
At the beginning of each iteration, the data subset that is used is
randomly selected (without replacement) from the whole data set.</p>
<h3 id="sec:ml_variational">Efficient Marginalization Using Variational
Inference</h3>
<p>In the preceding section, we have shown how machine learning
techniques can be leveraged to obtain a Path Weight Sampling (PWS)
estimate of the mutual information rate directly from empirical data. By
employing machine learning algorithms to learn the underlying stochastic
model of the data, we enable accurate computation of the mutual
information rate using the PWS framework.</p>
<p>In this section, we employ machine learning differently, to optimize
the PWS method itself. Specifically, we address the computationally most
demanding task: the evaluation of the marginalization integral. While we
have presented alternative techniques for computing this integral in <a
href="#ch:dpws">Ch. dpws</a> and <a href="#ch:variants">Ch.
variants</a>, here we leverage recent advances in machine learning and
introduce an efficient marginalization strategy based on variational
inference.</p>
<p>The idea of the variational marginalization procedure is to train a
second neural network, the <em>inference model</em>, that parameterizes
an importance sampling distribution over
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">s_{1:n}</annotation></semantics></math>
to enable the efficient computation of the marginal probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n})</annotation></semantics></math>.
This inference model, often referred to as the backward model, operates
in reverse directionality to the actual system, i.e., it generates an
input given an output. This is in contrast to the previous section,
which focused on generative models for the output
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>
given the input sequence, governed by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n}|s_{1:n})</annotation></semantics></math>.
Roughly, the inference network takes an output trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>
and generates input trajectories
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">s_{1:n}</annotation></semantics></math>
that could have likely produced the corresponding output. When this
network is used as an importance sampler, we can significantly
accelerate the computation of the marginal probability and thus the
mutual information. We denote the inference model‚Äôs generative
distribution as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">q(s_{1:n}|x_{1:n})</annotation></semantics></math>.</p>
<p>To compute the marginal probability with help of the inference model,
we write
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n})</annotation></semantics></math>
as the expectation with respect to a probability density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">q(s_{1:n}|x_{1:n})</annotation></semantics></math>,
i.e., </p>
<div id="eq:ml_importance_sampling">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><mo>‚à´</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>d</mi><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><msub><mi>ùîº</mi><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow></msub><mrow><mo stretchy="true" form="prefix">[</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="true" form="postfix">]</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><msub><mi>ùîº</mi><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow></msub><mrow><mo stretchy="true" form="prefix">[</mo><mfrac><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow></mfrac><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="true" form="postfix">]</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><msub><mi>ùîº</mi><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow></msub><mrow><mo stretchy="true" form="prefix">[</mo><mfrac><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow></mfrac><mo stretchy="true" form="postfix">]</mo></mrow></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
    \mathrm{P}(x_{1:n}) 
    &amp;= \int \mathrm{P}(x_{1:n}|s_{1:n})\mathrm{P}(s_{1:n})\,ds_{1:n}\\
    &amp;=\mathbb{E}_{\mathrm{P}(s_{1:n})} \left[\mathrm{P}(x_{1:n}|s_{1:n})\right]\\
    &amp;= \mathbb{E}_{\mathrm{P}(s_{1:n})} \left[ \frac{\mathrm{P}(x_{1:n}|s_{1:n})}{q(s_{1:n}|x_{1:n})} 
 q(s_{1:n}|x_{1:n})\right]\\
    &amp;= \mathbb{E}_{q(s_{1:n}|x_{1:n})} \left[ \frac{\mathrm{P}(s_{1:n})\mathrm{P}(x_{1:n}|s_{1:n})}{q(s_{1:n}|x_{1:n})} \right] 
\end{aligned}
    \label{eq:ml_importance_sampling}</annotation></semantics></math>
</div>
<p> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">q(s_{1:n}|x_{1:n})</annotation></semantics></math>
can be chosen arbitrarily in principle. <a
href="#eq:ml_importance_sampling">Equation ml_importance_sampling</a> is
estimated using Monte Carlo sampling, by using the inference network to
generate a set of trajectories
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><msubsup><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mn>1</mn></msubsup><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msubsup><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mi>M</mi></msubsup><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{s^1_{1:n},\ldots,s^M_{1:n}\}</annotation></semantics></math>
from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">q(s_{1:n}|x_{1:n})</annotation></semantics></math>
and computing the respective importance weights
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>w</mi><mi>M</mi></msub></mrow><annotation encoding="application/x-tex">w_1,\ldots,w_M</annotation></semantics></math>
according to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>k</mi></msub><mo>=</mo><mi>w</mi><mo stretchy="false" form="prefix">(</mo><msubsup><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mi>k</mi></msubsup><mo>,</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">w_k = w(s^k_{1:n}, x_{1:n})</annotation></semantics></math>
where </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mfrac><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow></mfrac><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">w(s_{1:n}, x_{1:n}) = \frac{\mathrm{P}(s_{1:n})\mathrm{P}(x_{1:n}|s_{1:n})}{q(s_{1:n}|x_{1:n})} \,.</annotation></semantics></math>
<p> The marginal probability is then estimated by </p>
<div id="eq:ml_importance_sample_mc">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>‚âà</mo><mfrac><mn>1</mn><mi>M</mi></mfrac><munderover><mo>‚àë</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><msub><mi>w</mi><mi>k</mi></msub><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n}) \approx \frac{1}{M} \sum^M_{k=1} w_k \,.
    \label{eq:ml_importance_sample_mc}</annotation></semantics></math>
</div>
<p> In this process,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">q(s_{1:n}|x_{1:n})</annotation></semantics></math>
serves as the importance sampling distribution. Regardless of the choice
of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">q(s_{1:n}|x_{1:n})</annotation></semantics></math>,
this estimate always converges to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n})</annotation></semantics></math>
in the limit
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>‚Üí</mo><mi>‚àû</mi></mrow><annotation encoding="application/x-tex">M\to\infty</annotation></semantics></math>.
However, crucially, for finite
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>
the choice of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">q(s_{1:n}|x_{1:n})</annotation></semantics></math>
determines the variance and thus efficiency of the estimate.</p>
<p>If, as done in Direct PWS (<a href="#ch:dpws">Ch. dpws</a>), we
choose the ‚Äúprior‚Äù probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(s_{1:n})</annotation></semantics></math>
as the importance sampling distribution, the resulting estimate is
typically highly inefficient. This is because with that choice the
importance weights are usually very unevenly distributed, with heavy
tails which significantly increases the variance of the estimator, see
also <a href="#ch:variants">Ch. variants</a>. It is well-known that the
prior is generally a poor importance sampling distribution since it
often allocates significant probability mass to regions of the
configuration space that contribute little to the likelihood <span
class="citation" data-cites="1976.Bennett 1989.Geweke">¬†[<a
href="#ref-1976.Bennett" role="doc-biblioref">52</a>,<a
href="#ref-1989.Geweke" role="doc-biblioref">53</a>]</span>. The
hypothetical optimal choice for the importance sampling distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">q(s_{1:n}|x_{1:n})</annotation></semantics></math>
is the true ‚Äúposterior‚Äù distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(s_{1:n} | x_{1:n})</annotation></semantics></math>,
as this makes the importance weights constant, resulting in a
theoretically zero variance estimator. However, since the true posterior
is typically intractable, we instead aim to approximate the posterior by
a tractable distribution, to reduce the variance as much as
possible.</p>
<p>The idea of variational inference is to train the inference model
using a loss function that minimizes the Kullback-Leibler
(KL-)divergence between the variational distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">q(s_{1:n}|x_{1:n})</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(s_{1:n} | x_{1:n})</annotation></semantics></math>.
Since the KL-divergence is always non-negative, and is only exactly zero
if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">q(s_{1:n}|x_{1:n})=\mathrm{P}(s_{1:n} | x_{1:n})</annotation></semantics></math>,
this criterion optimizes the importance sampling distribution. The idea
of using an inference network to approximate the posterior was
popularized with the introduction of the variational autoencoder (VAE)
by Kingma and Welling <span class="citation"
data-cites="2013.Kingma">¬†[<a href="#ref-2013.Kingma"
role="doc-biblioref">54</a>]</span>, a powerful technique for
approximating complex distributions. The training objective used in
variational inference is the Evidence Lower Bound Objective (ELBO) which
provides a lower bound on the ‚Äúevidence‚Äù
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n})</annotation></semantics></math>.
Maximizing this bound brings the variational approximation closer to the
true posterior. The ELBO can be derived by applying Jensen‚Äôs inequality
to the last line of <a
href="#eq:ml_importance_sampling">eq:ml_importance_sampling</a>: </p>
<div id="eq:ml_elbo">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>‚â•</mo><msub><mi>ùîº</mi><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow></msub><mrow><mo stretchy="true" form="prefix">[</mo><mi>ln</mi><mfrac><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow></mfrac><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><msub><mi>‚Ñí</mi><mtext mathvariant="normal">ELBO</mtext></msub></mrow><annotation encoding="application/x-tex">\ln \mathrm{P}(x_{1:n}) \geq 
\mathbb{E}_{q(s_{1:n}|x_{1:n})}  \left[ 
\ln\frac{\mathrm{P}(s_{1:n})\mathrm{P}(x_{1:n}|s_{1:n})}{q(s_{1:n}|x_{1:n})} \right] = \mathcal{L}_\text{ELBO}
\label{eq:ml_elbo}</annotation></semantics></math>
</div>
<p> It is easy to show that maximizing the ELBO is equivalent to
minimizing the KL-divergence between the variational distribution and
the true posterior. Although the estimate in <a
href="#eq:ml_importance_sample_mc">eq:ml_importance_sample_mc</a> is
always unbiased, i.e., it converges to the marginal probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n})</annotation></semantics></math>
as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>‚Üí</mo><mi>‚àû</mi></mrow><annotation encoding="application/x-tex">M\to\infty</annotation></semantics></math>
regardless of the choice of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">q(s_{1:n}|x_{1:n})</annotation></semantics></math>,
in practice, convergence will be slow unless the inference network
accurately approximates the posterior. Thus, optimizing the inference
network by maximizing the ELBO is crucial for efficient
marginalization.</p>
<p>To closely approximate the posterior, the inference network needs
enough flexibility to capture the key features of the true posterior.
Efficient marginalization in trajectory space, in particular, requires
an inference network capable of modeling high-dimensional distributions
with complex dependencies between variables. Specifically, for
efficiently marginalizing in trajectory space, we require an inference
network that can model high-dimensional distributions with complex
dependencies between variables. However, selecting an appropriate
inference network can be challenging: if the network lacks sufficient
flexibility, it may oversimplify the posterior, which may be hard to
diagnose. Various approaches for designing flexible inference networks
have been studied previously and could be applied here <span
class="citation"
data-cites="2015.Rezende 2016.Dinh 2016.Kingma 2018.VanDenBerg 2018.Kingma 2019.Kobyzev 2021.Papamakarios">¬†[<a
href="#ref-2015.Rezende" role="doc-biblioref">55</a>‚Äì<a
href="#ref-2021.Papamakarios" role="doc-biblioref">61</a>]</span>.</p>
<p>In our example, we use an inference model for marginalization that
closely resembles the generative model discussed in the previous section
and uses an autoregressive sequence model for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">q(s_{1:n}|x_{1:n})</annotation></semantics></math>.
The inference network consists of a RNN-based encoder-decoder
architecture <span class="citation" data-cites="2014.Sutskever">¬†[<a
href="#ref-2014.Sutskever" role="doc-biblioref">62</a>]</span> which
helps in approximating the posterior
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(s_{1:n}|x_{1:n})</annotation></semantics></math>
by effectively using the information in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>
to guide the generation of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">s_{1:n}</annotation></semantics></math>.</p>
<p>The encoder, a RNN, first processes the sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>
in reverse to create a latent representation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>h</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">h_{1:n}</annotation></semantics></math>,
which provides contextual information to the decoder. This latent
sequence is used by the decoder to generate a new sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>s</mi><mo accent="true">ÃÉ</mo></mover><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>‚àº</mo><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mover><mi>s</mi><mo accent="true">ÃÉ</mo></mover><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\tilde{s}_{1:n} \sim q(\tilde{s}_{1:n}|x_{1:n})</annotation></semantics></math>
that is compatible with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>.
Because the encoder processes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>
in reverse, the latent sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>h</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">h_{1:n}</annotation></semantics></math>
enables the decoder to incorporate information about all future values
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>j</mi></msub><annotation encoding="application/x-tex">x_j</annotation></semantics></math>
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>‚â•</mo><mi>i</mi></mrow><annotation encoding="application/x-tex">j\geq i</annotation></semantics></math>
into each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>s</mi><mo accent="true">ÃÉ</mo></mover><mi>i</mi></msub><annotation encoding="application/x-tex">\tilde{s}_i</annotation></semantics></math>.
Importantly, by including future information from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mi>i</mi><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{i:n}</annotation></semantics></math>
to sample
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>s</mi><mo accent="true">ÃÉ</mo></mover><mi>i</mi></msub><annotation encoding="application/x-tex">\tilde{s}_i</annotation></semantics></math>,
we can effectively capture the dependence structure of the true
posterior
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mover><mi>s</mi><mo accent="true">ÃÉ</mo></mover><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(\tilde{s}_{1:n}|x_{1:n})</annotation></semantics></math>
into our variational approximation. Thus, using an encoder is a key
ingredient for accurately approximating the posterior.</p>
<p>The decoder then autoregressively generates the sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>s</mi><mo accent="true">ÃÉ</mo></mover><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>‚àº</mo><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mover><mi>s</mi><mo accent="true">ÃÉ</mo></mover><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\tilde{s}_{1:n} \sim q(\tilde{s}_{1:n}|x_{1:n})</annotation></semantics></math>,
using the context sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>h</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">h_{1:n}</annotation></semantics></math>
provided by the encoder. Thus, each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>s</mi><mo accent="true">ÃÉ</mo></mover><mi>i</mi></msub><annotation encoding="application/x-tex">\tilde{s}_i</annotation></semantics></math>
is generated conditioned on both
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>h</mi><mi>i</mi></msub><annotation encoding="application/x-tex">h_i</annotation></semantics></math>
and the previously generated
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>s</mi><mo accent="true">ÃÉ</mo></mover><mrow><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">\tilde{s}_{i-1}</annotation></semantics></math>.
As in the forward model,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>s</mi><mo accent="true">ÃÉ</mo></mover><mi>i</mi></msub><annotation encoding="application/x-tex">\tilde{s}_i</annotation></semantics></math>
is generated probabilistically; however, rather than a Gaussian
distribution, the decoder uses a mixture of logistic distributions,
inspired by the Flow++ architecture <span class="citation"
data-cites="2019.Ho">¬†[<a href="#ref-2019.Ho"
role="doc-biblioref">63</a>]</span>. This encoder-decoder setup provides
a flexible, expressive model capable of accurately approximating the
posterior distribution.</p>
<p>Given that all parameters in our model are continuous, we optimize
the weights of the inference network using stochastic gradient
variational Bayes (SGVB) <span class="citation"
data-cites="2013.Kingma">¬†[<a href="#ref-2013.Kingma"
role="doc-biblioref">54</a>]</span>, a widely used method for training
variational models. SGVB leverages the reparameterization trick to
estimate the gradient of the ELBO, which makes the training procedure
efficient.</p>
<h2 id="sec:ml_application">Application to a Minimal Nonlinear
Model</h2>
<p>We evaluate our approach using synthetic training data to train a
generative model and then using PWS to compute the mutual information
rate.</p>
<h3 id="nonlinear-model">Nonlinear Model</h3>
<p>To generate training data for the neural network, we combine a linear
auto-regressive input, with a stochastic nonlinear output model.
Specifically, we considered an input that evolves according to AR(1)
statistics: </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>œï</mi><msub><mi>S</mi><mrow><mi>t</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>Œæ</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">S_t = \phi S_{t-1} + \xi_t</annotation></semantics></math>
<p> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œæ</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\xi_t</annotation></semantics></math>
are iid random variables from a unit Gaussian distribution, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œï</mi><mo>‚àà</mo><mo stretchy="false" form="prefix">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\phi\in[0, 1)</annotation></semantics></math>
is a parameter. In steady state, the autocovariance of this process is
given by </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">‚ü®</mo><msub><mi>S</mi><mi>œÑ</mi></msub><msub><mi>S</mi><mrow><mi>œÑ</mi><mo>+</mo><mi>t</mi></mrow></msub><mo stretchy="false" form="postfix">‚ü©</mo><mo>=</mo><mfrac><msup><mi>œï</mi><mrow><mo stretchy="false" form="prefix">|</mo><mi>t</mi><mo stretchy="false" form="prefix">|</mo></mrow></msup><mrow><mn>1</mn><mo>‚àí</mo><msup><mi>œï</mi><mn>2</mn></msup></mrow></mfrac><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">\langle S_{\tau} S_{\tau + t} \rangle = \frac{\phi^{|t|}}{1 - \phi^2} \,.</annotation></semantics></math>
<p> The output
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mi>t</mi></msub><annotation encoding="application/x-tex">X_t</annotation></semantics></math>
is governed by the equation </p>
<div id="eq:nonlinear_model">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>t</mi></msub><mo>=</mo><mi>œÉ</mi><mo stretchy="false" form="prefix">(</mo><mi>Œ≥</mi><msub><mi>S</mi><mi>t</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mi>œÅ</mi><msub><mi>X</mi><mrow><mi>t</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>œë</mi><msub><mi>Œ∑</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">X_t = \sigma(\gamma S_t) + \rho X_{t-1} + \vartheta \eta_t \label{eq:nonlinear_model}</annotation></semantics></math>
</div>
<p> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ∑</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\eta_t</annotation></semantics></math>
are iid Gaussian random numbers,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ≥</mi><annotation encoding="application/x-tex">\gamma</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œÅ</mi><annotation encoding="application/x-tex">\rho</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œë</mi><annotation encoding="application/x-tex">\vartheta</annotation></semantics></math>
are positive real parameters, and </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œÉ</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mi>‚àí</mi><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\sigma(x) = \frac{1}{1+e^{-x}}</annotation></semantics></math>
<p> is the logistic function. The gain
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ≥</mi><annotation encoding="application/x-tex">\gamma</annotation></semantics></math>
effectively controls the strength of the nonlinearity; see <a
href="#fig:input_output">Fig. input_output</a>. This process models a
response that saturates as the input grows. In fact,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œÉ</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\sigma(x)</annotation></semantics></math>
is equivalent to the Hill function commonly used in biochemistry to
describe saturating enzyme kinetics <span class="citation"
data-cites="2005.Edelstein-Keshet">¬†[<a
href="#ref-2005.Edelstein-Keshet"
role="doc-biblioref">64</a>]</span>.</p>
<figure id="fig:input_output">
<img src="../images/input_output.svg"  />
<figcaption>Example time series from the training set. The training set
was generated using parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œï</mi><mo>=</mo><mn>0.5</mn><mo>,</mo><mi>œÅ</mi><mo>=</mo><mn>0.2</mn></mrow><annotation encoding="application/x-tex">\phi=\num{0.5}, \rho=\num{0.2}</annotation></semantics></math>,
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œë</mi><mo>=</mo><mn>0.2</mn></mrow><annotation encoding="application/x-tex">\vartheta=\num{0.2}</annotation></semantics></math>.
In the upper left panel one stochastic realization of the input process
is shown. The other panels show the mean output as well as 10/90-th
percentiles for the output at different values of the input gain
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ≥</mi><annotation encoding="application/x-tex">\gamma</annotation></semantics></math>.
The effect of the gain on the output can be clearly seen. For the
highest gain
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ≥</mi><mo>=</mo><mn>10.0</mn></mrow><annotation encoding="application/x-tex">\gamma = \num{10.0}</annotation></semantics></math>,
we observe saturation of the output.</figcaption>
</figure>
<h3 id="training-the-neural-networks">Training the Neural Networks</h3>
<p>We trained our machine learning model with synthetic data generated
according to <a href="#eq:nonlinear_model">eq:nonlinear_model</a> for
various values of the gain, denoted by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ≥</mi><annotation encoding="application/x-tex">\gamma</annotation></semantics></math>.
For each value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ≥</mi><annotation encoding="application/x-tex">\gamma</annotation></semantics></math>,
we created a distinct training set of 1000 pairs of time series
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mn>50</mn></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mn>50</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(s_{1:50}, x_{1:50})</annotation></semantics></math>
and trained one autoregressive model per training set. Once the models
were trained, we estimated the mutual information for each of them using
PWS, employing variational inference to perform the marginalization.</p>
<p>For the generative model, we use a recurrent neural network (RNN).
Using Gated Recurrent Unit (GRU) cells <span class="citation"
data-cites="2014.Cho">¬†[<a href="#ref-2014.Cho"
role="doc-biblioref">47</a>]</span> with a hidden size of 64 for
temporal processing, along with a dense layer that outputs two values,
representing the mean
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œº</mi><annotation encoding="application/x-tex">\mu</annotation></semantics></math>
and log-variance
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><msup><mi>œÉ</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\ln\sigma^2</annotation></semantics></math>
of a Gaussian distribution. For each time step
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>,
the model receives input signals
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>s</mi><mi>i</mi></msub><annotation encoding="application/x-tex">s_i</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">x_{i-1}</annotation></semantics></math>
and predicts the next output value
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>
by sampling from this Gaussian. The model is trained by iteratively
optimizing over 100 epochs over the entire training set. The training
set is split into mini-batches of size 64 which are shuffled after each
epoch. We optimize the model using the Adam optimizer <span
class="citation" data-cites="2014.Kingma">¬†[<a href="#ref-2014.Kingma"
role="doc-biblioref">65</a>]</span>
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mn>1</mn></msub><mo>=</mo><mn>0.9</mn><mo>,</mo><msub><mi>b</mi><mn>2</mn></msub><mo>=</mo><mn>0.999</mn></mrow><annotation encoding="application/x-tex">b_1 = \num{0.9}, b_2 = \num{0.999}</annotation></semantics></math>)
with weight decay regularization <span class="citation"
data-cites="2017.Loshchilov">¬†[<a href="#ref-2017.Loshchilov"
role="doc-biblioref">66</a>]</span> of 1¬†√ó¬†10<sup>‚àí4</sup> and using a
cosine decay learning rate schedule <span class="citation"
data-cites="2016.Loshchilov">¬†[<a href="#ref-2016.Loshchilov"
role="doc-biblioref">67</a>]</span> that smoothly decreases the learning
rate from 1¬†√ó¬†10<sup>‚àí2</sup> to 1¬†√ó¬†10<sup>‚àí3</sup> throughout the
training process.</p>
<p>The inference model used for marginalization is also modeled as a
RNN. This model consists of an encoder-decoder architecture for
approximating the posterior
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(s_{1:n}|x_{1:n})</annotation></semantics></math>.
The encoder first processes the input sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>
in reverse using a GRU cell with 64 hidden units to create a latent
sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>h</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">h_{1:n}</annotation></semantics></math>.
The decoder then uses another RNN with a hidden size of 64 (using a GRU
cell), to autoregressively generate a sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>s</mi><mo accent="true">ÃÉ</mo></mover><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">\tilde{s}_{1:n}</annotation></semantics></math>
using the context sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>h</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">h_{1:n}</annotation></semantics></math>.
The sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>s</mi><mo accent="true">ÃÉ</mo></mover><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">\tilde{s}_{1:n}</annotation></semantics></math>
is generated probabilistically by sampling from a mixture of logistic
distributions with five components. The inference network is trained for
100 epochs with mini-batches of size 64. For each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>
in the training set, 16 Monte Carlo draws from the inference network
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>s</mi><mo accent="true">ÃÉ</mo></mover><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>‚àº</mo><mi>q</mi><mo stretchy="false" form="prefix">(</mo><msub><mover><mi>s</mi><mo accent="true">ÃÉ</mo></mover><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\tilde{s}_{1:n}\sim q(\tilde{s}_{1:n}|x_{1:n})</annotation></semantics></math>
are used to estimate the ELBO loss in <a
href="#eq:ml_elbo">eq:ml_elbo</a>. The loss function gradient is
estimated using SGVB <span class="citation"
data-cites="2013.Kingma">¬†[<a href="#ref-2013.Kingma"
role="doc-biblioref">54</a>]</span>. The model is optimized using the
ADAM optimizer with weight decay regularization (same parameters as
above). We use an initial learning rate of 5¬†√ó¬†10<sup>‚àí3</sup> that
decays exponentially by a factor of 0.5 as training progresses.</p>
<p>To compute the marginal probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n})</annotation></semantics></math>
from our models, we use the inference network to generate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>14</mn></msup><mo>=</mo><mn>16384</mn></mrow><annotation encoding="application/x-tex">2^{14} = \num{16384}</annotation></semantics></math>
samples
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>s</mi><mo accent="true">ÃÉ</mo></mover><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">\tilde{s}_{1:n}</annotation></semantics></math>
for each sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math>.
From these samples
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>s</mi><mo accent="true">ÃÉ</mo></mover><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">\tilde{s}_{1:n}</annotation></semantics></math>,
the marginal probability is estimated using <a
href="#eq:ml_importance_sample_mc">eq:ml_importance_sample_mc</a>. We
monitor the convergence of the variational marginalization procedure by
computing the effective sample size from the importance weights <span
class="citation" data-cites="2017.Martino">¬†[<a href="#ref-2017.Martino"
role="doc-biblioref">68</a>]</span>. In our case, the effective sample
size always remained above 85% of the actual sample size, indicating
that the inference network approximates the posterior well.</p>
<figure id="fig:mi_gain">
<img src="../images/MI_gain.svg"  />
<figcaption>Mutual information estimates for the nonlinear 1D
time-series model across a range of input gain values (see <a
href="#eq:nonlinear_model">eq:nonlinear_model</a>). The green dots
represent the ML-PWS estimates (using an autoregressive RNN model for
learning the stochastic dynamics), while the solid green line indicates
the ground truth mutual information calculated by applying PWS directly
to the nonlinear model. For comparison, the Gaussian approximation has
been obtained in two diferent ways: the dotted orange line (labeled
<em>Gaussian I</em>) represents Gaussian information estimates obtained
from the same dataset
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>=</mo><mn>1000</mn></mrow><annotation encoding="application/x-tex">N=\num{1000}</annotation></semantics></math>)
that was used to train the machine learning model, showing finite sample
size effects. The dashed orange line (labeled <em>Gaussian II</em>)
represents a ‚Äúreduced-bias‚Äù Gaussian approximation using an extended
dataset
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>=</mo><mn>100000</mn></mrow><annotation encoding="application/x-tex">N=\num{100000}</annotation></semantics></math>).
For low gain
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ≥</mi><mo>‚â≤</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">\gamma \lesssim 10</annotation></semantics></math>),
both Gaussian approximations align closely with the ground truth and
ML-PWS. At high gain, however, the Gaussian approximation fails to
capture nonlinear effects, and only provides a lower bound on the mutual
information. Yet, ML-PWS does not suffer from this problem and correctly
estimates the mutual information for the whole range of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ≥</mi><annotation encoding="application/x-tex">\gamma</annotation></semantics></math>.</figcaption>
</figure>
<h3 id="comparison-against-the-true-mutual-information">Comparison
Against the True Mutual Information</h3>
<p>The green dots in <a href="#fig:mi_gain">Fig. mi_gain</a> display the
ML-PWS estimate of the mutual information
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>S</mi><mrow><mn>1</mn><mo>:</mo><mn>50</mn></mrow></msub><mo>,</mo><msub><mi>X</mi><mrow><mn>1</mn><mo>:</mo><mn>50</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">I(S_{1:50}, X_{1:50})</annotation></semantics></math>
as a function of the gain
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ≥</mi><annotation encoding="application/x-tex">\gamma</annotation></semantics></math>,
see <a href="#eq:nonlinear_model">eq:nonlinear_model</a>. As expected,
for small
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ≥</mi><annotation encoding="application/x-tex">\gamma</annotation></semantics></math>,
the mutual information grows with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ≥</mi><annotation encoding="application/x-tex">\gamma</annotation></semantics></math>
as the gain enhances the signal-to-noise ratio. For larger values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ≥</mi><annotation encoding="application/x-tex">\gamma</annotation></semantics></math>,
we observe a saturation and even a decline in the information rate due
to the saturation effect of the logistic function. This behavior is
indicative of the nonlinearity of the system.</p>
<p>Next, we compared the mutual information estimates against various
benchmarks. First, we compute the true mutual information of the
nonlinear system using PWS directly with the model given in <a
href="#eq:nonlinear_model">eq:nonlinear_model</a>. Since this model
represents the true underlying dynamics of the training data, we
consider this result as the ‚Äúground truth‚Äù mutual information.</p>
<p><a href="#fig:mi_gain">Figure mi_gain</a> (solid green line) shows
the ground truth mutual information. We can see that the machine
learning approach matches the ground truth very well across all values
of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ≥</mi><annotation encoding="application/x-tex">\gamma</annotation></semantics></math>.
This demonstrates that the autoregressive neural network can accurately
learn the stochastic dynamics of the nonlinear model and reliably
estimate the path likelihood, which is required for the Monte Carlo
estimate of mutual information. These results confirm that combining PWS
with machine learning is a feasible and promising approach for computing
the mutual information rate in complex nonlinear systems.</p>
<h3 id="comparison-against-the-gaussian-approximation">Comparison
Against the Gaussian Approximation</h3>
<p>Second, we use the Gaussian approximation as a benchmark, which is
widely used for directly estimating mutual information rates from
time-series data. We obtain the Gaussian estimate by computing the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>n</mi><mo>√ó</mo><mn>2</mn><mi>n</mi></mrow><annotation encoding="application/x-tex">2n\times 2n</annotation></semantics></math>
covariance matrix </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Œ£</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><msub><mi mathvariant="normal">Œ£</mi><mrow><mi>s</mi><mi>s</mi></mrow></msub></mtd><mtd columnalign="center" style="text-align: center"><msub><mi mathvariant="normal">Œ£</mi><mrow><mi>s</mi><mi>x</mi></mrow></msub></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><msub><mi mathvariant="normal">Œ£</mi><mrow><mi>x</mi><mi>s</mi></mrow></msub></mtd><mtd columnalign="center" style="text-align: center"><msub><mi mathvariant="normal">Œ£</mi><mrow><mi>x</mi><mi>x</mi></mrow></msub></mtd></mtr></mtable><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\Sigma = \left(
    \begin{array}{cc}
        \Sigma_{ss} &amp; \Sigma_{sx} \\
        \Sigma_{xs} &amp; \Sigma_{xx}
    \end{array}
    \right)</annotation></semantics></math>
<p> from our dataset of trajectories
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{1:n}, x_{1:n}</annotation></semantics></math>.
The individual blocks of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi mathvariant="normal">Œ£</mi><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math>
are
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>√ó</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">n\times n</annotation></semantics></math>
matrices defined by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="normal">Œ£</mi><mrow><mi>Œ±</mi><mi>Œ≤</mi></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msubsup><mo>=</mo><mo stretchy="false" form="prefix">‚ü®</mo><msub><mi>Œ±</mi><mi>i</mi></msub><msub><mi>Œ≤</mi><mi>j</mi></msub><mo stretchy="false" form="postfix">‚ü©</mo></mrow><annotation encoding="application/x-tex">\Sigma^{ij}_{\alpha\beta} = \langle \alpha_i \beta_j \rangle</annotation></semantics></math>.
The Gaussian approximation for the mutual information (in nats) is given
by </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>S</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>X</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mfrac><mrow><mo stretchy="false" form="prefix">|</mo><msub><mi mathvariant="normal">Œ£</mi><mrow><mi>s</mi><mi>s</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><mo stretchy="false" form="prefix">|</mo><msub><mi mathvariant="normal">Œ£</mi><mrow><mi>x</mi><mi>x</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo></mrow><mrow><mo stretchy="false" form="prefix">|</mo><mi mathvariant="normal">Œ£</mi><mo stretchy="false" form="prefix">|</mo></mrow></mfrac><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">I(S_{1:n}, X_{1:n}) = \frac{1}{2} \ln \frac{|\Sigma_{ss}| |\Sigma_{xx}|}{|\Sigma|}\,.</annotation></semantics></math>
<p> See <a href="#ch:notes-gaussian">Ch. notes-gaussian</a> for more
details.</p>
<p>To make a fair comparison of our machine learning method with the
Gaussian approximation, we use the same dataset for obtaining the
Gaussian approximation that was used for training the ML model. We refer
to this benchmark as ‚ÄúGaussian¬†I‚Äù and it corresponds to the dotted
orange line in <a href="#fig:mi_gain">Fig. mi_gain</a>. The Gaussian
approximation suffers from two sources of systematic bias: a finite
sample size bias due to imperfect correlation function estimates from
1000 trajectory pairs, and a bias arising from the assumption of
linearity which does not hold at large
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ≥</mi><annotation encoding="application/x-tex">\gamma</annotation></semantics></math>.
Our aim was to distinguish these two sources of bias.</p>
<p>We created another benchmark, called ‚ÄúGaussian¬†II‚Äù (dashed orange
line in <a href="#fig:mi_gain">Fig. mi_gain</a>) to be able to quantify
the bias introduced by the small sample size of the ‚ÄúGaussian¬†I‚Äù
benchmark. Gaussian¬†II is similar to Gaussian¬†I but is obtained from a
significantly larger dataset of 100000 trajectory pairs
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mn>50</mn></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mn>50</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(s_{1:50}, x_{1:50})</annotation></semantics></math>,
generated from the nonlinear model. This larger dataset allows for very
precise estimates of the (cross-)covariance matrices required for the
Gaussian approximation, effectively eliminating the sample size bias.
However, it should be noted that this benchmark is ‚Äúunfair‚Äù since it
uses a much larger dataset than the one that was used to train the
autoregressive ML model.</p>
<p>In <a href="#fig:mi_gain">Fig. mi_gain</a> we compare the results
obtained using PWS against the two variants of the Gaussian
approximation, and we observe that for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ≥</mi><mo>‚â≤</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">\gamma \lesssim 10</annotation></semantics></math>
the Gaussian approximations (the regular one, Gaussian¬†I, and the one
with reduced bias, Gaussian¬†II) closely match the ground truth while
significantly deviations appear at larger gain. Indeed, in the low-gain
regime, the nonlinearity of the system does not significantly impact the
output, the Gaussian approximation provides a reliable estimate of the
information. In the high-gain regime, the Gaussian approximation fails
to correctly capture the nonlinear dynamics of the system, and only
yields a lower bound for the mutual information, as expected from
information theory¬†<span class="citation"
data-cites="mitra2001nonlinear">¬†[<a href="#ref-mitra2001nonlinear"
role="doc-biblioref">69</a>]</span>.</p>
<p><a href="#fig:mi_gain">Figure mi_gain</a> also clearly displays the
effect of finite sample size on the accuracy of the Gaussian
approximation. Specifically, the Gaussian approximation obtained from
the smaller training dataset (Gaussian¬†I, displayed as dotted orange
line in <a href="#fig:mi_gain">Fig. mi_gain</a>) consistently
overestimates the mutual information as computed with the Gaussian
approximation from the larger dataset (Gaussian¬†II, dashed orange line
in <a href="#fig:mi_gain">Fig. mi_gain</a>). This means that at low
gain, even though the system is approximately linear, the Gaussian
approximation obtained from the training set slightly overestimates the
true mutual information. This over-estimation is purely an artifact of
finite sample size bias, and is not present in the ‚Äúreduced-bias‚Äù
Gaussian approximation. Strikingly thus, our new method based on machine
learning yields a better estimate for the mutual information using the
training set, even at low gain, where the Gaussian approximation is
expected to hold.</p>
<h2 id="sec:ml_discussion">Discussion</h2>
<p>By combining neural networks with PWS, we introduced ML-PWS, a new
scheme to estimate the mutual information between input and output
trajectories of a system. PWS is a Monte Carlo method for calculating
mutual information between trajectories, relying on a stochastic model
that defines the probability distribution of trajectories to determine
the path action. We demonstrated how autoregressive sequence prediction
models can be trained on time-series data to learn this stochastic
model, making it possible to use PWS with such models to compute mutual
information. By applying ML-PWS to a nonlinear model of information
processing, we showed that it provides more accurate mutual information
estimates than the Gaussian approximation. While this example serves as
a proof of concept, it shows the potential of advanced machine learning
techniques to automatically derive stochastic models from experimental
data, and to make it possible to compute information-theoretic measures
for complex, high-dimensional data.</p>
<p>Using the mutual information rate as a measure for time series
correlation possesses a distinct advantage compared to other, simpler,
measures: it remains invariant under deterministic and lossless
transformations of the sequences <span class="citation"
data-cites="2006.Cover">¬†[<a href="#ref-2006.Cover"
role="doc-biblioref">70</a>]</span>. Not only is this property desirable
on philosophical grounds, but it can also simplify the training of
machine learning models. Specifically, in some cases, it could be
beneficial to preprocess the time series data by transforming it into a
different representation (e.g. a symbolic encoding) that is more
conducive to machine learning analysis <span class="citation"
data-cites="2003.Lin">¬†[<a href="#ref-2003.Lin"
role="doc-biblioref">71</a>]</span>. Such a transformation could be
applied before employing ML-PWS to compute the mutual information rate.
Additionally, this concept could be used for model reduction, making it
possible to answer the question of whether a time series with a
simplified representation still maintains the same mutual information
rate.</p>
<p>As our results in <a href="#fig:mi_gain">Fig. mi_gain</a>
demonstrate, ML-PWS with Gaussian autoregressive models is significantly
more general than the Gaussian framework <span class="citation"
data-cites="2009.Tostevin">¬†[<a href="#ref-2009.Tostevin"
role="doc-biblioref">2</a>]</span>. The range of stochastic processes
representable by neural autoregressive models is much larger than the
range of processes which can be described by a Gaussian model. Even
though in the autoregressive model the distribution of each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>
conditional on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">x_{1:i-1}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><annotation encoding="application/x-tex">s_{1:i}</annotation></semantics></math>
is Gaussian, the distribution of the whole sequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n}|s_{1:n})</annotation></semantics></math>
is generally not Gaussian due to the nonlinearity of the neural network.
In fact, a Gaussian autoregressive model can be seen as a
(time-discretized) representation of a nonlinear stochastic differential
equation of the form </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>d</mi><mi>t</mi><mo>+</mo><mi>g</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>d</mi><msub><mi>W</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">dx_t = f(s_{1:t}, x_{1:t-1})\,dt + g(s_{1:t}, x_{1:t-1})\,dW_t</annotation></semantics></math>
<p> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">f(s_{1:t}, x_{1:t-1})</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">g(s_{1:t}, x_{1:t-1})</annotation></semantics></math>
are the potentially nonlinear drift and diffusion terms that are learned
by the neural network. This representation is a generalization of the
Gaussian framework, which assumes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
to be linear operators.</p>
<p>Nonetheless, assuming that each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>
is normally distributed given its and the signal‚Äôs history, does
restrict the expressive power of the model. For instance, such a model
can never represent multimodal predictive distributions or discrete
state spaces. In these cases, other predictive distributions must be
chosen.</p>
<p>ML-PWS shares some characteristics with the Difference-of-Entropies
(DoE) estimator for the mutual information proposed by McAllester and
Stratos <span class="citation" data-cites="2018.McAllester">¬†[<a
href="#ref-2018.McAllester" role="doc-biblioref">34</a>]</span>. Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùë∫</mi><annotation encoding="application/x-tex">\mathbfit{S}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùëø</mi><annotation encoding="application/x-tex">\mathbfit{X}</annotation></semantics></math>
be (high-dimensional) random variables and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo stretchy="false" form="prefix">(</mo><mi>ùë∫</mi><mo>,</mo><mi>ùëø</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>ùëø</mi><mo stretchy="false" form="postfix">)</mo><mo>‚àí</mo><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>ùëø</mi><mo stretchy="false" form="prefix">|</mo><mi>ùë∫</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">I(\mathbfit{S},\mathbfit{X})=H(\mathbfit{X}) - H(\mathbfit{X}|\mathbfit{S})</annotation></semantics></math>
the desired mutual information computed as a difference of entropies. In
both ML-PWS and the DoE method, the generative model for the conditional
probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>ùíô</mi><mo stretchy="false" form="prefix">|</mo><mi>ùíî</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(\mathbfit{x}|\mathbfit{s})</annotation></semantics></math>
is trained by maximizing the likelihood, an objective that, as shown in
Ref.¬†<span class="citation" data-cites="2018.McAllester">¬†[<a
href="#ref-2018.McAllester" role="doc-biblioref">34</a>]</span>, results
in an upper bound of the conditional entropy
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>ùëø</mi><mo stretchy="false" form="prefix">|</mo><mi>ùë∫</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">H(\mathbfit{X}|\mathbfit{S})</annotation></semantics></math>.
However, unlike ML-PWS, McAllester and Stratos <span class="citation"
data-cites="2018.McAllester">¬†[<a href="#ref-2018.McAllester"
role="doc-biblioref">34</a>]</span> use a second generative model that
represents the marginal probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>ùíô</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(\mathbfit{x})</annotation></semantics></math>,
yielding an upper bound of the marginal entropy
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>ùëø</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">H(\mathbfit{X})</annotation></semantics></math>.
PWS instead computes the marginal probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>ùíô</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(\mathbfit{x})</annotation></semantics></math>
by marginalizing the joint probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>ùíî</mi><mo>,</mo><mi>ùíô</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>ùíî</mi><mo stretchy="false" form="postfix">)</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>ùíô</mi><mo stretchy="false" form="prefix">|</mo><mi>ùíî</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(\mathbfit{s},\mathbfit{x})=\mathrm{P}(\mathbfit{s})\mathrm{P}(\mathbfit{x}|\mathbfit{s})</annotation></semantics></math>.
In this way,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>ùíô</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(\mathbfit{x})</annotation></semantics></math>
can in principle be computed for any desired accuracy. This direct
marginalization in ML-PWS also enables efficient computation of the
mutual information
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo stretchy="false" form="prefix">(</mo><msup><mi>ùë∫</mi><mi>‚Ä≤</mi></msup><mo>,</mo><msup><mi>ùëø</mi><mi>‚Ä≤</mi></msup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">I(\mathbfit{S}^\prime, \mathbfit{X}^\prime)</annotation></semantics></math>
between a input signal
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ùë∫</mi><mi>‚Ä≤</mi></msup><annotation encoding="application/x-tex">\mathbfit{S}^\prime</annotation></semantics></math>
with different statistics and the corresponding output
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ùëø</mi><mi>‚Ä≤</mi></msup><annotation encoding="application/x-tex">\mathbfit{X}^\prime</annotation></semantics></math>,
without needing to re-train the marginal model. This is particularly
useful if one is interested in the channel capacity, as determined by
the input distribution that maximizes the mutual information or
information rate for the system of interest. Indeed, in systems without
feedback,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>ùíô</mi><mo stretchy="false" form="prefix">|</mo><mi>ùíî</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(\mathbfit{x}|\mathbfit{s})</annotation></semantics></math>
is a property of the system and does not change upon changing the input.
The generative model then remains the same, such that ML-PWS can
directly recompute the mutual information for different input
statistics. Determining which of these approaches is preferable for
estimating mutual information remains an open question for future
research.</p>
<p>Alongside ML-PWS, we introduced a new marginalization scheme for PWS,
leveraging techniques from variational inference. In PWS,
marginalization is used to compute the marginal probability of a
trajectory,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n})</annotation></semantics></math>.
Our approach trains an inference network to generate input trajectories
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">s_{1:n}</annotation></semantics></math>
approximately distributed according to the posterior distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(s_{1:n}|x_{1:n})</annotation></semantics></math>,
enabling efficient calculation of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_{1:n})</annotation></semantics></math>
through importance sampling. Importantly, this marginalization technique
is general and can be applied to any generative model, regardless of
whether it is based on neural networks. This flexibility makes it a
powerful marginalization scheme for any application of PWS to a system
with continuous state space. Furthermore, since marginalization is
mathematically equivalent to a free-energy computation (see <a
href="#ch:variants">Ch. variants</a>), our approach demonstrates that
variational techniques can yield efficient methods for free-energy
estimation.</p>
<p>In conclusion, ML-PWS‚Äîour integration of neural networks and
variational inference into the PWS framework‚Äîrepresents a promising
advance for estimating the mutual information of high-dimensional data,
a notoriously difficult problem. While our initial tests on a toy
example demonstrate the technique‚Äôs potential, further evaluation on
more complex systems is needed. Additionally, comparing ML-PWS with
other neural methods for mutual information estimation will help clarify
its advantages and limitations. By enabling the accurate computation of
the mutual information rate, we anticipate that ML-PWS could contribute
to a deeper understanding of complex dynamical systems, with potential
applications spanning neuroscience, biology, physics, and machine
learning.</p>
<h1 class="unnumbered" id="bibliography">References</h1>
<div id="refs" class="references csl-bib-body" data-entry-spacing="0"
role="list">
<div id="ref-1948.Shannon" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">C.
E. Shannon, <a
href="https://doi.org/10.1002/j.1538-7305.1948.tb01338.x"><span
class="nocase">A Mathematical Theory of Communication</span></a>, Bell
System Technical Journal <strong>27</strong>, 379 (1948).</div>
</div>
<div id="ref-2009.Tostevin" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">F.
Tostevin and P. R. ten Wolde, <a
href="https://doi.org/10.1103/physrevlett.102.218101"><span
class="nocase">Mutual Information between Input and Output Trajectories
of Biochemical Networks</span></a>, Physical Review Letters
<strong>102</strong>, 218101 (2009).</div>
</div>
<div id="ref-1990.Massey" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">J.
L. Massey, <em><span class="nocase">Causality, Feedback and Directed
Information</span></em>, in <em>Proc. 1990 Int. Symp. On Info. Th. &amp;
Its Applications</em> (Hawaii, USA, 1990), pp. 303‚Äì305.</div>
</div>
<div id="ref-2000.Schreiber" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">T.
Schreiber, <a href="https://doi.org/10.1103/physrevlett.85.461"><span
class="nocase">Measuring information transfer</span></a>, Physical
Review Letters <strong>85</strong>, 461 (2000).</div>
</div>
<div id="ref-2021.Mattingly" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">H.
H. Mattingly, K. Kamino, B. B. Machta, and T. Emonet, <a
href="https://doi.org/10.1038/s41567-021-01380-3"><span
class="nocase">Escherichia coli chemotaxis is information
limited</span></a>, Nature Physics <strong>17</strong>, 1426
(2021).</div>
</div>
<div id="ref-2023.Hahn" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">L.
Hahn, A. M. Walczak, and T. Mora, <a
href="https://doi.org/10.1103/physrevlett.131.128401"><span
class="nocase">Dynamical Information Synergy in Biochemical Signaling
Networks</span></a>, Physical Review Letters <strong>131</strong>,
128401 (2023).</div>
</div>
<div id="ref-2023.Moor" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div
class="csl-right-inline">A.-L. Moor and C. Zechner, <a
href="https://doi.org/10.1103/physrevresearch.5.013032"><span
class="nocase">Dynamic information transfer in stochastic biochemical
networks</span></a>, Physical Review Research <strong>5</strong>, 013032
(2023).</div>
</div>
<div id="ref-2023.Schmitt" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">M.
S. Schmitt, M. Koch-Janusz, M. Fruchart, D. S. Seara, and V. Vitelli, <a
href="https://doi.org/10.48550/arxiv.2312.06608"><span
class="nocase">Information theory for model reduction in stochastic
dynamical systems</span></a>, arXiv (2023).</div>
</div>
<div id="ref-2007.Frenzel" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">S.
Frenzel and B. Pompe, <a
href="https://doi.org/10.1103/physrevlett.99.204101"><span
class="nocase">Partial Mutual Information for Coupling Analysis of
Multivariate Time Series</span></a>, Physical Review Letters
<strong>99</strong>, 204101 (2007).</div>
</div>
<div id="ref-2007.Hlav√°ƒçkov√°-Schindler" class="csl-entry"
role="listitem">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">K.
Hlav√°ƒçkov√°-Schindler, M. Palu≈°, M. Vejmelka, and J. Bhattacharya, <a
href="https://doi.org/10.1016/j.physrep.2006.12.004"><span
class="nocase">Causality detection based on information-theoretic
approaches in time series analysis</span></a>, Physics Reports
<strong>441</strong>, 1 (2007).</div>
</div>
<div id="ref-1995.Palu≈°" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">M.
Palu≈°, <a href="https://doi.org/10.1016/0167-2789(95)90079-9"><span
class="nocase">Testing for nonlinearity using redundancies: quantitative
and qualitative aspects</span></a>, Physica D: Nonlinear Phenomena
<strong>80</strong>, 186 (1995).</div>
</div>
<div id="ref-2002.Marschinski" class="csl-entry" role="listitem">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">R.
Marschinski and H. Kantz, <a
href="https://doi.org/10.1140/epjb/e2002-00379-2"><span
class="nocase">Analysing the information flow between financial time
series</span></a>, The European Physical Journal B - Condensed Matter
and Complex Systems <strong>30</strong>, 275 (2002).</div>
</div>
<div id="ref-2013.Dimpfl" class="csl-entry" role="listitem">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">T.
Dimpfl and F. J. Peter, <a
href="https://doi.org/10.1515/snde-2012-0044"><span class="nocase">Using
transfer entropy to measure information flows between financial
markets</span></a>, Studies in Nonlinear Dynamics and Econometrics
<strong>17</strong>, 85 (2013).</div>
</div>
<div id="ref-2016.Dimpfl" class="csl-entry" role="listitem">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">T.
Dimpfl and S. Jank, <a href="https://doi.org/10.1111/eufm.12058"><span
class="nocase">Can Internet Search Queries Help to Predict Stock Market
Volatility?</span></a>, European Financial Management
<strong>22</strong>, 171 (2016).</div>
</div>
<div id="ref-2011.Rad" class="csl-entry" role="listitem">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline">K.
Rad and L. Paninski, <em><a
href="https://proceedings.neurips.cc/paper\_files/paper/2011/file/8eefcfdf5990e441f0fb6f3fad709e21-Paper.pdf"><span
class="nocase">Information Rates and Optimal Decoding in Large Neural
Populations</span></a></em>, in <em>Advances in Neural Information
Processing Systems</em>, Vol. 24 (Curran Associates, Inc., 2011), pp.
846‚Äì854.</div>
</div>
<div id="ref-2012.So" class="csl-entry" role="listitem">
<div class="csl-left-margin">[16] </div><div class="csl-right-inline">K.
So, A. C. Koralek, K. Ganguly, M. C. Gastpar, and J. M. Carmena, <a
href="https://doi.org/10.1088/1741-2560/9/2/026004"><span
class="nocase">Assessing functional connectivity of neural ensembles
using directed information</span></a>, Journal of Neural Engineering
<strong>9</strong>, 026004 (2012).</div>
</div>
<div id="ref-1986.Fraser" class="csl-entry" role="listitem">
<div class="csl-left-margin">[17] </div><div class="csl-right-inline">A.
M. Fraser and H. L. Swinney, <a
href="https://doi.org/10.1103/physreva.33.1134"><span
class="nocase">Independent coordinates for strange attractors from
mutual information</span></a>, Physical Review A <strong>33</strong>,
1134 (1986).</div>
</div>
<div id="ref-1995.Moon" class="csl-entry" role="listitem">
<div class="csl-left-margin">[18] </div><div
class="csl-right-inline">Y.-I. Moon, B. Rajagopalan, and U. Lall, <a
href="https://doi.org/10.1103/physreve.52.2318"><span
class="nocase">Estimation of mutual information using kernel density
estimators</span></a>, Physical Review E <strong>52</strong>, 2318
(1995).</div>
</div>
<div id="ref-2003.Paninski" class="csl-entry" role="listitem">
<div class="csl-left-margin">[19] </div><div class="csl-right-inline">L.
Paninski, <a href="https://doi.org/10.1162/089976603321780272"><span
class="nocase">Estimation of Entropy and Mutual Information</span></a>,
Neural Computation <strong>15</strong>, 1191 (2003).</div>
</div>
<div id="ref-2019.Cepeda-Humerez" class="csl-entry" role="listitem">
<div class="csl-left-margin">[20] </div><div class="csl-right-inline">S.
A. Cepeda-Humerez, J. Ruess, and G. Tkaƒçik, <a
href="https://doi.org/10.1371/journal.pcbi.1007290"><span
class="nocase">Estimating information in time-varying
signals.</span></a>, PLoS Computational Biology <strong>15</strong>,
e1007290 (2019).</div>
</div>
<div id="ref-2021.Meijers" class="csl-entry" role="listitem">
<div class="csl-left-margin">[21] </div><div class="csl-right-inline">M.
Meijers, S. Ito, and P. R. ten Wolde, <a
href="https://doi.org/10.1103/physreve.103.l010102"><span
class="nocase">Behavior of information flow near criticality</span></a>,
Physical Review E <strong>103</strong>, L010102 (2021).</div>
</div>
<div id="ref-2004.Kraskov" class="csl-entry" role="listitem">
<div class="csl-left-margin">[22] </div><div class="csl-right-inline">A.
Kraskov, H. St√∂gbauer, and P. Grassberger, <a
href="https://doi.org/10.1103/physreve.69.066138"><span
class="nocase">Estimating mutual information</span></a>, Physical Review
E <strong>69</strong>, 066138 (2004).</div>
</div>
<div id="ref-2014.Gao" class="csl-entry" role="listitem">
<div class="csl-left-margin">[23] </div><div class="csl-right-inline">S.
Gao, G. V. Steeg, and A. Galstyan, <a
href="https://doi.org/10.48550/arxiv.1411.2003"><span
class="nocase">Efficient Estimation of Mutual Information for Strongly
Dependent Variables</span></a>, arXiv (2014).</div>
</div>
<div id="ref-2010.Tostevin" class="csl-entry" role="listitem">
<div class="csl-left-margin">[24] </div><div class="csl-right-inline">F.
Tostevin and P. R. ten Wolde, <a
href="https://doi.org/10.1103/PhysRevE.81.061917">Mutual information in
time-varying biochemical systems</a>, Phys. Rev. E <strong>81</strong>,
061917 (2010).</div>
</div>
<div id="ref-2019.Duso" class="csl-entry" role="listitem">
<div class="csl-left-margin">[25] </div><div class="csl-right-inline">L.
Duso and C. Zechner, <em><a
href="https://doi.org/10.1109/CDC40024.2019.9029316">Path Mutual
Information for a Class of Biochemical Reaction Networks</a></em>, in
<em>2019 IEEE 58th Conference on Decision and Control (CDC)</em> (2019),
pp. 6610‚Äì6615.</div>
</div>
<div id="ref-2023.Reinhardt" class="csl-entry" role="listitem">
<div class="csl-left-margin">[26] </div><div class="csl-right-inline">M.
Reinhardt, G. Tkaƒçik, and P. R. ten Wolde, <a
href="https://doi.org/10.1103/physrevx.13.041017"><span
class="nocase">Path Weight Sampling: Exact Monte Carlo Computation of
the Mutual Information between Stochastic Trajectories</span></a>,
Physical Review X <strong>13</strong>, 041017 (2023).</div>
</div>
<div id="ref-2023.Sinzger" class="csl-entry" role="listitem">
<div class="csl-left-margin">[27] </div><div class="csl-right-inline">M.
Sinzger-D‚ÄôAngelo and H. Koeppl, <a
href="https://doi.org/10.1109/tit.2023.3293996"><span
class="nocase">Counting Processes with Piecewise-Deterministic Markov
Conditional Intensity: Asymptotic Analysis, Implementation and
Information-Theoretic Use</span></a>, IEEE Transactions on Information
Theory 1 (2023).</div>
</div>
<div id="ref-2004.Barber" class="csl-entry" role="listitem">
<div class="csl-left-margin">[28] </div><div class="csl-right-inline">D.
Barber and F. Agakov, <em><span class="nocase">The IM Algorithm : A
variational approach to Information Maximization</span></em>, in
<em>Advances in Neural Information Processing Systems 16</em> (MIT
Press, Cambridge, Massachusetts, 2004), pp. 201‚Äì208.</div>
</div>
<div id="ref-2010.Nguyen" class="csl-entry" role="listitem">
<div class="csl-left-margin">[29] </div><div class="csl-right-inline">X.
Nguyen, M. J. Wainwright, and M. I. Jordan, <a
href="https://doi.org/10.1109/tit.2010.2068870"><span
class="nocase">Estimating Divergence Functionals and the Likelihood
Ratio by Convex Risk Minimization</span></a>, IEEE Transactions on
Information Theory <strong>56</strong>, 5847 (2010).</div>
</div>
<div id="ref-2016.Alemi" class="csl-entry" role="listitem">
<div class="csl-left-margin">[30] </div><div class="csl-right-inline">A.
A. Alemi, I. Fischer, J. V. Dillon, and K. Murphy, <a
href="https://doi.org/10.48550/arxiv.1612.00410"><span>Deep Variational
Information Bottleneck</span></a>, arXiv (2016).</div>
</div>
<div id="ref-2018.Belghazi" class="csl-entry" role="listitem">
<div class="csl-left-margin">[31] </div><div class="csl-right-inline">M.
I. Belghazi, A. Baratin, S. Rajeshwar, S. Ozair, Y. Bengio, A.
Courville, and D. Hjelm, <em><a
href="https://proceedings.mlr.press/v80/belghazi18a.html">Mutual
Information Neural Estimation</a></em>, in <em>Proceedings of the 35th
International Conference on Machine Learning</em>, edited by J. Dy and
A. Krause, Vol. 80 (PMLR, 2018), pp. 531‚Äì540.</div>
</div>
<div id="ref-2018.Oord" class="csl-entry" role="listitem">
<div class="csl-left-margin">[32] </div><div class="csl-right-inline">A.
van den Oord, Y. Li, and O. Vinyals, <a
href="https://doi.org/10.48550/arxiv.1807.03748"><span
class="nocase">Representation Learning with Contrastive Predictive
Coding</span></a>, arXiv (2018).</div>
</div>
<div id="ref-2019.Poole" class="csl-entry" role="listitem">
<div class="csl-left-margin">[33] </div><div class="csl-right-inline">B.
Poole, S. Ozair, A. van den Oord, A. A. Alemi, and G. Tucker, <a
href="https://doi.org/10.48550/arxiv.1905.06922"><span class="nocase">On
Variational Bounds of Mutual Information</span></a>, arXiv (2019).</div>
</div>
<div id="ref-2018.McAllester" class="csl-entry" role="listitem">
<div class="csl-left-margin">[34] </div><div class="csl-right-inline">D.
McAllester and K. Stratos, <a
href="https://doi.org/10.48550/arxiv.1811.04251"><span
class="nocase">Formal Limitations on the Measurement of Mutual
Information</span></a>, arXiv (2018).</div>
</div>
<div id="ref-2019.Kolchinsky" class="csl-entry" role="listitem">
<div class="csl-left-margin">[35] </div><div class="csl-right-inline">A.
Kolchinsky, B. D. Tracey, and D. H. Wolpert, <a
href="https://doi.org/10.3390/e21121181"><span>Nonlinear Information
Bottleneck</span></a>, Entropy <strong>21</strong>, 1181 (2019).</div>
</div>
<div id="ref-2019.Hledik" class="csl-entry" role="listitem">
<div class="csl-left-margin">[36] </div><div class="csl-right-inline">M.
Hled√≠k, T. R. Sokolowski, and G. Tkaƒçik, <em><a
href="https://doi.org/10.1109/itw44776.2019.8989292"><span
class="nocase">A Tight Upper Bound on Mutual
Information</span></a></em>, in <em>2019 IEEE Information Theory
Workshop (ITW)</em> (2019), pp. 1‚Äì5.</div>
</div>
<div id="ref-2016.Oord" class="csl-entry" role="listitem">
<div class="csl-left-margin">[37] </div><div class="csl-right-inline">A.
van den Oord, N. Kalchbrenner, and K. Kavukcuoglu, <em><a
href="https://proceedings.mlr.press/v48/oord16.html">Pixel Recurrent
Neural Networks</a></em>, in <em>Proceedings of the 33rd International
Conference on Machine Learning</em>, edited by M. F. Balcan and K. Q.
Weinberger, Vol. 48 (PMLR, New York, New York, USA, 2016), pp.
1747‚Äì1756.</div>
</div>
<div id="ref-2011.Sutskever" class="csl-entry" role="listitem">
<div class="csl-left-margin">[38] </div><div class="csl-right-inline">I.
Sutskever, J. Martens, and G. Hinton, <em><span
class="nocase">Generating text with recurrent neural
networks</span></em>, in <em>Proceedings of the 28th International
Conference on International Conference on Machine Learning</em>
(Omnipress, Madison, WI, USA, 2011), pp. 1017‚Äì1024.</div>
</div>
<div id="ref-2019.Muller" class="csl-entry" role="listitem">
<div class="csl-left-margin">[39] </div><div class="csl-right-inline">T.
M√ºller, B. Mcwilliams, F. Rousselle, M. Gross, and J. Nov√°k, <a
href="https://doi.org/10.1145/3341156"><span>Neural Importance
Sampling</span></a>, ACM Transactions on Graphics (TOG)
<strong>38</strong>, 1 (2019).</div>
</div>
<div id="ref-2024.Fan" class="csl-entry" role="listitem">
<div class="csl-left-margin">[40] </div><div class="csl-right-inline">R.
Fan and A. Hilfinger, <a
href="https://doi.org/10.1103/physreve.110.034309"><span
class="nocase">Characterizing the nonmonotonic behavior of mutual
information along biochemical reaction cascades</span></a>, Physical
Review E <strong>110</strong>, 034309 (2024).</div>
</div>
<div id="ref-1998.Frey" class="csl-entry" role="listitem">
<div class="csl-left-margin">[41] </div><div class="csl-right-inline">B.
J. Frey, <em>Graphical Models for Machine Learning and Digital
Communication</em> (The MIT Press, 1998).</div>
</div>
<div id="ref-2013.Graves" class="csl-entry" role="listitem">
<div class="csl-left-margin">[42] </div><div class="csl-right-inline">A.
Graves, <a
href="https://doi.org/10.48550/arxiv.1308.0850"><span>Generating
Sequences With Recurrent Neural Networks</span></a>, arXiv (2013).</div>
</div>
<div id="ref-2014.Bayer" class="csl-entry" role="listitem">
<div class="csl-left-margin">[43] </div><div class="csl-right-inline">J.
Bayer and C. Osendorfer, <a
href="https://doi.org/10.48550/arxiv.1411.7610"><span>Learning
Stochastic Recurrent Networks</span></a>, arXiv (2014).</div>
</div>
<div id="ref-2017.Vaswani" class="csl-entry" role="listitem">
<div class="csl-left-margin">[44] </div><div class="csl-right-inline">A.
Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L.
Kaiser, and I. Polosukhin, <a
href="https://doi.org/10.48550/arxiv.1706.03762"><span>Attention Is All
You Need</span></a>, arXiv (2017).</div>
</div>
<div id="ref-2018.Devlin" class="csl-entry" role="listitem">
<div class="csl-left-margin">[45] </div><div class="csl-right-inline">J.
Devlin, M.-W. Chang, K. Lee, and K. Toutanova, <a
href="https://doi.org/10.48550/arxiv.1810.04805"><span
class="nocase">BERT: Pre-training of Deep Bidirectional Transformers for
Language Understanding</span></a>, arXiv (2018).</div>
</div>
<div id="ref-1997.Hochreiter" class="csl-entry" role="listitem">
<div class="csl-left-margin">[46] </div><div class="csl-right-inline">S.
Hochreiter and J. Schmidhuber, <a
href="https://doi.org/10.1162/neco.1997.9.8.1735"><span>Long Short-Term
Memory</span></a>, Neural Computation <strong>9</strong>, 1735
(1997).</div>
</div>
<div id="ref-2014.Cho" class="csl-entry" role="listitem">
<div class="csl-left-margin">[47] </div><div class="csl-right-inline">K.
Cho, B. van Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares, H.
Schwenk, and Y. Bengio, <a
href="https://doi.org/10.48550/arxiv.1406.1078"><span
class="nocase">Learning Phrase Representations using RNN Encoder-Decoder
for Statistical Machine Translation</span></a>, arXiv (2014).</div>
</div>
<div id="ref-2017.Papamakarios" class="csl-entry" role="listitem">
<div class="csl-left-margin">[48] </div><div class="csl-right-inline">G.
Papamakarios, T. Pavlakou, and I. Murray, <em><a
href="https://proceedings.neurips.cc/paper_files/paper/2017/file/6c1da886822c67822bcf3679d04369fa-Paper.pdf">Masked
Autoregressive Flow for Density Estimation</a></em>, in <em>Advances in
Neural Information Processing Systems</em>, edited by I. Guyon, U. V.
Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R.
Garnett, Vol. 30 (Curran Associates, Inc., 2017).</div>
</div>
<div id="ref-2006.Bishop" class="csl-entry" role="listitem">
<div class="csl-left-margin">[49] </div><div class="csl-right-inline">C.
M. Bishop, <em>Pattern Recognition and Machine Learning</em>, 1st ed.
(Springer, New York, 2006).</div>
</div>
<div id="ref-2010.Bottou" class="csl-entry" role="listitem">
<div class="csl-left-margin">[50] </div><div class="csl-right-inline">L.
Bottou, <em><a
href="https://doi.org/10.1007/978-3-7908-2604-3\_16"><span
class="nocase">Large-Scale Machine Learning with Stochastic Gradient
Descent</span></a></em>, in <em>Proceedings of COMPSTATS‚Äô2010</em>
(Physica-Verlag HD, Heidelberg, Germany, 2010), pp. 177‚Äì186.</div>
</div>
<div id="ref-2021.Feng" class="csl-entry" role="listitem">
<div class="csl-left-margin">[51] </div><div class="csl-right-inline">Y.
Feng and Y. Tu, <a href="https://doi.org/10.1073/pnas.2015617118"><span
class="nocase">The inverse variance‚Äìflatness relation in stochastic
gradient descent is critical for finding flat minima</span></a>,
Proceedings of the National Academy of Sciences <strong>118</strong>,
e2015617118 (2021).</div>
</div>
<div id="ref-1976.Bennett" class="csl-entry" role="listitem">
<div class="csl-left-margin">[52] </div><div class="csl-right-inline">C.
H. Bennett, <a href="https://doi.org/10.1016/0021-9991(76)90078-4"><span
class="nocase">Efficient estimation of free energy differences from
Monte Carlo data</span></a>, Journal of Computational Physics
<strong>22</strong>, 245 (1976).</div>
</div>
<div id="ref-1989.Geweke" class="csl-entry" role="listitem">
<div class="csl-left-margin">[53] </div><div class="csl-right-inline">J.
Geweke, <span class="nocase">Bayesian Inference in Econometric Models
Using Monte Carlo Integration</span>, Econometrica (1989).</div>
</div>
<div id="ref-2013.Kingma" class="csl-entry" role="listitem">
<div class="csl-left-margin">[54] </div><div class="csl-right-inline">D.
P. Kingma and M. Welling, <a
href="https://doi.org/10.48550/arxiv.1312.6114"><span>Auto-Encoding
Variational Bayes</span></a>, arXiv (2013).</div>
</div>
<div id="ref-2015.Rezende" class="csl-entry" role="listitem">
<div class="csl-left-margin">[55] </div><div class="csl-right-inline">D.
Rezende and S. Mohamed, <a
href="https://proceedings.mlr.press/v37/rezende15.html"><span
class="nocase">Variational Inference with Normalizing Flows</span></a>,
Proceedings of Machine Learning Research <strong>37</strong>, 1530
(2015).</div>
</div>
<div id="ref-2016.Dinh" class="csl-entry" role="listitem">
<div class="csl-left-margin">[56] </div><div class="csl-right-inline">L.
Dinh, J. Sohl-Dickstein, and S. Bengio, <a
href="https://doi.org/10.48550/arxiv.1605.08803"><span
class="nocase">Density estimation using Real NVP</span></a>, arXiv
(2016).</div>
</div>
<div id="ref-2016.Kingma" class="csl-entry" role="listitem">
<div class="csl-left-margin">[57] </div><div class="csl-right-inline">D.
P. Kingma, T. Salimans, R. Jozefowicz, X. Chen, I. Sutskever, and M.
Welling, <a href="https://doi.org/10.48550/arxiv.1606.04934"><span
class="nocase">Improving Variational Inference with Inverse
Autoregressive Flow</span></a>, arXiv (2016).</div>
</div>
<div id="ref-2018.VanDenBerg" class="csl-entry" role="listitem">
<div class="csl-left-margin">[58] </div><div class="csl-right-inline">R.
Van Den Berg, L. Hasenclever, J. M. Tomczak, and M. Welling,
<em>Sylvester Normalizing Flows for Variational Inference</em>, in
<em>34th Conference on Uncertainty in Artificial Intelligence 2018, UAI
2018</em>, edited by A. Globerson, A. Globerson, and R. Silva
(Association For Uncertainty in Artificial Intelligence (AUAI), 2018),
pp. 393‚Äì402.</div>
</div>
<div id="ref-2018.Kingma" class="csl-entry" role="listitem">
<div class="csl-left-margin">[59] </div><div class="csl-right-inline">D.
P. Kingma and P. Dhariwal, <a
href="https://doi.org/10.48550/arxiv.1807.03039"><span
class="nocase">Glow: Generative Flow with Invertible 1x1
Convolutions</span></a>, arXiv (2018).</div>
</div>
<div id="ref-2019.Kobyzev" class="csl-entry" role="listitem">
<div class="csl-left-margin">[60] </div><div class="csl-right-inline">I.
Kobyzev, S. J. D. Prince, and M. A. Brubaker, <a
href="https://doi.org/10.1109/tpami.2020.2992934"><span
class="nocase">Normalizing Flows: An Introduction and Review of Current
Methods</span></a>, IEEE Transactions on Pattern Analysis and Machine
Intelligence <strong>43</strong>, 3964 (2019).</div>
</div>
<div id="ref-2021.Papamakarios" class="csl-entry" role="listitem">
<div class="csl-left-margin">[61] </div><div class="csl-right-inline">G.
Papamakarios, E. Nalisnick, D. J. Rezende, S. Mohamed, and B.
Lakshminarayanan, <a
href="http://jmlr.org/papers/v22/19-1028.html"><span
class="nocase">Normalizing Flows for Probabilistic Modeling and
Inference</span></a>, Journal of Machine Learning Research
<strong>22</strong>, 1 (2021).</div>
</div>
<div id="ref-2014.Sutskever" class="csl-entry" role="listitem">
<div class="csl-left-margin">[62] </div><div class="csl-right-inline">I.
Sutskever, O. Vinyals, and Q. V. Le, <a
href="https://doi.org/10.48550/arxiv.1409.3215"><span
class="nocase">Sequence to Sequence Learning with Neural
Networks</span></a>, arXiv (2014).</div>
</div>
<div id="ref-2019.Ho" class="csl-entry" role="listitem">
<div class="csl-left-margin">[63] </div><div class="csl-right-inline">J.
Ho, X. Chen, A. Srinivas, Y. Duan, and P. Abbeel, <a
href="https://doi.org/10.48550/arxiv.1902.00275"><span
class="nocase">Flow++: Improving Flow-Based Generative Models with
Variational Dequantization and Architecture Design</span></a>, arXiv
(2019).</div>
</div>
<div id="ref-2005.Edelstein-Keshet" class="csl-entry" role="listitem">
<div class="csl-left-margin">[64] </div><div class="csl-right-inline">L.
Edelstein-Keshet, <em>Mathematical Models in Biology</em> (Society for
Industrial; Applied Mathematics, USA, 2005).</div>
</div>
<div id="ref-2014.Kingma" class="csl-entry" role="listitem">
<div class="csl-left-margin">[65] </div><div class="csl-right-inline">D.
P. Kingma and J. Ba, <a
href="https://doi.org/10.48550/arxiv.1412.6980"><span
class="nocase">Adam: A Method for Stochastic Optimization</span></a>,
arXiv (2014).</div>
</div>
<div id="ref-2017.Loshchilov" class="csl-entry" role="listitem">
<div class="csl-left-margin">[66] </div><div class="csl-right-inline">I.
Loshchilov and F. Hutter, <a
href="https://doi.org/10.48550/arxiv.1711.05101"><span>Decoupled Weight
Decay Regularization</span></a>, arXiv (2017).</div>
</div>
<div id="ref-2016.Loshchilov" class="csl-entry" role="listitem">
<div class="csl-left-margin">[67] </div><div class="csl-right-inline">I.
Loshchilov and F. Hutter, <a
href="https://doi.org/10.48550/arxiv.1608.03983"><span
class="nocase">SGDR: Stochastic Gradient Descent with Warm
Restarts</span></a>, arXiv (2016).</div>
</div>
<div id="ref-2017.Martino" class="csl-entry" role="listitem">
<div class="csl-left-margin">[68] </div><div class="csl-right-inline">L.
Martino, V. Elvira, and F. Louzada, <a
href="https://doi.org/10.1016/j.sigpro.2016.08.025"><span
class="nocase">Effective sample size for importance sampling based on
discrepancy measures</span></a>, Signal Processing <strong>131</strong>,
386 (2017).</div>
</div>
<div id="ref-mitra2001nonlinear" class="csl-entry" role="listitem">
<div class="csl-left-margin">[69] </div><div class="csl-right-inline">P.
P. Mitra and J. B. Stark, Nonlinear limits to the information capacity
of optical fibre communications, Nature <strong>411</strong>, 1027
(2001).</div>
</div>
<div id="ref-2006.Cover" class="csl-entry" role="listitem">
<div class="csl-left-margin">[70] </div><div class="csl-right-inline">T.
M. Cover and J. A. Thomas, <em><span class="nocase">Elements of
Information Theory</span></em>, 2nd ed. (John Wiley &amp; Sons,
2006).</div>
</div>
<div id="ref-2003.Lin" class="csl-entry" role="listitem">
<div class="csl-left-margin">[71] </div><div class="csl-right-inline">J.
Lin, E. Keogh, S. Lonardi, and B. Chiu, <em><a
href="https://doi.org/10.1145/882082.882086">A Symbolic Representation
of Time Series, with Implications for Streaming Algorithms</a></em>, in
<em>Proceedings of the 8th ACM SIGMOD Workshop on Research Issues in
Data Mining and Knowledge Discovery</em> (Association for Computing
Machinery, New York, NY, USA, 2003), pp. 2‚Äì11.</div>
</div>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>See also <a href="#ch:lna_vs_pws">Ch. lna_vs_pws</a>,
where we extensively discuss the limitations of the Gaussian
approximation for nonlinear systems.<a href="#fnref1"
class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
</ol>
</section>
</body>
</html>
