<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <link rel="sitemap" type="application/xml" href="/sitemap.xml">
  <title>Path Weight Sampling</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <link rel="stylesheet" href="../css/thesis-style.css" />
  <a href="../index.html" class="back-link">â† Back to Contents</a>
  <script src="../js/equation-tooltips.js"></script>
</head>
<body>
<header id="title-block-header">
<h1 class="title">Path Weight Sampling</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#abstract" id="toc-abstract">Abstract</a></li>
<li><a href="#path-weight-sampling" id="toc-path-weight-sampling">Path
Weight Sampling</a>
<ul>
<li><a href="#monte-carlo-estimate-of-the-mutual-information"
id="toc-monte-carlo-estimate-of-the-mutual-information">Monte Carlo
Estimate of the Mutual Information</a>
<ul>
<li><a href="#statement-of-the-problem"
id="toc-statement-of-the-problem">Statement of the Problem</a></li>
<li><a href="#direct-pws" id="toc-direct-pws"> Direct PWS</a></li>
<li><a href="#driven-markov-jump-process"
id="toc-driven-markov-jump-process"> Driven Markov Jump Process</a></li>
<li><a href="#input-statistics" id="toc-input-statistics">Input
Statistics</a></li>
</ul></li>
<li><a href="#integrating-out-internal-components"
id="toc-integrating-out-internal-components">Integrating Out Internal
Components </a></li>
<li><a href="#dealing-with-feedback"
id="toc-dealing-with-feedback">Dealing with Feedback</a>
<ul>
<li><a
href="#computing-the-mutual-information-with-feedback-between-input-and-output"
id="toc-computing-the-mutual-information-with-feedback-between-input-and-output">Computing
the Mutual Information with Feedback between Input and Output</a></li>
<li><a href="#marginalization-integrals-for-systems-with-feedback"
id="toc-marginalization-integrals-for-systems-with-feedback">Marginalization
Integrals for Systems with Feedback</a></li>
</ul></li>
<li><a href="#discussion" id="toc-discussion">Discussion</a></li>
</ul></li>
<li><a href="#bibliography" id="toc-bibliography">References</a></li>
</ul>
</nav>
<h1 id="abstract">Abstract</h1>
<blockquote>
<p>Most natural and engineered information-processing systems transmit
information via signals that vary in time. Computing the information
transmission rate or the information encoded in the temporal
characteristics of these signals requires the mutual information between
the input and output signals as a function of time, i.e., between the
input and output trajectories. Yet, this is notoriously difficult
because of the high-dimensional nature of the trajectory space, and all
existing techniques require approximations. We present an exact Monte
Carlo technique called Path Weight Sampling (PWS) that, for the first
time, makes it possible to compute the mutual information between input
and output trajectories for any stochastic system that is described by a
master equation. The principal idea is to use the master equation to
evaluate the exact conditional probability of an individual output
trajectory for a given input trajectory and average this via Monte Carlo
sampling in trajectory space to obtain the mutual information. PWS also
makes it possible to compute the mutual information between input and
output trajectories for systems with hidden internal states as well as
systems with feedback from output to input.</p>
</blockquote>
<h1 id="ch:dpws" id="path-weight-sampling">Path Weight Sampling</h1>
<p>Quantifying information transmission is vital for understanding and
designing natural and engineered information-processing systems, ranging
from biochemical and neural networks, to electronic circuits and optical
systemsÂ <span class="citation"
data-cites="2011.Tkacik 2016.Tkacik 2003.MacKay">Â [<a
href="#ref-2011.Tkacik" role="doc-biblioref">1</a>â€“<a
href="#ref-2003.MacKay" role="doc-biblioref">3</a>]</span>. Claude
Shannon introduced the mutual information and the information rate as
the central measures of Information Theory more than 70 years agoÂ <span
class="citation" data-cites="1948.Shannon">Â [<a href="#ref-1948.Shannon"
role="doc-biblioref">4</a>]</span>. These measures quantify the fidelity
by which a noisy system transmits information from its inputs to its
outputs. Yet, computing these quantities exactly remains notoriously
difficult, if not impossible. This is because the inputs and outputs are
often not scalar values, but rather temporal trajectories.</p>
<p>Most, if not all, information-processing systems transmit signal that
vary in time. The canonical measure for quantifying information
transmission via time-varying signals is the mutual information rate
<span class="citation"
data-cites="1948.Shannon 2006.Cover 2009.Tostevin 2014.Fiedor">Â [<a
href="#ref-1948.Shannon" role="doc-biblioref">4</a>â€“<a
href="#ref-2014.Fiedor" role="doc-biblioref">7</a>]</span>. It
quantifies the speed at which distinct messages are transmitted through
the system, and it depends not only on the accuracy of the input-output
mapping but also on the correlations within the input and output
signals. Computing the mutual information rate thus requires computing
the mutual information between the input and output trajectories, not
between their signal values at given time points. The rate at which this
trajectory mutual information increases with the trajectory duration in
the long-time limit defines the mutual information rate, see <a
href="#eq:intro-info-rate">eq:intro-info-rate</a>. In the absence of
feedback this rate also equals the multi-step transfer entropy <span
class="citation" data-cites="1990.Massey 2000.Schreiber">Â [<a
href="#ref-1990.Massey" role="doc-biblioref">8</a>,<a
href="#ref-2000.Schreiber" role="doc-biblioref">9</a>]</span>.</p>
<p>More generally, useful information is often contained in the temporal
dynamics of the signal. A prime example is bacterial chemotaxis, where
the response does not depend on the current ligand concentration, but
rather on whether it has changed in the recent past <span
class="citation" data-cites="1983.Block 1986.Segall">Â [<a
href="#ref-1983.Block" role="doc-biblioref">10</a>,<a
href="#ref-1986.Segall" role="doc-biblioref">11</a>]</span>. Moreover,
the information from the input may be encoded in the temporal dynamics
of the output <span class="citation"
data-cites="1995.Marshall 2013.Purvis 2014.Selimkhanov 2018.Granados">Â [<a
href="#ref-1995.Marshall" role="doc-biblioref">12</a>â€“<a
href="#ref-2018.Granados" role="doc-biblioref">15</a>]</span>.
Quantifying information encoded in these temporal features of the
signals requires the mutual information not between two time points,
i.e. the instantaneous mutual information, but rather between input and
output trajectories <span class="citation"
data-cites="2009.Tostevin">Â [<a href="#ref-2009.Tostevin"
role="doc-biblioref">6</a>]</span>.</p>
<p>Unfortunately, computing the mutual information between trajectories
is exceptionally difficult. The conventional approach requires
non-parametric distribution estimates of the input and output
distributions, e.g. via histograms of data obtained through simulations
or experiments <span class="citation"
data-cites="1998.Strong 2003.Paninski 2011.Cheong 2008.Tkacik 2014.Tkacik 2021.Meijers">Â [<a
href="#ref-1998.Strong" role="doc-biblioref">16</a>â€“<a
href="#ref-2021.Meijers" role="doc-biblioref">21</a>]</span>. These
non-parametric distribution estimates are necessary because the mutual
information cannot generally be computed from summary statistics like
the mean or variance of the data alone. However, the high-dimensional
nature of trajectories makes it infeasible to obtain enough empirical
data to accurately estimate the required probability distributions.
Moreover, this approach requires the discretization of time, which
becomes problematic when the information is encoded in the precise
timing of signal spikes, as, e.g., in neuronal systems <span
class="citation" data-cites="1999.Rieke">Â [<a href="#ref-1999.Rieke"
role="doc-biblioref">22</a>]</span>. Except for the simplest systems
with a binary state space <span class="citation"
data-cites="2021.Meijers">Â [<a href="#ref-2021.Meijers"
role="doc-biblioref">21</a>]</span>, the conventional approach to
estimate the mutual information via histograms therefore cannot be
transposed to trajectories.</p>
<p>Because there are currently no general schemes available to compute
the mutual information between trajectories exactly, approximate methods
or simplified models are typically used. While empirical distribution
estimates can be avoided by employing the K-nearest-neighbors entropy
estimator <span class="citation"
data-cites="2002.Kaiser 2004.Kraskov">Â [<a href="#ref-2002.Kaiser"
role="doc-biblioref">23</a>,<a href="#ref-2004.Kraskov"
role="doc-biblioref">24</a>]</span>, this method depends on a choice of
metric in trajectory space and can become unreliable for long
trajectories <span class="citation"
data-cites="2019.Cepeda-Humerez">Â [<a href="#ref-2019.Cepeda-Humerez"
role="doc-biblioref">25</a>]</span>. AÌ±lternative, decoding-based
information estimates can be developed for trajectories <span
class="citation" data-cites="2008.Gao">Â [<a href="#ref-2008.Gao"
role="doc-biblioref">26</a>]</span>, but merely provide a lower bound of
the mutual information, and it remains unclear how tight these lower
bounds areÂ <span class="citation"
data-cites="1999.Borst 2019.Cepeda-Humerez 2019.Hledik">Â [<a
href="#ref-2019.Cepeda-Humerez" role="doc-biblioref">25</a>,<a
href="#ref-1999.Borst" role="doc-biblioref">27</a>,<a
href="#ref-2019.Hledik" role="doc-biblioref">28</a>]</span>. Analytical
results are avaiable for simple systems <span class="citation"
data-cites="2016.Thomas">Â [<a href="#ref-2016.Thomas"
role="doc-biblioref">29</a>]</span>, and for linear systems that obey
Gaussian statistics, the mutual information between trajectories can be
obtained from the covariance matrix <span class="citation"
data-cites="2009.Tostevin">Â [<a href="#ref-2009.Tostevin"
role="doc-biblioref">6</a>]</span>. However, many information processing
systems are complex and non-linear such that the Gaussian approximation
does not hold, and analytical solutions do not exist. A more promising
approach to estimate the trajectory mutual information for chemical
reaction networks has been developed by Duso and Zechner <span
class="citation" data-cites="2019.Duso">Â [<a href="#ref-2019.Duso"
role="doc-biblioref">30</a>]</span> and generalized in Ref.Â <span
class="citation" data-cites="2023.Moor">Â [<a href="#ref-2023.Moor"
role="doc-biblioref">31</a>]</span>. However, the scheme relies on a
moment closure approximation and has so far only been applied to very
simple networks, seemingly being difficult to extend to complex
systems.</p>
<p>Here, we present <em>Path Weight Sampling</em> (PWS), an exact
technique to compute the trajectory mutual information for any system
described by a master equation. Master equations are widely used to
model chemical reaction networks <span class="citation"
data-cites="1940.Delbrueck 1963.McQuarrie 1964.McQuarrie 2000.Elowitz">Â [<a
href="#ref-1940.Delbrueck" role="doc-biblioref">32</a>â€“<a
href="#ref-2000.Elowitz" role="doc-biblioref">35</a>]</span>, biological
population growth <span class="citation"
data-cites="1939.Feller 2010.Park 2012.Cremer">Â [<a
href="#ref-1939.Feller" role="doc-biblioref">36</a>â€“<a
href="#ref-2012.Cremer" role="doc-biblioref">38</a>]</span>, economic
processes <span class="citation"
data-cites="1992.Weidlich 1995.Lux">Â [<a href="#ref-1992.Weidlich"
role="doc-biblioref">39</a>,<a href="#ref-1995.Lux"
role="doc-biblioref">40</a>]</span>, and a large variety of other
systems <span class="citation"
data-cites="2001.Helbing 2009.Castellano">Â [<a href="#ref-2001.Helbing"
role="doc-biblioref">41</a>,<a href="#ref-2009.Castellano"
role="doc-biblioref">42</a>]</span>, making our scheme of interest to a
broad class of problems.</p>
<p>PWS is an exact Monte Carlo scheme, in the sense that it provides an
unbiased statistical estimate of the trajectory mutual information. In
PWS, the mutual information is computed as the difference between the
marginal output entropy associated with the marginal distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>
of the output trajectories
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’™</mi><annotation encoding="application/x-tex">\mathbfit{x}</annotation></semantics></math>,
and the conditional output entropy associated with the output
distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>
conditioned on the input trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>.
Our scheme is inspired by the observation of Cepeda-Humerez et al. <span
class="citation" data-cites="2019.Cepeda-Humerez">Â [<a
href="#ref-2019.Cepeda-Humerez" role="doc-biblioref">25</a>]</span> that
the path likelihood, i.e., the probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|s]</annotation></semantics></math>,
can be computed exactly from the master equation for a <em>static</em>
input signal
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>.
This makes it possible to compute the mutual information between a
discrete input and a time-varying output via a Monte Carlo averaging
procedure of the likelihoods, rather than from an empirical estimate of
the intractable high-dimensional probability distribution functions. The
scheme of Cepeda-Humerez et al. <span class="citation"
data-cites="2019.Cepeda-Humerez">Â [<a href="#ref-2019.Cepeda-Humerez"
role="doc-biblioref">25</a>]</span> is however limited to discrete input
signals that do not vary in time. Here we show that the path likelihood
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>
can also be computed for a dynamical input <em>trajectory</em>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>,
which allows us to compute the conditional output entropy also for
time-varying inputs. While this solves the problem in part, the marginal
output entropy associated with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>
cannot be computed with the approach of Cepeda-Humerez et al. <span
class="citation" data-cites="2019.Cepeda-Humerez">Â [<a
href="#ref-2019.Cepeda-Humerez" role="doc-biblioref">25</a>]</span>, and
thus requires a different scheme.</p>
<p>In <a href="#sec:sec2">Sec. sec2</a> we show how, for time-varying
input signals, the marginal probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>
can be obtained as a Monte Carlo average of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>
over a large number of input trajectories. We then use the Monte Carlo
estimate for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>
to compute the marginal output entropy.</p>
<p>In <a href="#sec:integrating-out">Sec. integrating-out</a> we show
that, surprisingly, our PWS methods additionally make it possible to
compute the mutual information between input and output trajectories of
systems with hidden internal states. Hidden states correspond, for
example, to network components that merely relay, process or transform
the signal from the input to the output. Indeed, the downstream system
typically responds to the information that is encoded in this output,
and not the other internal system components. Most information
processing systems contain such hidden states, and generally we want to
integrate out these latent network components. In addition, we can
generalize PWS to systems with feedback from the output to the input as
shown in <a href="#sec:feedback">Sec. feedback</a>.</p>
<h2 id="sec:sec2"
id="monte-carlo-estimate-of-the-mutual-information">Monte Carlo Estimate
of the Mutual Information</h2>
<p>In this section we present the fundamental ideas of PWS. These ideas
lie at the heart of Direct PWS (DPWS) and also form the foundation of
the other two more advanced PWS variants which will be explained in <a
href="#ch:variants">Ch. variants</a>.</p>
<h3 id="statement-of-the-problem">Statement of the Problem</h3>
<p>All information processing systems repeatedly take an input value
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>
and produce a corresponding output
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>.
Due to noise, the output produced for the same input can be different
every time, such that the system samples outputs from the distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm P(x|s)</annotation></semantics></math>.
In the information theoretic sense, the deviceâ€™s capabilities are fully
specified by its output distributions for all possible inputs. We
consider the inputs as being distributed according to a probability
density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>s</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(s)</annotation></semantics></math>
such that the whole setup of signal and device is completely described
by the joint probability density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>s</mi><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(s, x) = \mathrm{P}(s)\,\mathrm P(x|s)</annotation></semantics></math>.</p>
<p>When the conditional output distributions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm P(x|s)</annotation></semantics></math>
overlap with each other, information is lost because the input can not
always be inferred uniquely from the output (see <a
href="#fig:information">Fig. information</a>). The remaining information
that the output carries about the signal on average is quantified by the
mutual information between input and output.</p>
<figure id="fig:information">
<img src="../images/mi-schema.svg"  />
<figcaption> Schematic of information processing under the influence of
noise. Overlapping output distributions for different inputs lead to
information loss, because the input cannot always be uniquely inferred
from the output. The mutual information
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">I</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo>,</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{I}(\mathcal{S},\mathcal{X})</annotation></semantics></math>
quantifies how much information the observation of the output typically
retains about the input signal. </figcaption>
</figure>
<p>Mathematically, the mutual information between a random variable
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’®</mi><annotation encoding="application/x-tex">\mathcal{S}</annotation></semantics></math>,
representing the input, and a second random variable
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’³</mi><annotation encoding="application/x-tex">\mathcal{X}</annotation></semantics></math>,
representing the output, is defined as </p>
<div id="eq:mutual_information">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">I</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo>,</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mo>âˆ¬</mo><mi>d</mi><mi>s</mi><mspace width="0.167em"></mspace><mi>d</mi><mi>x</mi><mspace width="0.222em"></mspace><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mfrac><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>s</mi><mo stretchy="false" form="postfix">)</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow></mfrac><mspace width="0.167em"></mspace><mo>,</mo></mrow><annotation encoding="application/x-tex">\mathrm I(\mathcal{S}, \mathcal{X}) = \iint ds\,dx\  \mathrm{P}(s, x) \ln \frac{\mathrm{P}(s, x)}{\mathrm{P}(s) \mathrm{P}(x)}\,,
    \label{eq:mutual_information}</annotation></semantics></math>
</div>
<p> where the marginal output distribution is given by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mo>âˆ«</mo><mi>d</mi><mi>s</mi><mspace width="0.222em"></mspace><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x) = \int ds\ \mathrm{P}(s, x)</annotation></semantics></math>.
The quantity
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">I</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo>,</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm I(\mathcal{S}, \mathcal{X})</annotation></semantics></math>
as defined above is a non-negative real number, representing the mutual
information between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’®</mi><annotation encoding="application/x-tex">\mathcal{S}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’³</mi><annotation encoding="application/x-tex">\mathcal{X}</annotation></semantics></math>
in nats. á¹®he integrals in <a
href="#eq:mutual_information">eq:mutual_information</a> run over all
possible realizations of the random variables
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’®</mi><annotation encoding="application/x-tex">\mathcal{S}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’³</mi><annotation encoding="application/x-tex">\mathcal{X}</annotation></semantics></math>.
In our case,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’®</mi><annotation encoding="application/x-tex">\mathcal{S}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’³</mi><annotation encoding="application/x-tex">\mathcal{X}</annotation></semantics></math>
represent stochastic trajectories and so the integrals become path
integrals.</p>
<p>In general, the mutual information can be decomposed into two terms,
a conditional and marginal entropy. Due to the symmetry of <a
href="#eq:mutual_information">eq:mutual_information</a> with respect to
exchange of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’®</mi><annotation encoding="application/x-tex">\mathcal{S}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’³</mi><annotation encoding="application/x-tex">\mathcal{X}</annotation></semantics></math>,
this decomposition can be written as </p>
<div id="eq:mutual_information_entropies">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">I</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo>,</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo stretchy="false" form="postfix">)</mo><mo>âˆ’</mo><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo><mo>âˆ’</mo><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’³</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’®</mi><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">\mathrm I(\mathcal{S}, \mathcal{X}) = \mathrm{H}(\mathcal{S}) - \mathrm{H}(\mathcal{S}|\mathcal{X}) = \mathrm{H}(\mathcal{X}) - \mathrm{H}(\mathcal{X}|\mathcal{S})\,.
    \label{eq:mutual_information_entropies}</annotation></semantics></math>
</div>
<p> The (marginal) input entropy
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{H}(\mathcal{S})</annotation></semantics></math>
represents the total uncertainty about the input, and the conditional
input entropy
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{H}(\mathcal{S}|\mathcal{X})</annotation></semantics></math>
describes the remaining uncertainty of the input after having observed
the output. Thus, the mutual information
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">I</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo>,</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo stretchy="false" form="postfix">)</mo><mo>âˆ’</mo><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{I}(\mathcal{S},\mathcal{X})=\mathrm{H}(\mathcal{S}) - \mathrm{H}(\mathcal{S}|\mathcal{X})</annotation></semantics></math>
naturally quantifies the reduction in uncertainty about the input
through the observation of the output.</p>
<p>When analyzing data from experiments or simulations however, the
mutual information is generally estimated via
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">I</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo>,</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo><mo>âˆ’</mo><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’³</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’®</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{I}(\mathcal{S},\mathcal{X})=\mathrm{H}(\mathcal{X}) - \mathrm{H}(\mathcal{X}|\mathcal{S})</annotation></semantics></math>.
á¹®his is because simulation or experimental data generally provide
information about the distribution of outputs for a given input, rather
than vice versa. The accessible entropies are thus the marginal output
entropy
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{H}(\mathcal{X})</annotation></semantics></math>
and the conditional output entropy
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’³</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’®</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{H}(\mathcal{X}|\mathcal{S})</annotation></semantics></math>,
which are defined as </p>
<div id="eq:marginal-entropy">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><mi>âˆ’</mi><mo>âˆ«</mo><mi>d</mi><mi>x</mi><mspace width="0.222em"></mspace><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’³</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’®</mi><mo stretchy="false" form="postfix">)</mo></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><mi>âˆ’</mi><mo>âˆ«</mo><mi>d</mi><mi>s</mi><mspace width="0.222em"></mspace><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>s</mi><mo stretchy="false" form="postfix">)</mo><mo>âˆ«</mo><mi>d</mi><mi>x</mi><mspace width="0.222em"></mspace><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo stretchy="false" form="postfix">)</mo><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
    \mathrm{H}(\mathcal{X}) &amp;= -\int dx\ \mathrm{P}(x) \ln \mathrm{P}(x)
    \label{eq:marginal-entropy} \\
    \mathrm{H}(\mathcal{X}|\mathcal{S}) &amp;= -\int ds\ \mathrm{P}(s) \int dx\  \mathrm{P}(x|s) \ln \mathrm{P}(x|s) \,.
    \label{eq:conditional-entropy}
\end{aligned}</annotation></semantics></math>
</div>
<p>The conventional way of computing the mutual information involves
generating many samples to obtain empirical distribution estimates for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x|s)</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x)</annotation></semantics></math>
via histograms. However, the number of samples needs to be substantially
larger than the number of histogram bins to reduce the noise in the bin
counts. Obtaining enough samples is effectively impossible for
high-dimensional data, like signal trajectories. Moreover, any nonzero
bin size leads to a systematic bias in the entropy estimates, even in
one dimension <span class="citation" data-cites="2003.Paninski">Â [<a
href="#ref-2003.Paninski" role="doc-biblioref">17</a>]</span>. These
limitations of the conventional method make it impractical for
high-dimensional data, highlighting the need for alternative approaches
to accurately compute mutual information for trajectories.</p>
<h3 id="sec:algorithm" id="direct-pws"> Direct PWS</h3>
<figure id="fig:algorithm">
<img src="../images/Algorithm.svg"  />
<figcaption>The PWS framework to compute the mutual information between
trajectories in 4 steps. <strong>1</strong>.Â Generate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
input-output pairs from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s},\mathbfit{x}]</annotation></semantics></math>.
<strong>2</strong>.Â For each input-output pair compute the trajectory
likelihood
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msub><mi>ğ’™</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>ğ’”</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}_i|\mathbfit{s}_i]</annotation></semantics></math>
using <a href="#eq:traj_prob">eq:traj_prob</a>.
<strong>3</strong>.Â Compute
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msub><mi>ğ’™</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}_i]</annotation></semantics></math>
for every output. This step differentiates the different variants of PWS
from each other. Direct PWS is presented in this chapter, whereas RR-PWS
and TI-PWS are described in <a href="#ch:variants">Ch. variants</a>.
<strong>4</strong>.Â Using the likelihoods and the marginal probabilities
from the previous steps we can estimate the mutual information using <a
href="#eq:average-of-differences">eq:average-of-differences</a>.
</figcaption>
</figure>
<p>The central idea of PWS is to compute probability densities for
trajectories exactly, sidestepping the problem having to estimate them
via histograms. We exploit that for systems described by a master
equation, the conditional probability of an output trajectory for a
given input trajectory can be computed analytically. With this insight
we can derive a procedure to compute the mutual information.
Specifically, we will show that</p>
<ul>
<li><p>for a system described by a master equation, the trajectory
likelihood
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>
is a quantity that can be computed on the fly in a stochastic
simulation;</p></li>
<li><p>input trajectories can be generated from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}]</annotation></semantics></math>,
output trajectories for a given input
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>
can be generated according to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>
using standard SSA (Gillespie) simulations;</p></li>
<li><p>by combining the two ideas above, we can derive a direct Monte
Carlo estimate for the mutual information
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">I</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo>,</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{I}(\mathcal{S},\mathcal{X})</annotation></semantics></math>,
as illustrated in <a href="#fig:algorithm">Fig. algorithm</a>.</p></li>
</ul>
<p>Note that we denote trajectories by bold symbols to distinguish them
from scalar quantities.</p>
<p>Our technique is conceptually straightforward. Using Monte Carlo
simulations we can compute averages over the configuration space of
trajectories. Suppose we have a function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’›</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">f[\mathbfit{z}]</annotation></semantics></math>
that takes a trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’›</mi><annotation encoding="application/x-tex">\mathbfit{z}</annotation></semantics></math>
and produces a scalar value. The mean of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’›</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">f[\mathbfit{z}]</annotation></semantics></math>
with respect to the trajectory distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’›</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{z}]</annotation></semantics></math>
is then </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">âŸ¨</mo><mi>f</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’›</mi><mo stretchy="false" form="postfix">]</mo><msub><mo stretchy="false" form="postfix">âŸ©</mo><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’›</mi><mo stretchy="false" form="postfix">]</mo></mrow></msub><mo>â‰¡</mo><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’›</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.167em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’›</mi><mo stretchy="false" form="postfix">]</mo><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’›</mi><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">\langle f[\mathbfit{z}] \rangle_{\mathcal{P}[\mathbfit{z}]}\equiv\int\mathcal{D}[\mathbfit{z}]\, \mathcal{P}[\mathbfit{z}]f(\mathbfit{z}) \,.</annotation></semantics></math>
<p> We write
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’›</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\int\mathcal{D}[\mathbfit{z}]</annotation></semantics></math>
to denote a path integral over all possible trajectories of a given
duration. We estimate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">âŸ¨</mo><mi>f</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’›</mi><mo stretchy="false" form="postfix">]</mo><msub><mo stretchy="false" form="postfix">âŸ©</mo><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’›</mi><mo stretchy="false" form="postfix">]</mo></mrow></msub></mrow><annotation encoding="application/x-tex">\langle f[\mathbfit{z}] \rangle_{\mathcal{P}[\mathbfit{z}]}</annotation></semantics></math>,
by generating a large number of trajectories
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’›</mi><mn>1</mn></msub><mo>,</mo><mi>â€¦</mi><mo>,</mo><msub><mi>ğ’›</mi><mi>N</mi></msub></mrow><annotation encoding="application/x-tex">\mathbfit{z}_1,\ldots,\mathbfit{z}_N</annotation></semantics></math>
from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’›</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{z}]</annotation></semantics></math>
and evaluating the corresponding Monte Carlo average </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>f</mi><mo accent="true">Ì‚</mo></mover><mi>N</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>ğ’›</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\hat{f}_N = \frac{1}{N} \sum^N_{i=1} f(\mathbfit{z}_i)</annotation></semantics></math>
<p> which converges to the true mean in the limit
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>â†’</mo><mi>âˆ</mi></mrow><annotation encoding="application/x-tex">N\to\infty</annotation></semantics></math>.</p>
<p>SÌ±pecifically, we want to estimate the conditional and the marginal
entropy to compute the mutual information. Let us imagine that we
generate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
input trajectories
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’”</mi><mn>1</mn></msub><mo>,</mo><mi>â€¦</mi><mo>,</mo><msub><mi>ğ’”</mi><mi>N</mi></msub></mrow><annotation encoding="application/x-tex">\mathbfit{s}_1,\ldots,\mathbfit{s}_N</annotation></semantics></math>
from the distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}]</annotation></semantics></math>.
Next, for every input
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ğ’”</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\mathbfit{s}_i</annotation></semantics></math>,
we generate a set of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
outputs
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’™</mi><mrow><mi>i</mi><mo>,</mo><mn>1</mn></mrow></msub><mo>,</mo><mi>â€¦</mi><mo>,</mo><msub><mi>ğ’™</mi><mrow><mi>i</mi><mo>,</mo><mi>K</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbfit{x}_{i,1},\ldots,\mathbfit{x}_{i,K}</annotation></semantics></math>
from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><msub><mi>ğ’”</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}_i]</annotation></semantics></math>.
Then, the Monte Carlo estimate for the conditional entropy is </p>
<div id="eq:conditional-entropy-estimate">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’³</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’®</mi><mo stretchy="false" form="postfix">)</mo></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><mi>âˆ’</mi><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.222em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.222em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><mi>âˆ’</mi><msub><mrow><mo stretchy="true" form="prefix">âŸ¨</mo><msub><mrow><mo stretchy="true" form="prefix">âŸ¨</mo><mi>ln</mi><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo stretchy="true" form="postfix">âŸ©</mo></mrow><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow></msub><mo stretchy="true" form="postfix">âŸ©</mo></mrow><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow></msub></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>â‰ˆ</mo><mi>âˆ’</mi><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mfrac><mn>1</mn><mi>K</mi></mfrac><munderover><mo>âˆ‘</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msub><mi>ğ’™</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>ğ’”</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">]</mo><mspace width="0.167em"></mspace><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
    \mathrm{H}(\mathcal{X}|\mathcal{S}) &amp;= -\int \mathcal{D}[\mathbfit{s}]\ \mathcal{P}[\mathbfit{s}]\int \mathcal{D}[\mathbfit{x}]\ \mathcal{P}[\mathbfit{x}|\mathbfit{s}] \ln\mathcal{P}[\mathbfit{x}|\mathbfit{s}] \\ 
    &amp;=-\left\langle \left\langle \ln\mathcal{P}[\mathbfit{x}|\mathbfit{s}] \right\rangle_{\mathcal{P}[\mathbfit{x}|\mathbfit{s}]} \right\rangle_{\mathcal{P}[\mathbfit{s}]} \\
    &amp;\approx -\frac{1}{N}\sum^{N}_{i=1}\frac{1}{K}\sum^{K}_{j=1} \ln\mathcal{P}[\mathbfit{x}_{i,j}|\mathbfit{s}_i] \,.
\end{aligned}
\label{eq:conditional-entropy-estimate}</annotation></semantics></math>
</div>
<p> SÌ±econdly, for a given output
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’™</mi><annotation encoding="application/x-tex">\mathbfit{x}</annotation></semantics></math>
we generate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>
inputs
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>ğ’”</mi><mn>1</mn><mi>â€²</mi></msubsup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msubsup><mi>ğ’”</mi><mi>M</mi><mi>â€²</mi></msubsup></mrow><annotation encoding="application/x-tex">\mathbfit{s}^\prime_1,\ldots,\mathbfit{s}^\prime_M</annotation></semantics></math>
according to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}]</annotation></semantics></math>,
then we can obtain a Monte Carlo estimate for the marginal probability
of the output trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>:
</p>
<div id="eq:marginal-naive">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.222em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><msub><mrow><mo stretchy="true" form="prefix">âŸ¨</mo><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo stretchy="true" form="postfix">âŸ©</mo></mrow><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow></msub></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>â‰ˆ</mo><mfrac><mn>1</mn><mi>M</mi></mfrac><munderover><mo>âˆ‘</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><msubsup><mi>ğ’”</mi><mi>j</mi><mi>â€²</mi></msubsup><mo stretchy="false" form="postfix">]</mo><mspace width="0.167em"></mspace><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
    \mathcal{P}[\mathbfit{x}] &amp;= \int\mathcal{D}[\mathbfit{s}]\  \mathcal{P}[\mathbfit{s}]  \mathcal{P}[\mathbfit{x}|\mathbfit{s}] \\
    &amp;= \left\langle \mathcal{P}[\mathbfit{x}|\mathbfit{s}] \right\rangle_{\mathcal{P}[\mathbfit{s}]} \\
    &amp;\approx \frac{1}{M}\sum^M_{j=1} \mathcal{P}[\mathbfit{x}|\mathbfit{s}^\prime_{j}]\,.
\end{aligned}
    \label{eq:marginal-naive}</annotation></semantics></math>
</div>
<p> The estimate for the marginal entropy is then given by </p>
<div id="eq:marginal-entropy-estimate">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><mi>âˆ’</mi><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.222em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><mi>âˆ’</mi><msub><mrow><mo stretchy="true" form="prefix">âŸ¨</mo><mi>ln</mi><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo stretchy="true" form="postfix">âŸ©</mo></mrow><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow></msub></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>â‰ˆ</mo><mi>âˆ’</mi><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msub><mi>ğ’™</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">]</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>â‰ˆ</mo><mi>âˆ’</mi><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mrow><mo stretchy="true" form="prefix">[</mo><mfrac><mn>1</mn><mi>M</mi></mfrac><munderover><mo>âˆ‘</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msub><mi>ğ’™</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">|</mo><msubsup><mi>ğ’”</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mi>â€²</mi></msubsup><mo stretchy="false" form="postfix">]</mo><mo stretchy="true" form="postfix">]</mo></mrow><mspace width="0.167em"></mspace><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
    \mathrm{H}(\mathcal{X}) &amp;= -\int\mathcal{D}[\mathbfit{x}]\ \mathcal{P}[\mathbfit{x}]\ln\mathcal{P}[\mathbfit{x}] \\
    &amp;= -\left\langle \ln\mathcal{P}[\mathbfit{x}] \right\rangle_{\mathcal{P}[\mathbfit{x}]}\\
    &amp;\approx -\frac{1}{N}\sum^{N}_{i=1} \ln\mathcal{P}[\mathbfit{x}_i] \\
    &amp;\approx -\frac{1}{N}\sum^{N}_{i=1} \ln \left[ \frac{1}{M}\sum^M_{j=1} \mathcal{P}[\mathbfit{x}_i|\mathbfit{s}^\prime_{i,j}] \right]\,.
\end{aligned}
    \label{eq:marginal-entropy-estimate}</annotation></semantics></math>
</div>
<p> In the last step we inserted the result from <a
href="#eq:marginal-naive">eq:marginal-naive</a>. In this estimate, the
trajectories
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’™</mi><mn>1</mn></msub><mo>,</mo><mi>â€¦</mi><mo>,</mo><msub><mi>ğ’™</mi><mi>N</mi></msub></mrow><annotation encoding="application/x-tex">\mathbfit{x}_1,\ldots,\mathbfit{x}_N</annotation></semantics></math>
are sampled from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>,
i.e., by first sampling from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}]</annotation></semantics></math>
and then from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>.
Finally, the mutual information is obtained by taking the entropy
difference, i.e.,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">I</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo>,</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo><mo>âˆ’</mo><mi mathvariant="normal">H</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’³</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’®</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{I}(\mathcal{S},\mathcal{X})=\mathrm{H}(\mathcal{X}) - \mathrm{H}(\mathcal{X}|\mathcal{S})</annotation></semantics></math>.</p>
<p>While this is the main idea behind PWS, it is computationally
advantageous to change the order of operations in the estimate.
Specifically, computing the difference of two averages, leads to large
statistical errors. We can obtain an improved estimate by reformulating
the mutual information as a single average of differences: </p>
<div id="eq:average-of-differences">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"><mi mathvariant="normal">I</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo>,</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.222em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mfrac><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow></mfrac></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><msub><mrow><mo stretchy="true" form="prefix">âŸ¨</mo><mi>ln</mi><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo>âˆ’</mo><mi>ln</mi><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo stretchy="true" form="postfix">âŸ©</mo></mrow><mrow><mi>ğ’«</mi><mrow><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow></mrow></msub><mspace width="0.167em"></mspace><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
    \mathrm{I}(\mathcal{S},\mathcal{X}) &amp;= \int\mathcal{D}[\mathbfit{s}]\int\mathcal{D}[\mathbfit{x}]\ \mathcal{P}[\mathbfit{s},\mathbfit{x}] \ln\frac{\mathcal{P}[\mathbfit{x}|\mathbfit{s}]}{\mathcal{P}[\mathbfit{x}]} \\
    &amp;=  \left\langle
    \ln\mathcal{P}[\mathbfit{x}|\mathbfit{s}] -
    \ln\mathcal{P}[\mathbfit{x}]
    \right\rangle_{\mathcal{P}{[\mathbfit{s},\mathbfit{x}]}}\,.
\end{aligned}
\label{eq:average-of-differences}</annotation></semantics></math>
</div>
<p>á¹®his equation applies to all variants of PWS. They differ, however,
in the way
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>
is computed. In the brute-force version of PWS, called <em>Direct
PWS</em> (DPWS), we use <a
href="#eq:marginal-naive">eq:marginal-naive</a> to evaluate the marginal
probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>.
DPWS indeed involves two nested Monte Carlo computations, in which
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
pairs
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msub><mi>ğ’”</mi><mi>i</mi></msub><mo>,</mo><msub><mi>ğ’™</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(\mathbfit{s}_i, \mathbfit{x}_i)</annotation></semantics></math>
are generated, and for each output
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ğ’™</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\mathbfit{x}_i</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>
input trajectories
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{\mathbfit{s}\}</annotation></semantics></math>
are generated from scratch to compute
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>.
In <a href="#ch:variants">Ch. variants</a>, we present two additional
variants of PWS where the brute-force estimate of the marginal
probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>
is replaced by more elaborate schemes. That said, DPWS is a conceptually
simple, straightforward to implement, and exact scheme to compute the
mutual information.</p>
<p>HÌ±aving explained the core ideas of our technique above, we will
continue this section with a review of the necessary concepts of master
equations to implement PWS. First, in <a href="#sec:mjp">Sec. mjp</a>,
we derive the formula for the conditional probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>
which lies at the heart of our technique. In <a href="#sec:mjp">Sec.
mjp</a> and <a href="#sec:input-statistics">Sec. input-statistics</a>,
we discuss how trajectories are generated according to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}]</annotation></semantics></math>,
which are the remaining ingredients required for using DPWS. Then, in <a
href="#ch:variants">Ch. variants</a>, we will present the two other
variants of PWS that improve on DPWS.</p>
<h3 id="sec:mjp" id="driven-markov-jump-process"> Driven Markov Jump
Process</h3>
<p>In this chapter, we consider systems that can be modeled by a master
equation and are being driven by a stochastic signal. The master
equation specifies the time evolution of the conditional probability
distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mn>0</mn></msub><mo>,</mo><msub><mi>t</mi><mn>0</mn></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x,t|x_0, t_0)</annotation></semantics></math>
which is the probability for the process to reach the discrete state
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>âˆˆ</mo><mi mathvariant="normal">Î©</mi></mrow><annotation encoding="application/x-tex">x\in\Omega</annotation></semantics></math>
at time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>,
given that it was at state
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub><mo>âˆˆ</mo><mi mathvariant="normal">Î©</mi></mrow><annotation encoding="application/x-tex">x_0\in\Omega</annotation></semantics></math>
at the previous time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>t</mi><mn>0</mn></msub><annotation encoding="application/x-tex">t_0</annotation></semantics></math>.
The state space
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi mathvariant="normal">Î©</mi><annotation encoding="application/x-tex">\Omega</annotation></semantics></math>
is multi-dimensional if the system is made up of multiple components and
therefore
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mn>0</mn></msub><annotation encoding="application/x-tex">x_0</annotation></semantics></math>
can be vectors rather than scalar values. Denoting the transition rate
at time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>
from
stateÂ <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>
to another
stateÂ <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mi>â€²</mi></msup><mo>â‰ </mo><mi>x</mi></mrow><annotation encoding="application/x-tex">x^\prime \neq x</annotation></semantics></math>
by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mi>â€²</mi></msup><mo>,</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">w_t(x^\prime, x)</annotation></semantics></math>,
the master equation reads </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>âˆ‚</mi><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo></mrow><mrow><mi>âˆ‚</mi><mi>t</mi></mrow></mfrac><mo>=</mo><munder><mo>âˆ‘</mo><mrow><msup><mi>x</mi><mi>â€²</mi></msup><mo>âˆˆ</mo><mi mathvariant="normal">Î©</mi><mo>\</mo><mo stretchy="false" form="prefix">{</mo><mi>x</mi><mo stretchy="false" form="postfix">}</mo></mrow></munder><mo stretchy="false" form="prefix">[</mo><msub><mi>w</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><msup><mi>x</mi><mi>â€²</mi></msup><mo stretchy="false" form="postfix">)</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mi>â€²</mi></msup><mo>,</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo><mo>âˆ’</mo><msub><mi>w</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mi>â€²</mi></msup><mo>,</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="postfix">]</mo><mspace width="0.167em"></mspace><mo>,</mo></mrow><annotation encoding="application/x-tex">\frac{\partial\mathrm{P}(x,t)}{\partial t} = \sum_{x^\prime\in\Omega\setminus\{x\}} [w_t(x, x^\prime) \mathrm{P}(x^\prime,t) - w_t(x^\prime, x) \mathrm{P}(x,t)] \,,</annotation></semantics></math>
<p> where, for brevity, we suppress the dependence on the initial
condition, i.e.,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mn>0</mn></msub><mo>,</mo><msub><mi>t</mi><mn>0</mn></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x,t)=\mathrm{P}(x,t|x_0,t_0)</annotation></semantics></math>.
By defining
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mi>â€²</mi></msup><mo>,</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><msub><mi>w</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mi>â€²</mi></msup><mo>,</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">Q_t(x^\prime,x) = w_t(x^\prime,x)</annotation></semantics></math>
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>â‰ </mo><msup><mi>x</mi><mi>â€²</mi></msup></mrow><annotation encoding="application/x-tex">x \neq x^\prime</annotation></semantics></math>
and </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi>âˆ’</mi><munder><mo>âˆ‘</mo><mrow><msup><mi>x</mi><mi>â€²</mi></msup><mo>âˆˆ</mo><mi mathvariant="normal">Î©</mi><mo>âˆ–</mo><mo stretchy="false" form="prefix">{</mo><mi>x</mi><mo stretchy="false" form="postfix">}</mo></mrow></munder><msub><mi>w</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mi>â€²</mi></msup><mo>,</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">Q_t(x, x) = -\sum_{x^\prime\in\Omega\smallsetminus\{x\}} w_t(x^\prime, x)</annotation></semantics></math>
<p> the master equation simplifies to </p>
<div id="eq:master-equation">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>âˆ‚</mi><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo></mrow><mrow><mi>âˆ‚</mi><mi>t</mi></mrow></mfrac><mo>=</mo><munder><mo>âˆ‘</mo><mrow><msup><mi>x</mi><mi>â€²</mi></msup><mo>âˆˆ</mo><mi mathvariant="normal">Î©</mi></mrow></munder><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><msup><mi>x</mi><mi>â€²</mi></msup><mo stretchy="false" form="postfix">)</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mi>â€²</mi></msup><mo>,</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">\frac{\partial\mathrm{P}(x,t)}{\partial t} = \sum_{x^\prime\in\Omega} Q_t(x, x^\prime) \mathrm{P}(x^\prime,t)\,. \label{eq:master-equation}</annotation></semantics></math>
</div>
<p> Note that by definition the diagonal matrix element
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">Q_t(x,x)</annotation></semantics></math>
is the negative exit rate from state
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>,
i.e. the total rate at which probability flows away from state
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>.</p>
<p>Using the master equation we can compute the probability of any
trajectory. A trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’™</mi><annotation encoding="application/x-tex">\mathbfit{x}</annotation></semantics></math>
is defined by a list of jump times
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mn>1</mn></msub><mo>,</mo><mi>â€¦</mi><mo>,</mo><msub><mi>t</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">t_1,\ldots,t_{n-1}</annotation></semantics></math>,
together with a sequence of system states
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub><mo>,</mo><mi>â€¦</mi><mo>,</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_0,\ldots,x_{n-1}</annotation></semantics></math>.
The trajectory starts at time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>t</mi><mn>0</mn></msub><annotation encoding="application/x-tex">t_0</annotation></semantics></math>
in state
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mn>0</mn></msub><annotation encoding="application/x-tex">x_0</annotation></semantics></math>
and ends at time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>t</mi><mi>n</mi></msub><annotation encoding="application/x-tex">t_n</annotation></semantics></math>
in state
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">x_{n-1}</annotation></semantics></math>,
such that its duration is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><msub><mi>t</mi><mi>n</mi></msub><mo>âˆ’</mo><msub><mi>t</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">T=t_n-t_0</annotation></semantics></math>.
At each time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>t</mi><mi>i</mi></msub><annotation encoding="application/x-tex">t_i</annotation></semantics></math>
(for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>â€¦</mi><mo>,</mo><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">i=1,\ldots,n-1</annotation></semantics></math>)
the trajectory describes an instantaneous jump
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo>â†’</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_{i-1}\rightarrow x_{i}</annotation></semantics></math>.
The probability density of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’™</mi><annotation encoding="application/x-tex">\mathbfit{x}</annotation></semantics></math>
is </p>
<div id="eq:traj-prob-master-eq">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false" form="postfix">)</mo><mo>Ã—</mo><mrow><mo stretchy="true" form="prefix">(</mo><munderover><mo>âˆ</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></munderover><msub><mi>Q</mi><msub><mi>t</mi><mi>i</mi></msub></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mspace width="1.0em"></mspace><mo>Ã—</mo><mrow><mo stretchy="true" form="prefix">(</mo><munderover><mo>âˆ</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>exp</mi><munderover><mo>âˆ«</mo><msub><mi>t</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><msub><mi>t</mi><mi>i</mi></msub></munderover><mi>d</mi><mi>t</mi><mspace width="0.222em"></mspace><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
    \mathcal{P}[\mathbfit{x}] &amp;= 
    \mathrm{P}(x_0)\times \left(
    \prod^{n-1}_{i=1} Q_{t_i}\left(x_i, x_{i-1}\right) 
    \right) \\
    &amp;\quad\times\left(
    \prod^{n}_{i=1}
    \exp\int\limits^{t_{i}}_{t_{i-1}} dt\ Q_t(x_{i-1}, x_{i-1})
    \right),
\end{aligned}
\label{eq:traj-prob-master-eq}</annotation></semantics></math>
</div>
<p> aÌ± product of the probability of the initial state
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_0)</annotation></semantics></math>,
the rates of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n-1</annotation></semantics></math>
transitions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><msub><mi>t</mi><mi>i</mi></msub></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">Q_{t_i}\left(x_i, x_{i-1}\right)</annotation></semantics></math>,
and the survival probabilities for the waiting times between jumps,
given by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>exp</mi><mo>&#8289;</mo></mrow><msubsup><mo>âˆ«</mo><msub><mi>t</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><msub><mi>t</mi><mi>i</mi></msub></msubsup><mi>d</mi><mi>t</mi><mspace width="0.222em"></mspace><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\exp\int^{t_{i}}_{t_{i-1}} dt\ Q_t(x_{i-1}, x_{i-1})</annotation></semantics></math>
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>â€¦</mi><mo>,</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">i=1,\ldots,n</annotation></semantics></math>.</p>
<h4 id="sec:likelihood"
id="computing-the-likelihood-mathcalpxs">Computing the Likelihood
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>x</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[x|s]</annotation></semantics></math>
</h4>
<p>To compute the likelihood or conditional
probabilityÂ <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>
of an output
trajectoryÂ <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’™</mi><annotation encoding="application/x-tex">\mathbfit{x}</annotation></semantics></math>
for a given input trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>,
we note that the input determines the time-dependent stochastic dynamics
of the jump process. Indeed, the transition rates at time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>,
given by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mi>â€²</mi></msup><mo>,</mo><mi>x</mi><mo>;</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">Q_t(x^\prime,x; {\mathbfit{s}})</annotation></semantics></math>,
depend explicitly on the input
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo stretchy="false" form="prefix">(</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">s(t)</annotation></semantics></math>
at time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>
and may even depend on the entire history of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">{\mathbfit{s}}</annotation></semantics></math>
prior to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>.</p>
<p>In the common case that every input trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>
leads to a unique transition rate matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mi>â€²</mi></msup><mo>,</mo><mi>x</mi><mo>;</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">Q_t(x^\prime,x;\mathbfit{s})</annotation></semantics></math>,
i.e. the map
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’”</mi><mo>â†¦</mo><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>â‹…</mi><mo>,</mo><mi>â‹…</mi><mo>;</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathbfit{s}\mapsto Q_t(\cdot,\cdot;\mathbfit{s})</annotation></semantics></math>
is injective, the likelihood is directly given by <a
href="#eq:traj-prob-master-eq">eq:traj-prob-master-eq</a>: </p>
<div id="eq:traj_prob">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mn>0</mn></msub><mo stretchy="false" form="postfix">)</mo><mo>Ã—</mo><mrow><mo stretchy="true" form="prefix">(</mo><munderover><mo>âˆ</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></munderover><msub><mi>Q</mi><msub><mi>t</mi><mi>i</mi></msub></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo>;</mo><mi>ğ’”</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mspace width="1.0em"></mspace><mo>Ã—</mo><mrow><mo stretchy="true" form="prefix">(</mo><munderover><mo>âˆ</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>exp</mi><munderover><mo>âˆ«</mo><msub><mi>t</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><msub><mi>t</mi><mi>i</mi></msub></munderover><mi>d</mi><mi>t</mi><mspace width="0.222em"></mspace><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo>;</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">)</mo><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
    \mathcal{P}[\mathbfit{x}|\mathbfit{s}] &amp;= 
    \mathrm{P}(x_0|s_0)\times \left(
    \prod^{n-1}_{i=1} Q_{t_i}\left(x_i, x_{i-1} ;\mathbfit{s}\right) 
    \right) \\
    &amp;\quad\times\left(
    \prod^{n}_{i=1}
    \exp\int\limits^{t_{i}}_{t_{i-1}} dt\ Q_t(x_{i-1}, x_{i-1};\mathbfit{s})
    \right)
    \label{eq:traj_prob}
\end{aligned}</annotation></semantics></math>
</div>
<p> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mn>0</mn></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_0|s_0)</annotation></semantics></math>
is the probability of the initial state
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mn>0</mn></msub><annotation encoding="application/x-tex">x_0</annotation></semantics></math>
of the output given the initial state of the input
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mn>0</mn></msub><mo>=</mo><mi>s</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>t</mi><mn>0</mn></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">s_0=s(t_0)</annotation></semantics></math>.</p>
<p>The evaluation of the trajectory likelihood is at the heart of our
Monte Carlo scheme. However, numerically computing a large product like
<a href="#eq:traj_prob">eq:traj_prob</a> very quickly reaches the limits
of floating point arithmetic since the result is often either too large
or too close to zero to be representable as a floating point number.
Thus, to avoid numerical issues, it is vital to perform the computations
in log-space, i.e. to compute </p>
<div id="eq:log_traj_prob">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mn>0</mn></msub><mo stretchy="false" form="postfix">)</mo><mo>+</mo><msubsup><mo>âˆ«</mo><msub><mi>t</mi><mn>0</mn></msub><mi>T</mi></msubsup><mi>d</mi><mi>t</mi><mspace width="0.222em"></mspace><msub><mi>â„’</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\ln\mathcal{P}[\mathbfit{x}|\mathbfit{s}] = \ln \mathrm{P}(x_0|s_0) + \int^T_{t_0}dt\ \mathcal{L}_t[\mathbfit{s},\mathbfit{x}]
    \label{eq:log_traj_prob}</annotation></semantics></math>
</div>
<p> where </p>
<div id="eq:path_action">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>â„’</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="prefix">(</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo><mo>,</mo><mi>x</mi><mo stretchy="false" form="prefix">(</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo><mo>;</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">)</mo><mo>+</mo><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></munderover><mi>Î´</mi><mo stretchy="false" form="prefix">(</mo><mi>t</mi><mo>âˆ’</mo><msub><mi>t</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo>;</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">\mathcal{L}_t[\mathbfit{s},\mathbfit{x}] = Q_t(x(t),x(t);\mathbfit{s}) +
    \sum^{n-1}_{i=1} \delta(t-t_i) \ln Q_t(x_i,x_{i-1};\mathbfit{s})\,.
    \label{eq:path_action}</annotation></semantics></math>
</div>
<p>á¹®he computation of the log-likelihood
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\ln\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>
for given trajectories
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’™</mi><annotation encoding="application/x-tex">\mathbfit{x}</annotation></semantics></math>
according to <a href="#eq:log_traj_prob">eq:log_traj_prob</a> and <a
href="#eq:path_action">eq:path_action</a> proceeds as follows:</p>
<ul>
<li><p>At the start of the trajectory we compute the log-probability of
the initial condition
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mn>0</mn></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\ln\mathrm{P}(x_0|s_0)</annotation></semantics></math>,</p></li>
<li><p>for every jump
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo>â†’</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_{i-1}\rightarrow x_i</annotation></semantics></math>
in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’™</mi><annotation encoding="application/x-tex">\mathbfit{x}</annotation></semantics></math>
(at time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>t</mi><mi>i</mi></msub><annotation encoding="application/x-tex">t_i</annotation></semantics></math>)
compute the log jump propensity
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><msub><mi>Q</mi><msub><mi>t</mi><mi>i</mi></msub></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo>;</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\ln Q_{t_i}(x_i,x_{i-1};\mathbfit{s})</annotation></semantics></math>,
and</p></li>
<li><p>for every interval
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msub><mi>t</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>t</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(t_{i-1},t_i)</annotation></semantics></math>
of constant output value
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo stretchy="false" form="prefix">(</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x(t) = x_{i-1}</annotation></semantics></math>
between two jumps of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’™</mi><annotation encoding="application/x-tex">\mathbfit{x}</annotation></semantics></math>,
we compute
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>âˆ«</mo><msub><mi>t</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><msub><mi>t</mi><mi>i</mi></msub></msubsup><mi>d</mi><mi>t</mi><mspace width="0.222em"></mspace><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo>;</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\int^{t_i}_{t_{i-1}}dt\ Q_t(x_{i-1},x_{i-1}; \mathbfit{s})</annotation></semantics></math>.
This integral can be performed using standard numerical methods such as
the trapezoidal rule, which is also exact if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="prefix">(</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo><mo>,</mo><mi>x</mi><mo stretchy="false" form="prefix">(</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo><mo>;</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">Q_t(x(t),x(t);\mathbfit{s})</annotation></semantics></math>
is a piecewise linear function of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>.</p></li>
</ul>
<p>The sum of the three contributions above yields the exact
log-likelihood
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\ln\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>
as given in <a href="#eq:log_traj_prob">eq:log_traj_prob</a>.</p>
<p>The algorithm to compute the log-likelihood
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\ln\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>
is both efficient and straightforward to implement, being closely
related to the standard Gillespie algorithm. The only term in <a
href="#eq:log_traj_prob">eq:log_traj_prob</a> that cannot be directly
obtained from the master equation is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mn>0</mn></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\ln\mathrm{P}(x_0|s_0)</annotation></semantics></math>.
This quantity depends on the initial distribution of the system of
interest.</p>
<p>Our scheme can be applied to any system with a well-defined
(non-equilibrium) initial distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mn>0</mn></msub><mo>,</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(s_0, x_0)</annotation></semantics></math>
as specified by, e.g. the experimental setup. Most commonly though, one
is interested in studying information transmission for systems in steady
state. Then, the initial condition
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mn>0</mn></msub><mo>,</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(s_0,x_0)</annotation></semantics></math>
is the stationary distribution of the Markov process. Depending on the
complexity of the system, this distribution can be found either
analytically from the master equation <span class="citation"
data-cites="2007.vanKampen 2017.Weber">Â [<a href="#ref-2007.vanKampen"
role="doc-biblioref">43</a>,<a href="#ref-2017.Weber"
role="doc-biblioref">44</a>]</span> (possibly using simplifying
approximations <span class="citation"
data-cites="2009.Walczak 2007.Kim">Â [<a href="#ref-2009.Walczak"
role="doc-biblioref">45</a>,<a href="#ref-2007.Kim"
role="doc-biblioref">46</a>]</span>), or computationally from stochastic
simulations <span class="citation" data-cites="1976.Gillespie">Â [<a
href="#ref-1976.Gillespie" role="doc-biblioref">47</a>]</span>.</p>
<h4 id="sec:gillespie" id="sampling-from-mathcalpxs">Sampling from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>x</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[x|s]</annotation></semantics></math></h4>
<p>Standard kinetic Monte Carlo simulations naturally produce exact
samples of the probability distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>
as defined in <a href="#eq:traj_prob">eq:traj_prob</a>. That is, for any
signal trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>
and initial state
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mn>0</mn></msub><annotation encoding="application/x-tex">x_0</annotation></semantics></math>
drawn from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>s</mi><mn>0</mn></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(x_0|s_0)</annotation></semantics></math>
we can use the Stochastic Simulation AlgorithmÂ (SSA) or variants thereof
to generate a corresponding trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’™</mi><annotation encoding="application/x-tex">\mathbfit{x}</annotation></semantics></math>.
The SSA propagates the initial condition
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub><mo>,</mo><msub><mi>t</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">x_0,t_0</annotation></semantics></math>
forward in time according to the transition rate matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>â‹…</mi><mo>;</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">Q_t(\cdot;\mathbfit{s})</annotation></semantics></math>.
In the standard Direct SSA algorithmÂ <span class="citation"
data-cites="1976.Gillespie">Â [<a href="#ref-1976.Gillespie"
role="doc-biblioref">47</a>]</span> this is done by alternatingly
sampling the waiting time before the next transition, and then selecting
the actual transition.</p>
<p>The transition rates
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mi>â€²</mi></msup><mo>,</mo><mi>x</mi><mo>;</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">Q_t(x^\prime,x;\mathbfit{s})</annotation></semantics></math>
of a driven master equation are necessarily time-dependent since they
include the coupling of the jump process to the input trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>,
which itself varies in time. These time-varying transition rates need to
be accounted for in the SSA. While most treatments of the SSA assume
that the transition rates are constant in time, this restriction is
easily lifted. Consider step
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
of the Direct SSA which generates the next transition time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>t</mi><mi>i</mi></msub><mo>+</mo><mi mathvariant="normal">Î”</mi><msub><mi>t</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">t_{i+1} = t_i+\Delta t_i</annotation></semantics></math>.
For time-varying transition rates the distribution of the stochastic
waiting time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Î”</mi><msub><mi>t</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\Delta t_i</annotation></semantics></math>
is characterized by the survival function </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>Ï„</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><mi mathvariant="normal">Î”</mi><msub><mi>t</mi><mi>i</mi></msub><mo>&gt;</mo><mi>Ï„</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mrow><mi>exp</mi><mo>&#8289;</mo></mrow><msubsup><mo>âˆ«</mo><msub><mi>t</mi><mi>i</mi></msub><mrow><msub><mi>t</mi><mi>i</mi></msub><mo>+</mo><mi>Ï„</mi></mrow></msubsup><mi>d</mi><mi>t</mi><mspace width="0.222em"></mspace><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>i</mi></msub><mo>;</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">S_i(\tau) = \mathrm{P}(\Delta t_i &gt; \tau) = \exp\int^{t_i+\tau}_{t_i} dt\ Q_t(x_i, x_i;\mathbfit{s}) \,.</annotation></semantics></math>
<p> The waiting time can be sampled using inverse transform sampling,
i.e. by generating a uniformly distributed random number
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo>âˆˆ</mo><mo stretchy="false" form="prefix">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">u\in[0,1]</annotation></semantics></math>
and computing the waiting time using the inverse survival function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Î”</mi><msub><mi>t</mi><mi>i</mi></msub><mo>=</mo><msubsup><mi>S</mi><mi>i</mi><mrow><mi>âˆ’</mi><mn>1</mn></mrow></msubsup><mo stretchy="false" form="prefix">(</mo><mi>u</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\Delta t_i = S^{-1}_i(u)</annotation></semantics></math>.
Numerically, computing the inverse of the survival function requires
solving the equation </p>
<div id="eq:inverse-transform-sampling">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi>u</mi><mo>=</mo><msubsup><mo>âˆ«</mo><msub><mi>t</mi><mi>i</mi></msub><mrow><msub><mi>t</mi><mi>i</mi></msub><mo>+</mo><mi mathvariant="normal">Î”</mi><msub><mi>t</mi><mi>i</mi></msub></mrow></msubsup><mi>d</mi><mi>t</mi><mspace width="0.222em"></mspace><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>i</mi></msub><mo>;</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\ln u = \int^{t_i+\Delta t_i}_{t_i} dt\ Q_t(x_i, x_i;\mathbfit{s})
    \label{eq:inverse-transform-sampling}</annotation></semantics></math>
</div>
<p> for the waiting time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Î”</mi><msub><mi>t</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\Delta t_i</annotation></semantics></math>.
Depending on the complexity of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">Q_t(x_i, x_i|\mathbfit{s})</annotation></semantics></math>,
this equation can either be solved analytically or numerically, e.g.
using Newtonâ€™s method. Hence, this method to generate stochastic
trajectories is only truly exact if we can solve <a
href="#eq:inverse-transform-sampling">eq:inverse-transform-sampling</a>
analytically. Additionally, in some cases more efficient variants of the
SSA with time dependent rates could be used <span class="citation"
data-cites="1997.Prados 2015.Thanh">Â [<a href="#ref-1997.Prados"
role="doc-biblioref">48</a>,<a href="#ref-2015.Thanh"
role="doc-biblioref">49</a>]</span>.</p>
<h3 id="sec:input-statistics" id="input-statistics">Input
Statistics</h3>
<p>For our mutual information estimate, we need to be able to draw
samples from the input distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal P[\mathbfit{s}]</annotation></semantics></math>.
Our algorithm poses no restrictions on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}]</annotation></semantics></math>
other than the possibility to generate sample trajectories.</p>
<p>For example, the input signal may be described by a continuous-time
jump process. One benefit is that it is possible to generate exact
realizations of such a process (using the SSA) and to exactly compute
the likelihood
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>
using <a href="#eq:log_traj_prob">eq:log_traj_prob</a>. Specifically,
the likelihood can be exactly evaluated because the transition rates
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>â‹…</mi><mo>,</mo><mi>â‹…</mi><mo>;</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">Q_t(\cdot,\cdot;\mathbfit{s})</annotation></semantics></math>
for any input trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>,
while time-dependent, are <em>piece-wise constant</em>. This implies
that the integral in <a href="#eq:log_traj_prob">eq:log_traj_prob</a>
can be evaluated analytically without approximations. Similarly, for
piece-wise constant transition rates, the inverse function of <a
href="#eq:inverse-transform-sampling">eq:inverse-transform-sampling</a>
can be evaluated directly such that we can sample exact trajectories
from the driven jump process. As a result, when both input and output
are described by a master equation, PWS is a completely exact Monte
Carlo scheme to compute the mutual information.</p>
<p>However, the techniques described here do <em>not</em> require the
input signal
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>
to be described by a continuous-time jump process, or even to be
Markovian. The input signal can be any stochastic process for which
trajectories can be generated numerically. This includes continuous
stochastic processes that are found as solutions to stochastic
differential equations <span class="citation"
data-cites="1992.Kloeden">Â [<a href="#ref-1992.Kloeden"
role="doc-biblioref">50</a>]</span>.</p>
<h2 id="sec:integrating-out"
id="integrating-out-internal-components">Integrating Out Internal
Components </h2>
<p>So far the output trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’™</mi><annotation encoding="application/x-tex">\mathbfit{x}</annotation></semantics></math>
has been considered to correspond to the trajectory of the system in the
<em>full</em> state space
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi mathvariant="normal">Î©</mi><annotation encoding="application/x-tex">\Omega</annotation></semantics></math>.
Concomitantly, the method presented is a scheme for computing the mutual
information between the input signal
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>
and the trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’™</mi><annotation encoding="application/x-tex">\mathbfit{x}</annotation></semantics></math>,
comprising the time evolution of all the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
components in the system,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>X</mi><mn>1</mn></msup><mo>,</mo><msup><mi>X</mi><mn>2</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>X</mi><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">X^1, X^2,\ldots, X^n</annotation></semantics></math>.
Each component
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mi>i</mi></msup><annotation encoding="application/x-tex">X^i</annotation></semantics></math>
itself has a corresponding trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ğ’™</mi><mi>i</mi></msup><annotation encoding="application/x-tex">\mathbfit{x}^i</annotation></semantics></math>,
such that the full trajectory can be represented as a vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’™</mi><mo>=</mo><mo stretchy="false" form="prefix">(</mo><msup><mi>ğ’™</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathbfit{x}=(\mathbfit{x}^1,\ldots,\mathbfit{x}^n)</annotation></semantics></math>.
It is indeed also the conditional probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]=\mathcal{P}[\mathbfit{x}^1,\ldots,\mathbfit{x}^n|\mathbfit{s}]</annotation></semantics></math>
and the marginal probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]=\mathcal{P}[\mathbfit{x}^1,\ldots,\mathbfit{x}^n]</annotation></semantics></math>
of this vector in the full state space that can be directly computed
from the master equation. In fact, it is this vector, which captures the
states of all the components in the system, that carries the most
information on the input signal
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>,
and thus has the largest mutual information. However, typically the
downstream system cannot read out the states of all the components
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>X</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>X</mi><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">X^1, \ldots, X^n</annotation></semantics></math>.
Often, the downstream system reads out only a few components or often
even just one component, the â€œoutput componentâ€
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mi>r</mi></msup><annotation encoding="application/x-tex">X^r</annotation></semantics></math>.
The other components then mainly serve to transmit the information from
the input
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>
to this readout
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mi>r</mi></msup><annotation encoding="application/x-tex">X^r</annotation></semantics></math>.
From the perspective of the downstream system, the other components are
hidden. The natural quantity to measure the precision of information
processing is then the mutual information
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">I</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo>;</mo><msup><mi>ğ’³</mi><mi>r</mi></msup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{I}(\mathcal{S};\mathcal{X}^r)</annotation></semantics></math>
between the input
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>
and the output componentâ€™s trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ğ’™</mi><mi>r</mi></msup><annotation encoding="application/x-tex">\mathbfit{x}^r</annotation></semantics></math>,
not
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">I</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo>;</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{I}(\mathcal{S};\mathcal{X})</annotation></semantics></math>.
The question then becomes how to compute
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>r</mi></msup><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^r]</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>r</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^r|\mathbfit{s}]</annotation></semantics></math>,
from which
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">I</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo>;</mo><msup><mi>ğ’³</mi><mi>r</mi></msup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{I}(\mathcal{S};\mathcal{X}^r)</annotation></semantics></math>
can be obtained. Here, we present a scheme to achieve this.</p>
<p>As an example, consider a chemical reaction network with species
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>X</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>X</mi><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">X^1,\ldots,X^{n}</annotation></semantics></math>.
Without loss of generality, we will assume that the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>-th
component is the output component,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>X</mi><mi>r</mi></msup><mo>=</mo><msup><mi>X</mi><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">X^r=X^n</annotation></semantics></math>.
The other species
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>X</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>X</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">X^1,\ldots,X^{n-1}</annotation></semantics></math>
are thus not part of the output, but only relay information from the
input signal
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>
to the output signal
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ğ’™</mi><mi>n</mi></msup><annotation encoding="application/x-tex">\mathbfit{x}^n</annotation></semantics></math>.
To determine the mutual information
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">I</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo>,</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{I}(\mathcal{S},\mathcal{X})</annotation></semantics></math>
we need
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^n|\mathbfit{s}]</annotation></semantics></math>,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ğ’™</mi><mi>n</mi></msup><annotation encoding="application/x-tex">\mathbfit{x}^n</annotation></semantics></math>
is the trajectory of only the readout
componentÂ <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mi>n</mi></msup><annotation encoding="application/x-tex">X^n</annotation></semantics></math>.
However, from the master equation we can only obtain an expression for
the full conditional probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^1,\ldots,\mathbfit{x}^n|\mathbfit{s}]</annotation></semantics></math>
of all components. To compute the value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^n|\mathbfit{s}]</annotation></semantics></math>,
we must perform the marginalization integral </p>
<div id="eq:marginalization_integral">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mn>1</mn></msup><mo stretchy="false" form="postfix">]</mo><mi>â‹¯</mi><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msup><mo stretchy="false" form="postfix">]</mo><mspace width="0.278em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^n|\mathbfit{s}] = \int\mathcal{D}[\mathbfit{x}^1] \cdots \int\mathcal{D}[\mathbfit{x}^{n-1}]\; \mathcal{P}[\mathbfit{x}^1,\ldots,\mathbfit{x}^n|\mathbfit{s}]\,.
    \label{eq:marginalization_integral}</annotation></semantics></math>
</div>
<p> We can compute this integral using a Monte Carlo scheme as described
below and use the resulting estimate for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^n|\mathbfit{s}]</annotation></semantics></math>
to compute the mutual information using our technique presented in <a
href="#sec:algorithm">Sec. algorithm</a>.</p>
<p>The marginalization of <a
href="#eq:marginalization_integral">eq:marginalization_integral</a>
entails integrating out degrees of freedom from a known joint
probability distribution. In <a
href="#eq:marginal-naive">eq:marginal-naive</a> we solved the analogous
problem of obtaining the marginal probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>
by integrating out the input trajectories through the integral
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mo>âˆ«</mo><mi>d</mi><mi>ğ’”</mi><mspace width="0.222em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mo>âˆ«</mo><mi>d</mi><mi>ğ’”</mi><mspace width="0.222em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]=\int d\mathbfit{s}\ \mathcal{P}[\mathbfit{s},\mathbfit{x}]=\int d\mathbfit{s}\ \mathcal{P}[\mathbfit{s}]\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>.
As described in <a href="#sec:algorithm">Sec. algorithm</a>, the
integral from <a href="#eq:marginal-naive">eq:marginal-naive</a> can be
computed via a Monte Carlo estimate by sampling many input trajectories
from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}]</annotation></semantics></math>
and taking the average of the corresponding conditional probabilities
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><msub><mi>ğ’”</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}_i]</annotation></semantics></math>.
We will show that in the case where there is no feedback from the
readout component back to the other components, a completely analogous
Monte Carlo estimate can be derived for <a
href="#eq:marginalization_integral">eq:marginalization_integral</a>.</p>
<p>More specifically, we can evaluate <a
href="#eq:marginalization_integral">eq:marginalization_integral</a> via
a direct Monte Carlo estimate under the condition that the stochastic
dynamics of the other components
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>X</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>X</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">X^1,\ldots,X^{n-1}</annotation></semantics></math>
are not influenced by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mi>n</mi></msup><annotation encoding="application/x-tex">X^n</annotation></semantics></math>
(i.e., no feedback from the readout). Using the identity </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>ğ’™</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.222em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><msubsup><mi>ğ’™</mi><mi>i</mi><mn>1</mn></msubsup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msubsup><mi>ğ’™</mi><mi>i</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msubsup><mo>,</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^1,\ldots,\mathbfit{x}^n|\mathbfit{s}] = \mathcal{P}[\mathbfit{x}^1,\ldots,\mathbfit{x}^{n-1}|\mathbfit{s}]\ \mathcal{P}[\mathbfit{x}^n|\mathbfit{x}^1_i,\ldots,\mathbfit{x}^{n-1}_i,\mathbfit{s}]</annotation></semantics></math>
<p> to rewrite the integrand in <a
href="#eq:marginalization_integral">eq:marginalization_integral</a>, we
are able to represent the conditional probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^n|\mathbfit{s}]</annotation></semantics></math>
as an average over the readout componentâ€™s trajectory probability </p>
<div id="eq:marginalization_average">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><msub><mrow><mo stretchy="true" form="prefix">âŸ¨</mo><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><msubsup><mi>ğ’™</mi><mi>i</mi><mn>1</mn></msubsup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msubsup><mi>ğ’™</mi><mi>i</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msubsup><mo>,</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo stretchy="true" form="postfix">âŸ©</mo></mrow><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>ğ’™</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow></msub><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^n|\mathbfit{s}] = 
    \left\langle \mathcal{P}[\mathbfit{x}^n|\mathbfit{x}^1_i,\ldots,\mathbfit{x}^{n-1}_i,\mathbfit{s}] \right\rangle_{\mathcal{P}[\mathbfit{x}^1,\ldots,\mathbfit{x}^{n-1}|\mathbfit{s}]} \,.
    \label{eq:marginalization_average}</annotation></semantics></math>
</div>
<p> Thus, assuming that we can evaluate the conditional probability of
the readout given all the other components,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><msubsup><mi>ğ’™</mi><mi>i</mi><mn>1</mn></msubsup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msubsup><mi>ğ’™</mi><mi>i</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msubsup><mo>,</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^n|\mathbfit{x}^1_i,\ldots,\mathbfit{x}^{n-1}_i,\mathbfit{s}]</annotation></semantics></math>,
we arrive at the estimate </p>
<div id="eq:marginalization_mc">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo>â‰ˆ</mo><mfrac><mn>1</mn><mi>M</mi></mfrac><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><msubsup><mi>ğ’™</mi><mi>i</mi><mn>1</mn></msubsup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msubsup><mi>ğ’™</mi><mi>i</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msubsup><mo>,</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^n|\mathbfit{s}] 
    \approx \frac{1}{M}\sum^M_{i=1} \mathcal{P}[\mathbfit{x}^n|\mathbfit{x}^1_i,\ldots,\mathbfit{x}^{n-1}_i,\mathbfit{s}]
\label{eq:marginalization_mc}</annotation></semantics></math>
</div>
<p> where the samples
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>ğ’™</mi><mi>i</mi><mn>1</mn></msubsup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msubsup><mi>ğ’™</mi><mi>i</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msubsup></mrow><annotation encoding="application/x-tex">\mathbfit{x}^1_i,\ldots,\mathbfit{x}^{n-1}_i</annotation></semantics></math>
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>â€¦</mi><mo>,</mo><mi>M</mi></mrow><annotation encoding="application/x-tex">i=1,\ldots,M</annotation></semantics></math>
are drawn from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>ğ’™</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^1,\ldots,\mathbfit{x}^{n-1}|\mathbfit{s}]</annotation></semantics></math>.
Notice that the derivation of this Monte Carlo estimate is fully
analogous to the estimate in <a
href="#eq:marginal-naive">eq:marginal-naive</a>, but instead of
integrating out the input trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>
we integrate out the component trajectories
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>ğ’™</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>ğ’™</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbfit{x}^1,\ldots,\mathbfit{x}^{n-1}</annotation></semantics></math>.</p>
<p>To obtain
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><msubsup><mi>ğ’™</mi><mi>i</mi><mn>1</mn></msubsup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msubsup><mi>ğ’™</mi><mi>i</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msubsup><mo>,</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^n|\mathbfit{x}^1_i,\ldots,\mathbfit{x}^{n-1}_i,\mathbfit{s}]</annotation></semantics></math>
in <a href="#eq:marginalization_average">eq:marginalization_average</a>
and <a href="#eq:marginalization_mc">eq:marginalization_mc</a>, we note
that, in absence of feedback, we can describe the stochastic dynamics of
the readout component
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mi>n</mi></msup><annotation encoding="application/x-tex">X^n</annotation></semantics></math>
as a jump process with time-dependent transition rates whose
time-dependence arises from the trajectories of the other components
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>ğ’™</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>ğ’™</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbfit{x}^1,\ldots,\mathbfit{x}^{n-1}</annotation></semantics></math>
and the input input
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>.
In effect, this is a driven jump process for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mi>n</mi></msup><annotation encoding="application/x-tex">X^n</annotation></semantics></math>,
driven by all upstream components
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>X</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>X</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">X^1,\ldots,X^{n-1}</annotation></semantics></math>
and the input signal. Specifically, denoting
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’–</mi><mo>=</mo><mo stretchy="false" form="prefix">(</mo><msup><mi>ğ’™</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>ğ’™</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msup><mo>,</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathbfit{u}=(\mathbfit{x}^1,\ldots,\mathbfit{x}^{n-1},\mathbfit{s})</annotation></semantics></math>
as the joint trajectory representing the history of all upstream
components as well as the input signal, we can, as explained in <a
href="#sec:mjp">Sec. mjp</a>, write the time dependent transition rate
matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>â‹…</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’–</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">Q_t(\cdot|\mathbfit{u})</annotation></semantics></math>
for the stochastic dynamics of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mi>n</mi></msup><annotation encoding="application/x-tex">X^n</annotation></semantics></math>
and use <a href="#eq:traj_prob">eq:traj_prob</a> to compute
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’–</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><msubsup><mi>ğ’™</mi><mi>i</mi><mn>1</mn></msubsup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msubsup><mi>ğ’™</mi><mi>i</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msubsup><mo>,</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^n|\mathbfit{u}]=\mathcal{P}[\mathbfit{x}^n|\mathbfit{x}^1_i,\ldots,\mathbfit{x}^{n-1}_i,\mathbfit{s}]</annotation></semantics></math>.
Using <a href="#eq:marginalization_mc">eq:marginalization_mc</a>, this
then allows us to compute
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^n|\mathbfit{s}]</annotation></semantics></math>.</p>
<p>Finally, to compute the mutual information
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">I</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo>;</mo><msup><mi>ğ’³</mi><mi>n</mi></msup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{I}(\mathcal{S};\mathcal{X}^n)</annotation></semantics></math>,
e.g. using the estimate in <a
href="#eq:average-of-differences">eq:average-of-differences</a>, we
additionally need to evaluate the marginal output probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^n]</annotation></semantics></math>.
This requires us to perform one additional integration over the space of
input trajectories
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>:
</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="postfix">]</mo></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.222em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>=</mo><msub><mrow><mo stretchy="true" form="prefix">âŸ¨</mo><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo stretchy="true" form="postfix">âŸ©</mo></mrow><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow></msub><mspace width="0.167em"></mspace><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
    \mathcal{P}[\mathbfit{x}^n] &amp;= \int\mathcal{D}[\mathbfit{s}]\ \mathcal{P}[\mathbfit{s}] \mathcal{P}[\mathbfit{x}^n|\mathbfit{s}] \\
    &amp;= \left\langle \mathcal{P}[\mathbfit{x}^n|\mathbfit{s}] \right\rangle_{\mathcal{P}[\mathbfit{s}]} \,.
\end{aligned}</annotation></semantics></math>
<p> The corresponding Monte Carlo estimate is </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="postfix">]</mo></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>â‰ˆ</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><msub><mi>ğ’”</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">]</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right; padding-right: 0"></mtd><mtd columnalign="left" style="text-align: left; padding-left: 0"><mo>â‰ˆ</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mfrac><mn>1</mn><mi>M</mi></mfrac><munderover><mo>âˆ‘</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><msubsup><mi>ğ’™</mi><mrow><mi>i</mi><mi>j</mi></mrow><mn>1</mn></msubsup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msubsup><mi>ğ’™</mi><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msubsup><mo>,</mo><msub><mi>ğ’”</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">]</mo></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
    \mathcal{P}[\mathbfit{x}^n] &amp;\approx \frac{1}{N}\sum^N_{i=1} \mathcal{P}[\mathbfit{x}^n|\mathbfit{s}_i] \\
    &amp;\approx \frac{1}{N}\sum^N_{i=1}\frac{1}{M}\sum^M_{j=1} \mathcal{P}[\mathbfit{x}^n|\mathbfit{x}^1_{ij}, \ldots, \mathbfit{x}^{n-1}_{ij}, \mathbfit{s}_i]
    \end{aligned}</annotation></semantics></math>
<p> where the input trajectories
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ğ’”</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\mathbfit{s}_i</annotation></semantics></math>
follow
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}]</annotation></semantics></math>
and the intermediate components
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msubsup><mi>ğ’™</mi><mrow><mi>i</mi><mi>j</mi></mrow><mn>1</mn></msubsup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msubsup><mi>ğ’™</mi><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msubsup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(\mathbfit{x}^1_{ij},\ldots,\mathbfit{x}^{n-1}_{ij})</annotation></semantics></math>,
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>â€¦</mi><mo>,</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">i=1,\ldots,N</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>â€¦</mi><mo>,</mo><mi>M</mi></mrow><annotation encoding="application/x-tex">j=1,\ldots,M</annotation></semantics></math>,
follow
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mn>1</mn></msup><mo>,</mo><mi>â€¦</mi><mo>,</mo><msup><mi>ğ’™</mi><mrow><mi>n</mi><mo>âˆ’</mo><mn>1</mn></mrow></msup><mo stretchy="false" form="prefix">|</mo><msub><mi>ğ’”</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^1,\ldots,\mathbfit{x}^{n-1}|\mathbfit{s}_i]</annotation></semantics></math>.</p>
<p>In summary, the scheme to obtain
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’–</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^n|\mathbfit{u}]</annotation></semantics></math>
in the presence of hidden intermediate components is analogous to that
used for computing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>
from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>.
In both cases, one needs to marginalize a distribution function by
integrating out components. Indeed, the schemes presented here and in <a
href="#sec:algorithm">Sec. algorithm</a> are bona fide schemes to
compute the mutual information between the input
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>
and either the trajectory of the output component
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ğ’™</mi><mi>n</mi></msup><annotation encoding="application/x-tex">\mathbfit{x}^n</annotation></semantics></math>
or the full output
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’™</mi><annotation encoding="application/x-tex">\mathbfit{x}</annotation></semantics></math>.
However, when the trajectories are sufficiently long or the stochastic
dynamics are sufficiently complex, then the free-energy schemes of <a
href="#ch:variants">Ch. variants</a> may be necessary to enhance the
efficiency of computing the marginalized distribution,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>
or
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><msup><mi>ğ’™</mi><mi>n</mi></msup><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}^n|\mathbfit{s}]</annotation></semantics></math>.</p>
<h2 id="sec:feedback" id="dealing-with-feedback">Dealing with
Feedback</h2>
<p>In principle all physical information processing systems exhibit
feedback. The physical interaction needed to measure the input signal
necessarily affects the incoming signal, and indeed, it follows that no
information can be extracted from the input signal without any
perturbation of the input dynamics. Often, it is assumed that the
amplitude of such perturbations is comparatively small and thus that the
feedback can safely be ignored.</p>
<p>Indeed, the PWS scheme was derived with the assumption of no
feedback. In this section, we drop the assumption and will explicitly
consider systems where the produced output perturbs the input, i.e.
systems where the output feeds back onto the input. We will first
discuss the additional problems that arise when computing the mutual
information for a system with feedback, and subsequently present a
modified version of PWS that can be used to compute the trajectory
mutual information for these systems.</p>
<h3 id="sec:mi-feedback"
id="computing-the-mutual-information-with-feedback-between-input-and-output">Computing
the Mutual Information with Feedback between Input and Output</h3>
<p>PWS requires the computation of the trajectory likelihood
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>,
a quantity that is not readily available for systems with feedback.
Indeed, as already mentioned in <a href="#sec:likelihood">Sec.
likelihood</a>, for a given input trajectory
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>,
the output dynamics are no longer described by a Markov process in a
system with feedback, and therefore we cannot find an expression for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>
based on the master equation. This implies that for systems with
feedback, PWS schemes cannot be used without modification. While it is
generally not possible to derive an expression for the conditional
probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>
in systems with feedback, we often still can compute the joint
probability density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s},\mathbfit{x}]</annotation></semantics></math>
instead. Based on this quantity, we will present a modified PWS scheme
to compute the mutual information for systems with feedback.</p>
<p>Specifically, since PWS is a model-based approach to compute the
mutual information, when there is feedback from the output back to the
input, we require a complete model of the combined system. Specifically,
such a model must provide an expression for the joint probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s},\mathbfit{x}]</annotation></semantics></math>,
describing the input dynamics and the interaction between input and
output, including the feedback.</p>
<p>An estimate of the mutual information that only relies on the
computation of joint probability densities
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s},\mathbfit{x}]</annotation></semantics></math>
can be obtained by expressing the mutual information as </p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">I</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo>,</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.222em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mfrac><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.167em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow></mfrac><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">\mathrm{I}(\mathcal{S}, \mathcal{X}) = \int\mathcal{D}[\mathbfit{s}]\int\mathcal{D}[\mathbfit{x}]\ \mathcal{P}[\mathbfit{s},\mathbfit{x}] \ln \frac{\mathcal{P}[\mathbfit{s}, \mathbfit{x}]}{\mathcal{P}[\mathbfit{s}]\,\mathcal{P}[\mathbfit{x}]}\,.</annotation></semantics></math>
<p> Thus, the PWS scheme with feedback consists of the computation of
</p>
<div id="eq:mi-with-feedback">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">I</mi><mo stretchy="false" form="prefix">(</mo><mi>ğ’®</mi><mo>,</mo><mi>ğ’³</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><msub><mrow><mo stretchy="true" form="prefix">âŸ¨</mo><mi>ln</mi><mfrac><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.167em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow></mfrac><mo stretchy="true" form="postfix">âŸ©</mo></mrow><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow></msub></mrow><annotation encoding="application/x-tex">\mathrm{I}(\mathcal{S}, \mathcal{X}) = \left\langle
    \ln\frac{\mathcal{P}[\mathbfit{s}, \mathbfit{x}]}{\mathcal{P}[\mathbfit{s}]\,\mathcal{P}[\mathbfit{x}]}
    \right\rangle_{\mathcal{P}[\mathbfit{s},\mathbfit{x}]}
    \label{eq:mi-with-feedback}</annotation></semantics></math>
</div>
<p> which we want to estimate via a Monte Carlo average using samples
from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}, \mathbfit{x}]</annotation></semantics></math>.
We see that while we donâ€™t need to evaluate the likelihood
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>,
we now need to explicitly compute the joint density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}, \mathbfit{x}]</annotation></semantics></math>,
and two marginal densities,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}]</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>,
for each Monte Carlo sample
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">)</mo><mo>âˆ¼</mo><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">(\mathbfit{s}, \mathbfit{x})\sim\mathcal{P}[\mathbfit{s},\mathbfit{x}]</annotation></semantics></math>.
While the joint density can be evaluated directly by assumption, each of
the marginalized densities can only be computed using a nested Monte
Carlo estimate.</p>
<p>Specifically, for PWS with feedback, we need to compute <em>two</em>
marginalization integrals per Monte Carlo sample: </p>
<div id="eq:marg1">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.222em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.167em"></mspace><mo>,</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}] = \int\mathcal{D}[\mathbfit{x}]\ \mathcal{P}[\mathbfit{s}, \mathbfit{x}]\,,
    \label{eq:marg1}</annotation></semantics></math>
</div>
<p> and </p>
<div id="eq:marg2">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.222em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}] = \int\mathcal{D}[\mathbfit{s}]\ \mathcal{P}[\mathbfit{s}, \mathbfit{x}] \,.
    \label{eq:marg2}</annotation></semantics></math>
</div>
<p> However, these marginalization integrals cannot be directly computed
with the techniques described so far. Therefore, in the following
subsection, we discuss how to compute marginalization integrals for
systems with feedback.</p>
<p>Additionally, as discussed in <a href="#sec:integrating-out">Sec.
integrating-out</a>, we may also need to integrate out internal
components of the master equation even when the output feeds back onto
these internal components. The technique discussed below can also be
used in this case as a way to compute the marginalization integral in <a
href="#eq:marginalization_integral">eq:marginalization_integral</a>.</p>
<h3 id="sec:marginalization-feedback"
id="marginalization-integrals-for-systems-with-feedback">Marginalization
Integrals for Systems with Feedback</h3>
<p>Computing marginalization integrals in systems with feedback is
harder than it is in the case without feedback. Specifically, we will
show that it is not obvious how apply the Monte Carlo estimate from <a
href="#eq:marginal-naive">eq:marginal-naive</a> to systems with
feedback. Nevertheless, if the system with feedback can be decomposed
into a non-interacting part and an interacting part that includes the
feedback, it is often still possible to compute marginalization
integrals. Below, we sketch the steps that are necessary in order to
compute marginalization integrals for systems with feedback using such a
decomposition.</p>
<p>For concreteness, we discuss how to compute </p>
<div id="eq:feedback-marginalization-integral">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.222em"></mspace><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]=\int\mathcal{D}[\mathbfit{s}]\ \mathcal{P}[\mathbfit{s},\mathbfit{x}]
    \label{eq:feedback-marginalization-integral}</annotation></semantics></math>
</div>
<p> as the prototype for a marginalization integral we want to compute.
Unlike before, we now assume that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’™</mi><annotation encoding="application/x-tex">\mathbfit{x}</annotation></semantics></math>
feeds back onto
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>.
That means that we have access to the joint distributionâ€™s density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s},\mathbfit{x}]</annotation></semantics></math>,
but not to the marginal density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}]</annotation></semantics></math>
or the conditional density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="prefix">|</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}|\mathbfit{s}]</annotation></semantics></math>.</p>
<p>Formulated in the language of statistical physics, marginalization is
equivalent to the computation of the free-energy difference
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Î”</mi><mi>â„±</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mi>â„±</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>âˆ’</mo><msub><mi>â„±</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\Delta\mathcal{F}[\mathbfit{x}]=\mathcal{F}[\mathbfit{x}]-\mathcal{F}_0[\mathbfit{x}]</annotation></semantics></math>
between two ensembles described by potentials
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’°</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}[\mathbfit{s},\mathbfit{x}]</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’°</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}_0[\mathbfit{s},\mathbfit{x}]</annotation></semantics></math>.
Previously, for systems without feedback, we chose these potentials to
be
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’°</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mi>âˆ’</mi><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}_0[\mathbfit{s},\mathbfit{x}]=-\ln\mathcal{P}[\mathbfit{s}]</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’°</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mi>âˆ’</mi><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}[\mathbfit{s},\mathbfit{x}]=-\ln\mathcal{P}[\mathbfit{s}, \mathbfit{x}]</annotation></semantics></math>
with the idea that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’°</mi><annotation encoding="application/x-tex">\mathcal{U}</annotation></semantics></math>
is the potential corresponding to the actual system and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ğ’°</mi><mn>0</mn></msub><annotation encoding="application/x-tex">\mathcal{U}_0</annotation></semantics></math>
is the potential of a reference system with known free energy. Then, by
computing the free-energy difference between the reference system and
the actual system, we could compute the marginal probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>.</p>
<p>However, in systems with feedback we face a problem. Note that the
actual system is still described by the potential
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’°</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mi>âˆ’</mi><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}[\mathbfit{s},\mathbfit{x}]=-\ln\mathcal{P}[\mathbfit{s}, \mathbfit{x}]</annotation></semantics></math>,
even with feedback. Yet, for the reference system described by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’°</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}_0[\mathbfit{s},\mathbfit{x}]</annotation></semantics></math>
we cannot make the same choice as before, because the previous choice
involved the marginal probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}]</annotation></semantics></math>
which is not available with feedback.</p>
<p>Instead, we have to find an alternative expression for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’°</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}_0[\mathbfit{s},\mathbfit{x}]</annotation></semantics></math>.
To construct a suitable reference potential, we can use a decomposition
of the full potential into three parts </p>
<div id="eq:hamiltonian-decomposition">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’°</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><msub><mi>ğ’°</mi><mi>S</mi></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo>+</mo><msub><mi>ğ’°</mi><mi>X</mi></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>+</mo><mi mathvariant="normal">Î”</mi><mi>ğ’°</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}[\mathbfit{s}, \mathbfit{x}] = \mathcal{U}_S[\mathbfit{s}] + \mathcal{U}_X[\mathbfit{x}] + \Delta\mathcal{U}[\mathbfit{s}, \mathbfit{x}]
    \label{eq:hamiltonian-decomposition}</annotation></semantics></math>
</div>
<p> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Î”</mi><mi>ğ’°</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\Delta\mathcal{U}[\mathbfit{s}, \mathbfit{x}]</annotation></semantics></math>
describes the features of the system that induce interaction, or
correlation, between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’”</mi><annotation encoding="application/x-tex">\mathbfit{s}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’™</mi><annotation encoding="application/x-tex">\mathbfit{x}</annotation></semantics></math>.
The first two terms of the potential above,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’°</mi><mi>S</mi></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo>+</mo><msub><mi>ğ’°</mi><mi>X</mi></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}_S[\mathbfit{s}] + \mathcal{U}_X[\mathbfit{x}]</annotation></semantics></math>,
therefore describe a <em>non-interacting</em> version of the system,
where the input and output are fully independent of each other. We want
to use the potential of that non-interacting version as our expression
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ğ’°</mi><mn>0</mn></msub><annotation encoding="application/x-tex">\mathcal{U}_0</annotation></semantics></math>,
i.e.
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’°</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><msub><mi>ğ’°</mi><mi>S</mi></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo>+</mo><msub><mi>ğ’°</mi><mi>X</mi></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}_0[\mathbfit{s}, \mathbfit{x}] = \mathcal{U}_S[\mathbfit{s}] + \mathcal{U}_X[\mathbfit{x}]</annotation></semantics></math>.
To be able to do so, we require that the partition function
(normalization constant) </p>
<div id="eq:z0">
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’µ</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mo>âˆ«</mo><mi>ğ’Ÿ</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.222em"></mspace><msup><mi>e</mi><mrow><mi>âˆ’</mi><msub><mi>ğ’°</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\mathcal{Z}_0[\mathbfit{x}] = \int\mathcal{D}[\mathbfit{s}]\ e^{-\mathcal{U}_0[\mathbfit{s}, \mathbfit{x}]}
    \label{eq:z0}</annotation></semantics></math>
</div>
<p> is known. In other words, we need to choose the decomposition in <a
href="#eq:hamiltonian-decomposition">eq:hamiltonian-decomposition</a>
such that the partition function <a href="#eq:z0">eq:z0</a> is known
either analytically or numerically. If such a decomposition is found, we
can compute the marginal probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>
from the difference in free energy
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Î”</mi><mi>â„±</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\Delta\mathcal{F}[\mathbfit{x}]</annotation></semantics></math>
between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’°</mi><annotation encoding="application/x-tex">\mathcal{U}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ğ’°</mi><mn>0</mn></msub><annotation encoding="application/x-tex">\mathcal{U}_0</annotation></semantics></math>:
</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>âˆ’</mi><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mi>â„±</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><msub><mi>â„±</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>+</mo><mi mathvariant="normal">Î”</mi><mi>â„±</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">-\ln\mathcal{P}[\mathbfit{x}] = \mathcal{F}[\mathbfit{x}] = \mathcal{F}_0[\mathbfit{x}] + \Delta\mathcal{F}[\mathbfit{x}]</annotation></semantics></math>
<p> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>â„±</mi><mn>0</mn></msub><mo>=</mo><mi>âˆ’</mi><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><msub><mi>ğ’µ</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{F}_0 = -\ln\mathcal{Z}_0[\mathbfit{x}]</annotation></semantics></math>
is known. Because we have a known expression for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’°</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}_0[\mathbfit{s},\mathbfit{x}]</annotation></semantics></math>,
the free-energy difference
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Î”</mi><mi>â„±</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\Delta\mathcal{F}[\mathbfit{x}]</annotation></semantics></math>
can now be computed using any of the techniques described in <a
href="#sec:marginalization">Sec. marginalization</a>.</p>
<p>As an example for finding a decomposition like <a
href="#eq:hamiltonian-decomposition">eq:hamiltonian-decomposition</a>,
let us consider the case where the joint system of input and output is
described by a single master equation, i.e. we have a master equation
with two components,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
which represents the input, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
which represents the output. In such a system, information is
transmitted if there exist transitions that change the copy number of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
with a rate that depends on the copy number of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>.
In terms of chemical reactions,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>â†’</mo><mi>S</mi><mo>+</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">S\rightarrow S+X</annotation></semantics></math>
is an example for such a transition. In turn, this system exhibits
feedback if at least one of the transitions that change the copy number
of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
has a rate that depends on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>,
as for example with the reaction
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>+</mo><mi>X</mi><mo>â†’</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">S + X\rightarrow X</annotation></semantics></math>.
Note that with such reactions, the dynamics of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
depend on the current copy number of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>,
and therefore we cannot evolve
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
trajectories independently of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
trajectories, a consequence of feedback. Both of the reactions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>â†’</mo><mi>S</mi><mo>+</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">S\rightarrow S+X</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>+</mo><mi>X</mi><mo>â†’</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">S + X\rightarrow X</annotation></semantics></math>
introduce correlations between the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
trajectories.</p>
<p>In a non-interacting system, such interactions between the input and
output must be absent. Thus, a non-interacting version of the reaction
system contains no single reaction that involves both
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>.
We will now describe how we can use that non-interacting version of the
reaction system, to obtain the reference potential
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’°</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}_0[\mathbfit{s}, \mathbfit{x}]</annotation></semantics></math>.
Since the input and output trajectories are completely independent in
the non-interacting system, we can express the joint distributionâ€™s
probability density as the product of the individual componentâ€™s
trajectory densities,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’«</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><msub><mi>ğ’«</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mspace width="0.222em"></mspace><msub><mi>ğ’«</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}_0[\mathbfit{s}, \mathbfit{x}]=\mathcal{P}_0[\mathbfit{s}]\ \mathcal{P}_0[\mathbfit{x}]</annotation></semantics></math>.
Note that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’«</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}_0[\mathbfit{s}]</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’«</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}_0[\mathbfit{x}]</annotation></semantics></math>
should not be confused with the marginal probabilities
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}]</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>
of the <em>interacting</em> version of the reaction system, which must
be computed using a marginalization integral. Since in the
non-interacting version both
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
obey independent dynamics which are characterized by individual master
equations, both
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’«</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}_0[\mathbfit{s}]</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’«</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}_0[\mathbfit{x}]</annotation></semantics></math>
can be individually computed using <a
href="#eq:traj-prob-master-eq">eq:traj-prob-master-eq</a>. Thus, in this
case, the non-interacting potential is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’°</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mi>âˆ’</mi><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><msub><mi>ğ’«</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo><mo>âˆ’</mo><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><msub><mi>ğ’«</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}_0[\mathbfit{s}, \mathbfit{x}] = -\ln\mathcal{P}_0[\mathbfit{s}]-\ln\mathcal{P}_0[\mathbfit{x}]</annotation></semantics></math>
and, since the probability densities
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’«</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}_0[\mathbfit{s}]</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’«</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}_0[\mathbfit{x}]</annotation></semantics></math>
are normalized, the corresponding partition function is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’µ</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\mathcal{Z}_0=1</annotation></semantics></math>.
Hence, for this reaction system, we can straightforwardly define a
non-interacting version that can be used to obtain the reference
potential
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’°</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}_0[\mathbfit{s}, \mathbfit{x}]</annotation></semantics></math>.
Using the techniques described in <a href="#sec:marginalization">Sec.
marginalization</a>, we can then compute the free-energy difference
between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’°</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}_0[\mathbfit{s}, \mathbfit{x}]</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’°</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mi>âˆ’</mi><mrow><mi>ln</mi><mo>&#8289;</mo></mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}[\mathbfit{s}, \mathbfit{x}]=-\ln\mathcal{P}[\mathbfit{s}, \mathbfit{x}]</annotation></semantics></math>,
where the latter potential describes the dynamics of the fully
interacting system. Specifically, we can compute the marginal
probabilities
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}]</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>
pertaining to the interacting system which are required for the mutual
information estimate in <a
href="#eq:mi-with-feedback">eq:mi-with-feedback</a>.</p>
<p>In summary, for systems with feedback, we can compute marginalization
integrals by specifying a reference potential
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’°</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}_0[\mathbfit{s}, \mathbfit{x}]</annotation></semantics></math>
by finding a non-interacting version of the system. However, barring a
decomposition into interacting and non-interacting potentials, there is
generally no unambiguous choice of the reference potential
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’°</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}_0[\mathbfit{s},\mathbfit{x}]</annotation></semantics></math>
to compute the marginal probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>.
In fact, the optimal reference potential
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’°</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}_0[\mathbfit{s},\mathbfit{x}]</annotation></semantics></math>
is likely to be system-specific. Still, if a suitable expression for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ’°</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo>,</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}_0[\mathbfit{s},\mathbfit{x}]</annotation></semantics></math>
can be found, we can make use of the techniques developed in <a
href="#sec:marginalization">Sec. marginalization</a> to compute marginal
probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>.</p>
<h2 id="discussion">Discussion</h2>
<p>In this chapter, we have described a general, practical, and flexible
method that makes it possible to compute the mutual information between
trajectories exactly. PWS is a Monte Carlo scheme based on the exact
computation of trajectory probabilities. We showed how to compute exact
trajectory probabilities from the master equation and thus how to use
PWS for any system described by a master equation. Since the master
equation is employed in many fields and in particular provides an exact
stochastic model for well-mixed chemical reaction dynamics, PWS is very
broadly applicable.</p>
<p>However, it must be noted that PWS cannot be used to directly obtain
the mutual information between trajectories from experimental data, in
contrast to model-free (yet approximate) methods such as
K-nearest-neighbors estimators <span class="citation"
data-cites="2002.Kaiser 2004.Kraskov">Â [<a href="#ref-2002.Kaiser"
role="doc-biblioref">23</a>,<a href="#ref-2004.Kraskov"
role="doc-biblioref">24</a>]</span>, decoding-based information
estimates <span class="citation" data-cites="2008.Gao">Â [<a
href="#ref-2008.Gao" role="doc-biblioref">26</a>]</span>, or schemes
that compute the mutual information from the data within the Gaussian
framework <span class="citation" data-cites="2021.Mattingly">Â [<a
href="#ref-2021.Mattingly" role="doc-biblioref">51</a>]</span>. PWS
requires a (generative) model based on a master equation or Langevin
equation. Yet, in <a href="#ch:ml-pws">Ch. ml-pws</a>, we will show how
PWS can be combined with machine learning to obtain the rate directly
from time-series data.</p>
<p>We have applied PWS to compute the mutual information rate in steady
state, but PWS can be used equally well to study systems out of steady
state. For such systems a initial condition
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">P</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>s</mi><mn>0</mn></msub><mo>,</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{P}(s_0, x_0)</annotation></semantics></math>
must be specified in addition to the stochastic dynamics of input
trajectories
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’”</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{s}]</annotation></semantics></math>.
These distributions are defined by the (experimental) setup and lead to
a well-defined output distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’«</mi><mo stretchy="false" form="prefix">[</mo><mi>ğ’™</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}[\mathbfit{x}]</annotation></semantics></math>
when the system is coupled to the input. Thus, a steady state is no
prerequisite for the application of PWS to study the trajectory mutual
information.</p>
<p>Overall, PWS is a general framework for computing the mutual
information between trajectories. Because of its flexibility and
simplicity, we envision that it will become an important and reliable
tool for studying information transmission in dynamic stochastic
systems.</p>
<h1 class="unnumbered" id="bibliography">References</h1>
<div id="refs" class="references csl-bib-body" data-entry-spacing="0"
role="list">
<div id="ref-2011.Tkacik" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">G.
TkaÄik and A. M. Walczak, <a
href="https://doi.org/10.1088/0953-8984/23/15/153102"><span
class="nocase">Information transmission in genetic regulatory networks:
a review</span></a>, Journal of Physics: Condensed Matter
<strong>23</strong>, 153102 (2011).</div>
</div>
<div id="ref-2016.Tkacik" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">G.
TkaÄik and W. Bialek, <a
href="https://doi.org/10.1146/annurev-conmatphys-031214-014803"><span
class="nocase">Information Processing in Living Systems</span></a>,
Annual Review of Condensed Matter Physics <strong>7</strong>, 89
(2016).</div>
</div>
<div id="ref-2003.MacKay" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">D.
MacKay, <em><span class="nocase">Information theory, inference, and
learning algorithms</span></em> (Cambridge University Press, Cambridge,
UK, 2003).</div>
</div>
<div id="ref-1948.Shannon" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">C.
E. Shannon, <a
href="https://doi.org/10.1002/j.1538-7305.1948.tb01338.x"><span
class="nocase">A Mathematical Theory of Communication</span></a>, Bell
System Technical Journal <strong>27</strong>, 379 (1948).</div>
</div>
<div id="ref-2006.Cover" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">T.
M. Cover and J. A. Thomas, <em><span class="nocase">Elements of
Information Theory</span></em>, 2nd ed. (John Wiley &amp; Sons,
2006).</div>
</div>
<div id="ref-2009.Tostevin" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">F.
Tostevin and P. R. ten Wolde, <a
href="https://doi.org/10.1103/physrevlett.102.218101"><span
class="nocase">Mutual Information between Input and Output Trajectories
of Biochemical Networks</span></a>, Physical Review Letters
<strong>102</strong>, 218101 (2009).</div>
</div>
<div id="ref-2014.Fiedor" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">P.
Fiedor, <a href="https://doi.org/10.1103/physreve.89.052801"><span
class="nocase">Networks in financial markets based on the mutual
information rate</span></a>, Physical Review E <strong>89</strong>,
052801 (2014).</div>
</div>
<div id="ref-1990.Massey" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">J.
L. Massey, <em><span class="nocase">Causality, Feedback and Directed
Information</span></em>, in <em>Proc. 1990 Int. Symp. On Info. Th. &amp;
Its Applications</em> (Hawaii, USA, 1990), pp. 303â€“305.</div>
</div>
<div id="ref-2000.Schreiber" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">T.
Schreiber, <a href="https://doi.org/10.1103/physrevlett.85.461"><span
class="nocase">Measuring information transfer</span></a>, Physical
Review Letters <strong>85</strong>, 461 (2000).</div>
</div>
<div id="ref-1983.Block" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">S.
M. Block, J. E. Segall, and H. C. Berg, <a
href="https://doi.org/10.1128/jb.154.1.312-323.1983"><span
class="nocase">Adaptation kinetics in bacterial chemotaxis</span></a>,
Journal of Bacteriology <strong>154</strong>, 312 (1983).</div>
</div>
<div id="ref-1986.Segall" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">J.
E. Segall, S. M. Block, and H. C. Berg, <a
href="https://doi.org/10.1073/pnas.83.23.8987"><span
class="nocase">Temporal comparisons in bacterial chemotaxis</span></a>,
Proceedings of the National Academy of Sciences <strong>83</strong>,
8987 (1986).</div>
</div>
<div id="ref-1995.Marshall" class="csl-entry" role="listitem">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">C.
J. Marshall, <a
href="https://doi.org/10.1016/0092-8674(95)90401-8"><span
class="nocase">Specificity of receptor tyrosine kinase signaling:
Transient versus sustained extracellular signal-regulated kinase
activation</span></a>, Cell <strong>80</strong>, 179 (1995).</div>
</div>
<div id="ref-2013.Purvis" class="csl-entry" role="listitem">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">J.
E. Purvis and G. Lahav, <a
href="https://doi.org/10.1016/j.cell.2013.02.005"><span
class="nocase">Encoding and Decoding Cellular Information through
Signaling Dynamics</span></a>, Cell <strong>152</strong>, 945
(2013).</div>
</div>
<div id="ref-2014.Selimkhanov" class="csl-entry" role="listitem">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">J.
Selimkhanov, B. Taylor, J. Yao, A. Pilko, J. Albeck, A. Hoffmann, L.
Tsimring, and R. Wollman, <a
href="https://doi.org/10.1126/science.1254933"><span
class="nocase">Accurate information transmission through dynamic
biochemical signaling networks</span></a>, Science <strong>346</strong>,
1370 (2014).</div>
</div>
<div id="ref-2018.Granados" class="csl-entry" role="listitem">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline">A.
A. Granados, J. M. J. Pietsch, S. A. Cepeda-Humerez, I. L. Farquhar, G.
TkaÄik, and P. S. Swain, <a
href="https://doi.org/10.1073/pnas.1716659115"><span
class="nocase">Distributed and dynamic intracellular organization of
extracellular information</span></a>, Proceedings of the National
Academy of Sciences <strong>115</strong>, 201716659 (2018).</div>
</div>
<div id="ref-1998.Strong" class="csl-entry" role="listitem">
<div class="csl-left-margin">[16] </div><div class="csl-right-inline">S.
P. Strong, R. Koberle, R. R. de Ruyter van Steveninck, and W. Bialek, <a
href="https://doi.org/10.1103/physrevlett.80.197"><span
class="nocase">Entropy and Information in Neural Spike
Trains</span></a>, Physical Review Letters <strong>80</strong>, 197
(1998).</div>
</div>
<div id="ref-2003.Paninski" class="csl-entry" role="listitem">
<div class="csl-left-margin">[17] </div><div class="csl-right-inline">L.
Paninski, <a href="https://doi.org/10.1162/089976603321780272"><span
class="nocase">Estimation of Entropy and Mutual Information</span></a>,
Neural Computation <strong>15</strong>, 1191 (2003).</div>
</div>
<div id="ref-2011.Cheong" class="csl-entry" role="listitem">
<div class="csl-left-margin">[18] </div><div class="csl-right-inline">R.
Cheong, A. Rhee, C. J. Wang, I. Nemenman, and A. Levchenko, <a
href="https://doi.org/10.1126/science.1204553"><span
class="nocase">Information Transduction Capacity of Noisy Biochemical
Signaling Networks</span></a>, Science <strong>334</strong>, 354
(2011).</div>
</div>
<div id="ref-2008.Tkacik" class="csl-entry" role="listitem">
<div class="csl-left-margin">[19] </div><div class="csl-right-inline">G.
TkaÄik, C. G. Callan, and W. Bialek, <a
href="https://doi.org/10.1073/pnas.0806077105"><span
class="nocase">Information flow and optimization in transcriptional
regulation</span></a>, Proceedings of the National Academy of Sciences
<strong>105</strong>, 12265 (2008).</div>
</div>
<div id="ref-2014.Tkacik" class="csl-entry" role="listitem">
<div class="csl-left-margin">[20] </div><div class="csl-right-inline">G.
TkaÄik, J. O. Dubuis, M. D. Petkova, and T. Gregor, <a
href="https://doi.org/10.1534/genetics.114.171850"><span
class="nocase">Positional Information, Positional Error, and Read-Out
Precision in Morphogenesis: A Mathematical Framework</span></a>,
Genetics <strong>199</strong>, genetics.114.171850 (2014).</div>
</div>
<div id="ref-2021.Meijers" class="csl-entry" role="listitem">
<div class="csl-left-margin">[21] </div><div class="csl-right-inline">M.
Meijers, S. Ito, and P. R. ten Wolde, <a
href="https://doi.org/10.1103/physreve.103.l010102"><span
class="nocase">Behavior of information flow near criticality</span></a>,
Physical Review E <strong>103</strong>, L010102 (2021).</div>
</div>
<div id="ref-1999.Rieke" class="csl-entry" role="listitem">
<div class="csl-left-margin">[22] </div><div class="csl-right-inline">F.
Rieke, D. Warland, R. de Ruyter van Steveninck, and W. Bialek, <em><span
class="nocase">Spikes: exploring the neural code</span></em> (MIT Press,
Cambridge, Massachusetts, 1999).</div>
</div>
<div id="ref-2002.Kaiser" class="csl-entry" role="listitem">
<div class="csl-left-margin">[23] </div><div class="csl-right-inline">A.
Kaiser and T. Schreiber, <a
href="https://doi.org/10.1016/s0167-2789(02)00432-3"><span
class="nocase">Information transfer in continuous processes</span></a>,
Physica D: Nonlinear Phenomena <strong>166</strong>, 43 (2002).</div>
</div>
<div id="ref-2004.Kraskov" class="csl-entry" role="listitem">
<div class="csl-left-margin">[24] </div><div class="csl-right-inline">A.
Kraskov, H. StÃ¶gbauer, and P. Grassberger, <a
href="https://doi.org/10.1103/physreve.69.066138"><span
class="nocase">Estimating mutual information</span></a>, Physical Review
E <strong>69</strong>, 066138 (2004).</div>
</div>
<div id="ref-2019.Cepeda-Humerez" class="csl-entry" role="listitem">
<div class="csl-left-margin">[25] </div><div class="csl-right-inline">S.
A. Cepeda-Humerez, J. Ruess, and G. TkaÄik, <a
href="https://doi.org/10.1371/journal.pcbi.1007290"><span
class="nocase">Estimating information in time-varying
signals.</span></a>, PLoS Computational Biology <strong>15</strong>,
e1007290 (2019).</div>
</div>
<div id="ref-2008.Gao" class="csl-entry" role="listitem">
<div class="csl-left-margin">[26] </div><div class="csl-right-inline">Y.
Gao, I. Kontoyiannis, and E. Bienenstock, <a
href="https://doi.org/10.3390/entropy-e10020071"><span
class="nocase">Estimating the Entropy of Binary Time Series:
Methodology, Some Theory and a Simulation Study</span></a>, Entropy
<strong>10</strong>, 71 (2008).</div>
</div>
<div id="ref-1999.Borst" class="csl-entry" role="listitem">
<div class="csl-left-margin">[27] </div><div class="csl-right-inline">A.
Borst and F. E. Theunissen, <a
href="https://doi.org/10.1038/14731"><span class="nocase">Information
theory and neural coding</span></a>, Nature Neuroscience
<strong>2</strong>, 947 (1999).</div>
</div>
<div id="ref-2019.Hledik" class="csl-entry" role="listitem">
<div class="csl-left-margin">[28] </div><div class="csl-right-inline">M.
HledÃ­k, T. R. Sokolowski, and G. TkaÄik, <em><a
href="https://doi.org/10.1109/itw44776.2019.8989292"><span
class="nocase">A Tight Upper Bound on Mutual
Information</span></a></em>, in <em>2019 IEEE Information Theory
Workshop (ITW)</em> (2019), pp. 1â€“5.</div>
</div>
<div id="ref-2016.Thomas" class="csl-entry" role="listitem">
<div class="csl-left-margin">[29] </div><div class="csl-right-inline">P.
J. Thomas and A. W. Eckford, <a
href="https://doi.org/10.1109/tit.2016.2599178"><span
class="nocase">Capacity of a Simple Intercellular Signal Transduction
Channel</span></a>, IEEE Transactions on Information Theory
<strong>62</strong>, 7358 (2016).</div>
</div>
<div id="ref-2019.Duso" class="csl-entry" role="listitem">
<div class="csl-left-margin">[30] </div><div class="csl-right-inline">L.
Duso and C. Zechner, <em><a
href="https://doi.org/10.1109/CDC40024.2019.9029316">Path Mutual
Information for a Class of Biochemical Reaction Networks</a></em>, in
<em>2019 IEEE 58th Conference on Decision and Control (CDC)</em> (2019),
pp. 6610â€“6615.</div>
</div>
<div id="ref-2023.Moor" class="csl-entry" role="listitem">
<div class="csl-left-margin">[31] </div><div
class="csl-right-inline">A.-L. Moor and C. Zechner, <a
href="https://doi.org/10.1103/physrevresearch.5.013032"><span
class="nocase">Dynamic information transfer in stochastic biochemical
networks</span></a>, Physical Review Research <strong>5</strong>, 013032
(2023).</div>
</div>
<div id="ref-1940.Delbrueck" class="csl-entry" role="listitem">
<div class="csl-left-margin">[32] </div><div class="csl-right-inline">M.
DelbrÃ¼ck, <a href="https://doi.org/10.1063/1.1750549"><span
class="nocase">Statistical Fluctuations in Autocatalytic
Reactions</span></a>, The Journal of Chemical Physics
<strong>8</strong>, 120 (1940).</div>
</div>
<div id="ref-1963.McQuarrie" class="csl-entry" role="listitem">
<div class="csl-left-margin">[33] </div><div class="csl-right-inline">D.
A. McQuarrie, <a href="https://doi.org/10.1063/1.1733676"><span
class="nocase">Kinetics of Small Systems. I</span></a>, The Journal of
Chemical Physics <strong>38</strong>, 433 (1963).</div>
</div>
<div id="ref-1964.McQuarrie" class="csl-entry" role="listitem">
<div class="csl-left-margin">[34] </div><div class="csl-right-inline">D.
A. McQuarrie, C. J. Jachimowski, and M. E. Russell, <a
href="https://doi.org/10.1063/1.1724926"><span class="nocase">Kinetics
of Small Systems. II</span></a>, The Journal of Chemical Physics
<strong>40</strong>, 2914 (1964).</div>
</div>
<div id="ref-2000.Elowitz" class="csl-entry" role="listitem">
<div class="csl-left-margin">[35] </div><div class="csl-right-inline">M.
B. Elowitz and S. Leibler, <a
href="https://doi.org/10.1038/35002125"><span class="nocase">A synthetic
oscillatory network of transcriptional regulators</span></a>, Nature
<strong>403</strong>, 335 (2000).</div>
</div>
<div id="ref-1939.Feller" class="csl-entry" role="listitem">
<div class="csl-left-margin">[36] </div><div class="csl-right-inline">W.
Feller, <a href="https://doi.org/10.1007/bf01602932"><span
class="nocase">Die Grundlagen der Volterraschen Theorie des Kampfes ums
Dasein in wahrscheinlichkeitstheoretischer Behandlung</span></a>, Acta
Biotheoretica <strong>5</strong>, 11 (1939).</div>
</div>
<div id="ref-2010.Park" class="csl-entry" role="listitem">
<div class="csl-left-margin">[37] </div><div
class="csl-right-inline">J.-M. Park, E. MuÃ±oz, and M. W. Deem, <a
href="https://doi.org/10.1103/physreve.81.011902"><span
class="nocase">Quasispecies theory for finite populations</span></a>,
Physical Review E <strong>81</strong>, 011902 (2010).</div>
</div>
<div id="ref-2012.Cremer" class="csl-entry" role="listitem">
<div class="csl-left-margin">[38] </div><div class="csl-right-inline">J.
Cremer, A. Melbinger, and E. Frey, <a
href="https://doi.org/10.1038/srep00281"><span class="nocase">Growth
dynamics and the evolution of cooperation in microbial
populations</span></a>, Scientific Reports <strong>2</strong>, 281
(2012).</div>
</div>
<div id="ref-1992.Weidlich" class="csl-entry" role="listitem">
<div class="csl-left-margin">[39] </div><div class="csl-right-inline">W.
Weidlich and M. Braun, <a
href="https://doi.org/10.1007/bf01202420"><span class="nocase">The
master equation approach to nonlinear economics</span></a>, Journal of
Evolutionary Economics <strong>2</strong>, 233 (1992).</div>
</div>
<div id="ref-1995.Lux" class="csl-entry" role="listitem">
<div class="csl-left-margin">[40] </div><div class="csl-right-inline">T.
Lux, <a href="https://doi.org/10.2307/2235156"><span class="nocase">Herd
Behaviour, Bubbles and Crashes</span></a>, The Economic Journal
<strong>105</strong>, 881 (1995).</div>
</div>
<div id="ref-2001.Helbing" class="csl-entry" role="listitem">
<div class="csl-left-margin">[41] </div><div class="csl-right-inline">D.
Helbing, <a href="https://doi.org/10.1103/revmodphys.73.1067"><span
class="nocase">Traffic and related self-driven many-particle
systems</span></a>, Reviews of Modern Physics <strong>73</strong>, 1067
(2001).</div>
</div>
<div id="ref-2009.Castellano" class="csl-entry" role="listitem">
<div class="csl-left-margin">[42] </div><div class="csl-right-inline">C.
Castellano, S. Fortunato, and V. Loreto, <a
href="https://doi.org/10.1103/revmodphys.81.591"><span
class="nocase">Statistical physics of social dynamics</span></a>,
Reviews of Modern Physics <strong>81</strong>, 591 (2009).</div>
</div>
<div id="ref-2007.vanKampen" class="csl-entry" role="listitem">
<div class="csl-left-margin">[43] </div><div class="csl-right-inline">N.
G. van Kampen, <em><a
href="https://doi.org/10.1016/b978-0-444-52965-7.x5000-4"><span
class="nocase">Stochastic Processes in Physics and
Chemistry</span></a></em>, 3rd ed. (Elsevier, Amsterdam, 2007).</div>
</div>
<div id="ref-2017.Weber" class="csl-entry" role="listitem">
<div class="csl-left-margin">[44] </div><div class="csl-right-inline">M.
F. Weber and E. Frey, <a
href="https://doi.org/10.1088/1361-6633/aa5ae2"><span
class="nocase">Master equations and the theory of stochastic path
integrals</span></a>, Reports on Progress in Physics
<strong>80</strong>, 046601 (2017).</div>
</div>
<div id="ref-2009.Walczak" class="csl-entry" role="listitem">
<div class="csl-left-margin">[45] </div><div class="csl-right-inline">A.
M. Walczak, A. Mugler, and C. H. Wiggins, <a
href="https://doi.org/10.1073/pnas.0811999106"><span class="nocase">A
stochastic spectral analysis of transcriptional regulatory
cascades</span></a>, Proceedings of the National Academy of Sciences
<strong>106</strong>, 6529 (2009).</div>
</div>
<div id="ref-2007.Kim" class="csl-entry" role="listitem">
<div class="csl-left-margin">[46] </div><div
class="csl-right-inline">K.-Y. Kim and J. Wang, <a
href="https://doi.org/10.1371/journal.pcbi.0030060"><span
class="nocase">Potential Energy Landscape and Robustness of a Gene
Regulatory Network: Toggle Switch</span></a>, PLoS Computational Biology
<strong>3</strong>, e60 (2007).</div>
</div>
<div id="ref-1976.Gillespie" class="csl-entry" role="listitem">
<div class="csl-left-margin">[47] </div><div class="csl-right-inline">D.
T. Gillespie, <a
href="https://doi.org/10.1016/0021-9991(76)90041-3"><span
class="nocase">A general method for numerically simulating the
stochastic time evolution of coupled chemical reactions</span></a>,
Journal of Computational Physics <strong>22</strong>, 403 (1976).</div>
</div>
<div id="ref-1997.Prados" class="csl-entry" role="listitem">
<div class="csl-left-margin">[48] </div><div class="csl-right-inline">A.
Prados, J. J. Brey, and B. SÃ¡nchez-Rey, <a
href="https://doi.org/10.1007/bf02765541"><span class="nocase">A
dynamical monte carlo algorithm for master equations with time-dependent
transition rates</span></a>, Journal of Statistical Physics
<strong>89</strong>, 709 (1997).</div>
</div>
<div id="ref-2015.Thanh" class="csl-entry" role="listitem">
<div class="csl-left-margin">[49] </div><div class="csl-right-inline">V.
H. Thanh and C. Priami, <a
href="https://doi.org/10.1063/1.4927916"><span class="nocase">Simulation
of biochemical reactions with time-dependent rates by the
rejection-based algorithm</span></a>, The Journal of Chemical Physics
<strong>143</strong>, 054104 (2015).</div>
</div>
<div id="ref-1992.Kloeden" class="csl-entry" role="listitem">
<div class="csl-left-margin">[50] </div><div class="csl-right-inline">P.
E. Kloeden and E. Platen, <em><a
href="https://doi.org/10.1007/978-3-662-12616-5"><span
class="nocase">Numerical Solution of Stochastic Differential
Equations</span></a></em> (Springer, Berlin, Heidelberg, 1992).</div>
</div>
<div id="ref-2021.Mattingly" class="csl-entry" role="listitem">
<div class="csl-left-margin">[51] </div><div class="csl-right-inline">H.
H. Mattingly, K. Kamino, B. B. Machta, and T. Emonet, <a
href="https://doi.org/10.1038/s41567-021-01380-3"><span
class="nocase">Escherichia coli chemotaxis is information
limited</span></a>, Nature Physics <strong>17</strong>, 1426
(2021).</div>
</div>
</div>
</body>
</html>
